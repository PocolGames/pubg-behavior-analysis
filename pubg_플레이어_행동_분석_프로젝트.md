# PUBG í”Œë ˆì´ì–´ í–‰ë™ ë¶„ì„ í”„ë¡œì íŠ¸

## Phase 1: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„

``` python
import warnings
warnings.filterwarnings('ignore')
```

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸


``` python
# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸

# ê¸°ë³¸ ë°ì´í„° ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import numpy as np
import os
import json
import gc
from pathlib import Path

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.offline as pyo

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# í†µê³„ ë° ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import scipy.stats as stats
from scipy.cluster.hierarchy import dendrogram, linkage
import datetime
import time

print("âœ… í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ!")
```

### 2. Google Colab í™˜ê²½ ìµœì í™”
``` python
# 2. Google Colab í™˜ê²½ ìµœì í™”

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
print("ğŸ”§ ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸:")
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {tf.config.list_physical_devices('GPU')}")

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ í•¨ìˆ˜
def check_memory_usage():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    import psutil
    memory = psutil.virtual_memory()
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB / {memory.total/1024**3:.1f}GB)")

# í”Œë¡¯ ì„¤ì • ìµœì í™”
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# Plotly ì„¤ì •
pyo.init_notebook_mode(connected=True)

print("âœ… í™˜ê²½ ìµœì í™” ì™„ë£Œ!")
```
#### 2. Google Colab í™˜ê²½ ìµœì í™” ê²°ê³¼

``` bash
ğŸ”§ ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸:
TensorFlow ë²„ì „: 2.18.0
GPU ì‚¬ìš© ê°€ëŠ¥: []
âœ… í™˜ê²½ ìµœì í™” ì™„ë£Œ!
```

### 3. Kaggle API ì„¤ì • ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ
``` python
# 3. Kaggle API ì„¤ì • ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ

def setup_kaggle_api():
    """Kaggle API ì„¤ì • í•¨ìˆ˜"""
    try:
        # Colabì—ì„œ kaggle.json íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
        from google.colab import files

        print("ğŸ“ Kaggle API í‚¤ ì„¤ì •:")
        print("1. Kaggle ê³„ì • > Account > API > Create New API Token")
        print("2. ë‹¤ìš´ë¡œë“œëœ kaggle.json íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")

        # íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
        uploaded = files.upload()

        # kaggle.json íŒŒì¼ ì´ë™ ë° ê¶Œí•œ ì„¤ì •
        os.makedirs('/root/.kaggle', exist_ok=True)
        os.rename('kaggle.json', '/root/.kaggle/kaggle.json')
        os.chmod('/root/.kaggle/kaggle.json', 600)

        print("âœ… Kaggle API ì„¤ì • ì™„ë£Œ!")
        return True

    except Exception as e:
        print(f"âŒ Kaggle API ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def download_pubg_data():
    """PUBG ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜"""
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('/content/pubg_data', exist_ok=True)
        os.chdir('/content/pubg_data')

        # Kaggleì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
        print("ğŸ“¥ PUBG ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        os.system('kaggle competitions download -c pubg-finish-placement-prediction')

        # ì••ì¶• í•´ì œ
        print("ğŸ“¦ íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...")
        os.system('unzip -q pubg-finish-placement-prediction.zip')

        # íŒŒì¼ ëª©ë¡ í™•ì¸
        files = os.listdir('.')
        print("ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡:")
        for file in files:
            size = os.path.getsize(file) / (1024**2)  # MB ë‹¨ìœ„
            print(f"  - {file}: {size:.1f}MB")

        print("âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return True

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# Kaggle API ì„¤ì • ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
print("ğŸš€ Kaggle ë°ì´í„° ì¤€ë¹„ ì‹œì‘:")
print("\n" + "="*50)
print("ğŸ“Œ ìˆ˜ë™ ì‹¤í–‰ í•„ìš”:")
print("1. setup_kaggle_api() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ API í‚¤ ì„¤ì •")
print("2. download_pubg_data() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
print("="*50)
```
#### Kagle API ì„¤ì • ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ ê²°ê³¼

``` bash
ğŸš€ Kaggle ë°ì´í„° ì¤€ë¹„ ì‹œì‘:

==================================================
ğŸ“Œ ìˆ˜ë™ ì‹¤í–‰ í•„ìš”:
1. setup_kaggle_api() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ API í‚¤ ì„¤ì •
2. download_pubg_data() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
==================================================
```

### 4. ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ íƒìƒ‰ í•¨ìˆ˜
``` python
# 4. ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ íƒìƒ‰ í•¨ìˆ˜

def load_pubg_data(sample_size=None, random_state=42):
    """
    PUBG ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜

    Parameters:
    - sample_size: ìƒ˜í”Œë§í•  í–‰ ìˆ˜ (Noneì´ë©´ ì „ì²´ ë°ì´í„°)
    - random_state: ëœë¤ ì‹œë“œ
    """
    try:
        print("ğŸ“Š PUBG ë°ì´í„° ë¡œë”© ì‹œì‘...")

        # íŒŒì¼ ê²½ë¡œ í™•ì¸
        data_path = '/content/pubg_data/train_V2.csv'
        if not os.path.exists(data_path):
            print("âŒ train_V2.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return None

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(data_path) / (1024**2)
        print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:.1f}MB")

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        check_memory_usage()

        # ë°ì´í„° ë¡œë”© (ìƒ˜í”Œë§ ì˜µì…˜)
        if sample_size:
            print(f"ğŸ¯ {sample_size:,}í–‰ ìƒ˜í”Œë§ìœ¼ë¡œ ë¡œë”©...")
            # ì „ì²´ í–‰ ìˆ˜ í™•ì¸
            total_lines = sum(1 for line in open(data_path)) - 1
            skip_rows = sorted(np.random.choice(range(1, total_lines + 1),
                                              total_lines - sample_size,
                                              replace=False))
            df = pd.read_csv(data_path, skiprows=skip_rows)
        else:
            print("ğŸ“ˆ ì „ì²´ ë°ì´í„° ë¡œë”©...")
            df = pd.read_csv(data_path)

        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape[0]:,}í–‰ x {df.shape[1]}ì—´")
        return df

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def explore_basic_data(df):
    """ê¸°ë³¸ ë°ì´í„° íƒìƒ‰ í•¨ìˆ˜"""
    if df is None:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    print("\n" + "="*50)
    print("ğŸ“‹ ê¸°ë³¸ ë°ì´í„° ì •ë³´")
    print("="*50)

    # ê¸°ë³¸ ì •ë³´
    print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape[0]:,}í–‰ x {df.shape[1]}ì—´")
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.1f}MB")

    # ì»¬ëŸ¼ ì •ë³´
    print(f"\nğŸ“ ì»¬ëŸ¼ ëª©ë¡ ({len(df.columns)}ê°œ):")
    for i, col in enumerate(df.columns, 1):
        dtype = df[col].dtype
        null_count = df[col].isnull().sum()
        null_pct = (null_count / len(df)) * 100
        print(f"  {i:2d}. {col:<20} | {str(dtype):<10} | ê²°ì¸¡ì¹˜: {null_count:>6}ê°œ ({null_pct:.1f}%)")

    # ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(df.describe())

    # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ (winPlacePerc)
    if 'winPlacePerc' in df.columns:
        print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (winPlacePerc) ë¶„í¬:")
        print(df['winPlacePerc'].describe())

    # ìƒ˜í”Œ ë°ì´í„°
    print(f"\nğŸ” ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3í–‰):")
    print(df.head(3))

    return df

# ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_data_loading():
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸:")

    # ì‘ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸
    test_df = load_pubg_data(sample_size=1000)
    if test_df is not None:
        explore_basic_data(test_df)
        print("âœ… ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
    else:
        print("âŒ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        return False
```
### 5. í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸ í•¨ìˆ˜
``` python
# 5. í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸ í•¨ìˆ˜

def check_project_status():
    """í”„ë¡œì íŠ¸ í˜„ì¬ ìƒíƒœ í™•ì¸"""
    print("\n" + "ğŸ® PUBG í”Œë ˆì´ì–´ í–‰ë™ ë¶„ì„ í”„ë¡œì íŠ¸")
    print("="*60)
    print("ğŸ“ í˜„ì¬ ë‹¨ê³„: Phase 1 - í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„")
    print("="*60)

    # ì²´í¬ë¦¬ìŠ¤íŠ¸
    checklist = [
        ("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜", True),
        ("í™˜ê²½ ìµœì í™” ì„¤ì •", True),
        ("Kaggle API í•¨ìˆ˜ ì¤€ë¹„", True),
        ("ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ì¤€ë¹„", True),
        ("ê¸°ë³¸ íƒìƒ‰ í•¨ìˆ˜ ì¤€ë¹„", True)
    ]

    print("âœ… ì™„ë£Œëœ ì‘ì—…:")
    for task, completed in checklist:
        status = "âœ…" if completed else "â³"
        print(f"  {status} {task}")

    print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. setup_kaggle_api() ì‹¤í–‰")
    print("  2. download_pubg_data() ì‹¤í–‰")
    print("  3. test_data_loading() ì‹¤í–‰")
    print("  4. Phase 2ë¡œ ì§„í–‰")

    print("\nğŸ’¡ ë©”ëª¨ë¦¬ ì ˆì•½ íŒ:")
    print("  - ì „ì²´ ë°ì´í„°ê°€ í¬ë©´ sample_size=800000 ì‚¬ìš©")
    print("  - í•„ìš”ì‹œ gc.collect()ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬")
    print("  - GPU ëŸ°íƒ€ì„ ê¶Œì¥")

# í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸
check_project_status()

print("\nğŸš€ Phase 1 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ“± ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”:")
print("   setup_kaggle_api()")
print("   download_pubg_data()")
print("   test_data_loading()")
```
#### 5. í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸ í•¨ìˆ˜ ê²°ê³¼

``` bash
ğŸ® PUBG í”Œë ˆì´ì–´ í–‰ë™ ë¶„ì„ í”„ë¡œì íŠ¸
============================================================
ğŸ“ í˜„ì¬ ë‹¨ê³„: Phase 1 - í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„
============================================================
âœ… ì™„ë£Œëœ ì‘ì—…:
  âœ… í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
  âœ… í™˜ê²½ ìµœì í™” ì„¤ì •
  âœ… Kaggle API í•¨ìˆ˜ ì¤€ë¹„
  âœ… ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ì¤€ë¹„
  âœ… ê¸°ë³¸ íƒìƒ‰ í•¨ìˆ˜ ì¤€ë¹„

ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:
  1. setup_kaggle_api() ì‹¤í–‰
  2. download_pubg_data() ì‹¤í–‰
  3. test_data_loading() ì‹¤í–‰
  4. Phase 2ë¡œ ì§„í–‰

ğŸ’¡ ë©”ëª¨ë¦¬ ì ˆì•½ íŒ:
  - ì „ì²´ ë°ì´í„°ê°€ í¬ë©´ sample_size=800000 ì‚¬ìš©
  - í•„ìš”ì‹œ gc.collect()ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬
  - GPU ëŸ°íƒ€ì„ ê¶Œì¥

ğŸš€ Phase 1 ì¤€ë¹„ ì™„ë£Œ!
ğŸ“± ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”:
   setup_kaggle_api()
   download_pubg_data()
   test_data_loading()
```

### ì‹¤í–‰
``` python
setup_kaggle_api()
download_pubg_data()
test_data_loading()
```
#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ“ Kaggle API í‚¤ ì„¤ì •:
1. Kaggle ê³„ì • > Account > API > Create New API Token
2. ë‹¤ìš´ë¡œë“œëœ kaggle.json íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
kaggle.json
kaggle.json(application/json) - 67 bytes, last modified: 2025. 5. 26. - 100% done
Saving kaggle.json to kaggle.json
âœ… Kaggle API ì„¤ì • ì™„ë£Œ!
ğŸ“¥ PUBG ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...
ğŸ“¦ íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...
ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡:
  - test_V2.csv: 260.6MB
  - train_V2.csv: 629.0MB
  - pubg-finish-placement-prediction.zip: 360.9MB
  - sample_submission_V2.csv: 31.4MB
âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!
ğŸ§ª ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸:
ğŸ“Š PUBG ë°ì´í„° ë¡œë”© ì‹œì‘...
ğŸ“ íŒŒì¼ í¬ê¸°: 629.0MB
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 15.0% (1.6GB / 12.7GB)
ğŸ¯ 1,000í–‰ ìƒ˜í”Œë§ìœ¼ë¡œ ë¡œë”©...
âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: 1,000í–‰ x 29ì—´
```

``` bash
==================================================
ğŸ“‹ ê¸°ë³¸ ë°ì´í„° ì •ë³´
==================================================
ğŸ“Š ë°ì´í„° í¬ê¸°: 1,000í–‰ x 29ì—´
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 0.5MB

ğŸ“ ì»¬ëŸ¼ ëª©ë¡ (29ê°œ):
   1. Id                   | object     | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   2. groupId              | object     | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   3. matchId              | object     | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   4. assists              | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   5. boosts               | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   6. damageDealt          | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   7. DBNOs                | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   8. headshotKills        | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
   9. heals                | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  10. killPlace            | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  11. killPoints           | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  12. kills                | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  13. killStreaks          | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  14. longestKill          | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  15. matchDuration        | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  16. matchType            | object     | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  17. maxPlace             | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  18. numGroups            | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  19. rankPoints           | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  20. revives              | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  21. rideDistance         | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  22. roadKills            | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  23. swimDistance         | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  24. teamKills            | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  25. vehicleDestroys      | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  26. walkDistance         | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  27. weaponsAcquired      | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  28. winPoints            | int64      | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)
  29. winPlacePerc         | float64    | ê²°ì¸¡ì¹˜:      0ê°œ (0.0%)

ğŸ“ˆ ê¸°ë³¸ í†µê³„:
           assists       boosts  damageDealt        DBNOs  headshotKills  \
count  1000.000000  1000.000000  1000.000000  1000.000000    1000.000000   
mean      0.221000     1.159000   130.682024     0.639000       0.214000   
std       0.574882     1.805818   162.853553     1.040077       0.523907   
min       0.000000     0.000000     0.000000     0.000000       0.000000   
25%       0.000000     0.000000     0.000000     0.000000       0.000000   
50%       0.000000     0.000000    89.145000     0.000000       0.000000   
75%       0.000000     2.000000   181.900000     1.000000       0.000000   
max       4.000000    11.000000  1168.000000     7.000000       4.000000   

             heals    killPlace   killPoints        kills  killStreaks  ...  \
count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   
mean      1.467000    47.177000   472.241000     0.942000     0.541000  ...   
std       2.826818    27.719561   617.898381     1.516884     0.694839  ...   
min       0.000000     1.000000     0.000000     0.000000     0.000000  ...   
25%       0.000000    23.000000     0.000000     0.000000     0.000000  ...   
50%       0.000000    46.000000     0.000000     0.000000     0.000000  ...   
75%       2.000000    71.000000  1152.000000     1.000000     1.000000  ...   
max      25.000000   100.000000  1882.000000    12.000000     5.000000  ...   

           revives  rideDistance    roadKills  swimDistance    teamKills  \
count  1000.000000   1000.000000  1000.000000   1000.000000  1000.000000   
mean      0.153000    584.856341     0.002000      2.933933     0.027000   
std       0.442478   1411.430874     0.044699     16.956302     0.168224   
min       0.000000      0.000000     0.000000      0.000000     0.000000   
25%       0.000000      0.000000     0.000000      0.000000     0.000000   
50%       0.000000      0.000000     0.000000      0.000000     0.000000   
75%       0.000000     37.392500     0.000000      0.000000     0.000000   
max       5.000000  10730.000000     1.000000    238.300000     2.000000   

       vehicleDestroys  walkDistance  weaponsAcquired    winPoints  \
count      1000.000000   1000.000000       1000.00000  1000.000000   
mean          0.008000   1174.950077          3.60100   568.488000   
std           0.089129   1232.368923          2.33779   731.804729   
min           0.000000      0.000000          0.00000     0.000000   
25%           0.000000    158.550000          2.00000     0.000000   
50%           0.000000    682.600000          3.00000     0.000000   
75%           0.000000   1919.250000          5.00000  1492.000000   
max           1.000000   7383.000000         19.00000  1755.000000   

       winPlacePerc  
count   1000.000000  
mean       0.476836  
std        0.312325  
min        0.000000  
25%        0.192300  
50%        0.474050  
75%        0.750000  
max        1.000000  

[8 rows x 25 columns]

ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (winPlacePerc) ë¶„í¬:
count    1000.000000
mean        0.476836
std         0.312325
min         0.000000
25%         0.192300
50%         0.474050
75%         0.750000
max         1.000000
Name: winPlacePerc, dtype: float64

ğŸ” ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3í–‰):
               Id         groupId         matchId  assists  boosts  \
0  1d4802d5196bfc  5f7f2fcef7ffd2  4ae569cd5839bd        0       0   
1  adfb57db50ff99  8be5becce02129  9b3251ccfd56be        0       0   
2  23df6be369873d  6ef4e4dbd06580  44d4f3c1d95b55        0       0   

   damageDealt  DBNOs  headshotKills  heals  killPlace  ...  revives  \
0         53.0      1              0      0         40  ...        0   
1          0.0      0              0      0         36  ...        0   
2          0.0      0              0      0         73  ...        0   

   rideDistance  roadKills  swimDistance  teamKills vehicleDestroys  \
0           0.0          0           0.0          0               0   
1           0.0          0           0.0          0               0   
2           0.0          0           0.0          0               0   

   walkDistance  weaponsAcquired  winPoints  winPlacePerc  
0         40.94                1          0        0.0741  
1       1614.00                6       1497        0.7083  
2         57.67                1          0        0.2308  

[3 rows x 29 columns]
âœ… ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì„±ê³µ!
True
```

## Phase 2: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ë° ì „ì²˜ë¦¬

### 1. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ í•¨ìˆ˜ë“¤
``` python
print("ğŸ” Phase 2: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œì‘!")
print("="*60)
# 1. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ í•¨ìˆ˜ë“¤

def comprehensive_data_quality_check(df):
    """ì¢…í•©ì ì¸ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
    print("ğŸ“Š ì¢…í•© ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")
    print("-" * 40)

    quality_report = {}

    # 1. ê¸°ë³¸ ì •ë³´
    print(f"ğŸ“ˆ ë°ì´í„° í¬ê¸°: {df.shape[0]:,}í–‰ x {df.shape[1]}ì—´")
    quality_report['shape'] = df.shape

    # 2. ê²°ì¸¡ì¹˜ ë¶„ì„
    print(f"\nğŸ’¥ ê²°ì¸¡ì¹˜ ë¶„ì„:")
    missing_data = df.isnull().sum()
    missing_pct = (missing_data / len(df)) * 100

    missing_summary = pd.DataFrame({
        'Column': missing_data.index,
        'Missing_Count': missing_data.values,
        'Missing_Percentage': missing_pct.values
    }).sort_values('Missing_Count', ascending=False)

    print(missing_summary[missing_summary['Missing_Count'] > 0])
    quality_report['missing_data'] = missing_summary

    # 3. ì¤‘ë³µ ë°ì´í„° í™•ì¸
    duplicates = df.duplicated().sum()
    print(f"\nğŸ”„ ì¤‘ë³µ í–‰ ìˆ˜: {duplicates:,}ê°œ ({duplicates/len(df)*100:.2f}%)")
    quality_report['duplicates'] = duplicates

    # 4. ë°ì´í„° íƒ€ì… í™•ì¸
    print(f"\nğŸ“ ë°ì´í„° íƒ€ì… ë¶„í¬:")
    dtype_counts = df.dtypes.value_counts()
    print(dtype_counts)
    quality_report['dtypes'] = dtype_counts

    return quality_report

def check_game_logic_violations(df):
    """ê²Œì„ ë¡œì§ ê¸°ë°˜ ë°ì´í„° ê²€ì¦"""
    print("\nğŸ® ê²Œì„ ë¡œì§ ê¸°ë°˜ ë°ì´í„° ê²€ì¦")
    print("-" * 40)

    violations = {}

    # 1. ìŒìˆ˜ê°’ í™•ì¸ (ìŒìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ì—†ëŠ” ì»¬ëŸ¼ë“¤)
    non_negative_cols = ['kills', 'knockdowns', 'assists', 'revives', 'heals', 'boosts',
                        'weaponsAcquired', 'vehicleDestroys', 'roadKills', 'teamKills',
                        'DBNOs', 'walkDistance', 'rideDistance', 'swimDistance']

    for col in non_negative_cols:
        if col in df.columns:
            negative_count = (df[col] < 0).sum()
            if negative_count > 0:
                violations[f'{col}_negative'] = negative_count
                print(f"âŒ {col}: {negative_count:,}ê°œì˜ ìŒìˆ˜ê°’")

    # 2. ë…¼ë¦¬ì  ë¶ˆì¼ì¹˜ í™•ì¸
    if 'kills' in df.columns and 'DBNOs' in df.columns:
        # í‚¬ ìˆ˜ê°€ ë‹¤ìš´ ìˆ˜ë³´ë‹¤ ë§ì€ ê²½ìš° (ë…¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥)
        kill_dbno_violation = (df['kills'] > df['DBNOs']).sum()
        if kill_dbno_violation > 0:
            violations['kills_gt_dbnos'] = kill_dbno_violation
            print(f"âŒ í‚¬ ìˆ˜ > ë‹¤ìš´ ìˆ˜: {kill_dbno_violation:,}ê°œ")

    # 3. ê·¹ë‹¨ê°’ í™•ì¸
    if 'kills' in df.columns:
        max_kills = df['kills'].max()
        extreme_kills = (df['kills'] > 30).sum()
        print(f"âš ï¸  ìµœëŒ€ í‚¬ ìˆ˜: {max_kills}, 30í‚¬ ì´ìƒ: {extreme_kills:,}ê°œ")
        violations['extreme_kills'] = extreme_kills

    # 4. winPlacePerc ë²”ìœ„ í™•ì¸
    if 'winPlacePerc' in df.columns:
        invalid_winplace = ((df['winPlacePerc'] < 0) | (df['winPlacePerc'] > 1)).sum()
        if invalid_winplace > 0:
            violations['invalid_winplaceperc'] = invalid_winplace
            print(f"âŒ winPlacePerc ë²”ìœ„ ì˜¤ë¥˜ (0-1 ë°–): {invalid_winplace:,}ê°œ")

    print(f"\nğŸ“Š ì´ {len(violations)}ê°œì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë°œê²¬")
    return violations

def detect_outliers_statistical(df, method='iqr'):
    """í†µê³„ì  ì´ìƒì¹˜ íƒì§€"""
    print(f"\nğŸ“ˆ í†µê³„ì  ì´ìƒì¹˜ íƒì§€ ({method.upper()} ë°©ë²•)")
    print("-" * 40)

    numeric_cols = df.select_dtypes(include=[np.number]).columns
    outliers_info = {}

    for col in numeric_cols:
        if col in ['Id', 'groupId', 'matchId']:  # ID ì»¬ëŸ¼ ì œì™¸
            continue

        if method == 'iqr':
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()

        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(df[col].dropna()))
            outliers = (z_scores > 3).sum()

        if outliers > 0:
            outliers_info[col] = {
                'count': outliers,
                'percentage': (outliers / len(df)) * 100
            }

    # ìƒìœ„ 10ê°œ ì´ìƒì¹˜ ì»¬ëŸ¼ ì¶œë ¥
    sorted_outliers = sorted(outliers_info.items(),
                           key=lambda x: x[1]['count'],
                           reverse=True)[:10]

    for col, info in sorted_outliers:
        print(f"ğŸ“Š {col:<20}: {info['count']:>6,}ê°œ ({info['percentage']:>5.1f}%)")

    return outliers_info
```

### 2. ë°ì´í„° ì •ì œ í•¨ìˆ˜ë“¤
``` python
# 2. ë°ì´í„° ì •ì œ í•¨ìˆ˜ë“¤

def clean_missing_values(df, strategy='smart'):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    print(f"\nğŸ§¹ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì „ëµ: {strategy})")
    print("-" * 40)

    df_cleaned = df.copy()

    if strategy == 'smart':
        # ìŠ¤ë§ˆíŠ¸ ì „ëµ: ì»¬ëŸ¼ë³„ ë§ì¶¤ ì²˜ë¦¬

        # 1. winPlacePerc ê²°ì¸¡ì¹˜ ì œê±° (íƒ€ê²Ÿ ë³€ìˆ˜)
        if 'winPlacePerc' in df_cleaned.columns:
            before_count = len(df_cleaned)
            df_cleaned = df_cleaned.dropna(subset=['winPlacePerc'])
            removed = before_count - len(df_cleaned)
            print(f"ğŸ“ winPlacePerc ê²°ì¸¡ì¹˜ ì œê±°: {removed:,}í–‰")

        # 2. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ëŠ” 0ìœ¼ë¡œ ëŒ€ì²´ (ê²Œì„ì—ì„œ í–‰ë™í•˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ í•´ì„)
        numeric_fill_zero = ['kills', 'knockdowns', 'assists', 'revives', 'heals', 'boosts',
                           'weaponsAcquired', 'vehicleDestroys', 'roadKills', 'teamKills', 'DBNOs']

        for col in numeric_fill_zero:
            if col in df_cleaned.columns:
                filled = df_cleaned[col].isnull().sum()
                df_cleaned[col] = df_cleaned[col].fillna(0)
                if filled > 0:
                    print(f"ğŸ”§ {col}: {filled:,}ê°œë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´")

        # 3. ê±°ë¦¬ ê´€ë ¨ ë³€ìˆ˜ë„ 0ìœ¼ë¡œ ëŒ€ì²´
        distance_cols = ['walkDistance', 'rideDistance', 'swimDistance']
        for col in distance_cols:
            if col in df_cleaned.columns:
                filled = df_cleaned[col].isnull().sum()
                df_cleaned[col] = df_cleaned[col].fillna(0)
                if filled > 0:
                    print(f"ğŸ”§ {col}: {filled:,}ê°œë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´")

    elif strategy == 'drop':
        # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ëª¨ë‘ ì œê±°
        before_count = len(df_cleaned)
        df_cleaned = df_cleaned.dropna()
        removed = before_count - len(df_cleaned)
        print(f"ğŸ—‘ï¸ ê²°ì¸¡ì¹˜ í¬í•¨ í–‰ ì œê±°: {removed:,}í–‰")

    print(f"âœ… ì •ì œ í›„ ë°ì´í„° í¬ê¸°: {df_cleaned.shape[0]:,}í–‰")
    return df_cleaned

def handle_duplicates(df, strategy='remove'):
    """ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬"""
    print(f"\nğŸ”„ ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ (ì „ëµ: {strategy})")
    print("-" * 40)

    df_cleaned = df.copy()

    if strategy == 'remove':
        before_count = len(df_cleaned)
        df_cleaned = df_cleaned.drop_duplicates()
        removed = before_count - len(df_cleaned)
        print(f"ğŸ—‘ï¸ ì¤‘ë³µ í–‰ ì œê±°: {removed:,}í–‰")

    elif strategy == 'keep_first':
        before_count = len(df_cleaned)
        df_cleaned = df_cleaned.drop_duplicates(keep='first')
        removed = before_count - len(df_cleaned)
        print(f"ğŸ¥‡ ì¤‘ë³µ í–‰ ì¤‘ ì²« ë²ˆì§¸ë§Œ ìœ ì§€: {removed:,}í–‰ ì œê±°")

    print(f"âœ… ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df_cleaned.shape[0]:,}í–‰")
    return df_cleaned

def fix_game_logic_violations(df):
    """ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì •"""
    print(f"\nğŸ® ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì •")
    print("-" * 40)

    df_fixed = df.copy()
    fixes = {}

    # 1. ìŒìˆ˜ê°’ì„ 0ìœ¼ë¡œ ìˆ˜ì •
    non_negative_cols = ['kills', 'knockdowns', 'assists', 'revives', 'heals', 'boosts',
                        'weaponsAcquired', 'vehicleDestroys', 'roadKills', 'teamKills',
                        'DBNOs', 'walkDistance', 'rideDistance', 'swimDistance']

    for col in non_negative_cols:
        if col in df_fixed.columns:
            negative_count = (df_fixed[col] < 0).sum()
            if negative_count > 0:
                df_fixed.loc[df_fixed[col] < 0, col] = 0
                fixes[f'{col}_negative_fixed'] = negative_count
                print(f"ğŸ”§ {col}: {negative_count:,}ê°œì˜ ìŒìˆ˜ê°’ì„ 0ìœ¼ë¡œ ìˆ˜ì •")

    # 2. winPlacePerc ë²”ìœ„ ìˆ˜ì • (0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘)
    if 'winPlacePerc' in df_fixed.columns:
        out_of_range = ((df_fixed['winPlacePerc'] < 0) | (df_fixed['winPlacePerc'] > 1)).sum()
        if out_of_range > 0:
            df_fixed['winPlacePerc'] = df_fixed['winPlacePerc'].clip(0, 1)
            fixes['winplaceperc_clipped'] = out_of_range
            print(f"ğŸ”§ winPlacePerc: {out_of_range:,}ê°œ ê°’ì„ 0-1 ë²”ìœ„ë¡œ ìˆ˜ì •")

    # 3. ê·¹ë‹¨ê°’ ì²˜ë¦¬ (Winsorization)
    extreme_cols = ['kills', 'damageDealt', 'walkDistance', 'rideDistance']
    for col in extreme_cols:
        if col in df_fixed.columns:
            # 99.5 í¼ì„¼íƒ€ì¼ë¡œ ê·¹ë‹¨ê°’ ì œí•œ
            upper_limit = df_fixed[col].quantile(0.995)
            extreme_count = (df_fixed[col] > upper_limit).sum()
            if extreme_count > 0:
                df_fixed.loc[df_fixed[col] > upper_limit, col] = upper_limit
                fixes[f'{col}_winsorized'] = extreme_count
                print(f"ğŸ”§ {col}: {extreme_count:,}ê°œ ê·¹ë‹¨ê°’ì„ {upper_limit:.1f}ë¡œ ì œí•œ")

    print(f"âœ… ì´ {len(fixes)}ê°œ ìœ í˜•ì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ìˆ˜ì •")
    return df_fixed, fixes

def optimize_memory_usage(df):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”")
    print("-" * 40)

    df_optimized = df.copy()
    memory_before = df_optimized.memory_usage(deep=True).sum() / 1024**2

    # ìˆ˜ì¹˜í˜• ë°ì´í„° íƒ€ì… ìµœì í™”
    for col in df_optimized.select_dtypes(include=['int64']).columns:
        df_optimized[col] = pd.to_numeric(df_optimized[col], downcast='integer')

    for col in df_optimized.select_dtypes(include=['float64']).columns:
        df_optimized[col] = pd.to_numeric(df_optimized[col], downcast='float')

    # ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì²˜ë¦¬
    categorical_candidates = ['matchType']
    for col in categorical_candidates:
        if col in df_optimized.columns:
            if df_optimized[col].nunique() < len(df_optimized) * 0.5:  # ì¹´ë””ë„ë¦¬í‹°ê°€ ë‚®ìœ¼ë©´
                df_optimized[col] = df_optimized[col].astype('category')

    memory_after = df_optimized.memory_usage(deep=True).sum() / 1024**2
    memory_saved = memory_before - memory_after

    print(f"ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_before:.1f}MB â†’ {memory_after:.1f}MB")
    print(f"ğŸ’° ì ˆì•½ëœ ë©”ëª¨ë¦¬: {memory_saved:.1f}MB ({memory_saved/memory_before*100:.1f}%)")

    return df_optimized
```
### 3. ì¢…í•© ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸
``` python
# 3. ì¢…í•© ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸

def comprehensive_data_cleaning_pipeline(df, sample_size=None):
    """ì¢…í•©ì ì¸ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸"""
    print("ğŸš€ ì¢…í•© ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*60)

    # ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
    if sample_size and len(df) > sample_size:
        print(f"ğŸ¯ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ {sample_size:,}í–‰ìœ¼ë¡œ ìƒ˜í”Œë§")
        df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)

    # ë‹¨ê³„ë³„ ì •ì œ
    steps_log = []

    # 1. ì´ˆê¸° í’ˆì§ˆ ê²€ì‚¬
    print(f"\n{'='*20} 1ë‹¨ê³„: ì´ˆê¸° í’ˆì§ˆ ê²€ì‚¬ {'='*20}")
    initial_quality = comprehensive_data_quality_check(df)
    game_violations = check_game_logic_violations(df)
    outliers_info = detect_outliers_statistical(df)
    steps_log.append(f"ì´ˆê¸° ë°ì´í„°: {df.shape[0]:,}í–‰")

    # 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    print(f"\n{'='*20} 2ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ {'='*20}")
    df_cleaned = clean_missing_values(df, strategy='smart')
    steps_log.append(f"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„: {df_cleaned.shape[0]:,}í–‰")

    # 3. ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬
    print(f"\n{'='*20} 3ë‹¨ê³„: ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ {'='*20}")
    df_cleaned = handle_duplicates(df_cleaned, strategy='remove')
    steps_log.append(f"ì¤‘ë³µ ì œê±° í›„: {df_cleaned.shape[0]:,}í–‰")

    # 4. ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì •
    print(f"\n{'='*20} 4ë‹¨ê³„: ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì • {'='*20}")
    df_cleaned, fixes = fix_game_logic_violations(df_cleaned)
    steps_log.append(f"ë¡œì§ ìˆ˜ì • í›„: {df_cleaned.shape[0]:,}í–‰")

    # 5. ë©”ëª¨ë¦¬ ìµœì í™”
    print(f"\n{'='*20} 5ë‹¨ê³„: ë©”ëª¨ë¦¬ ìµœì í™” {'='*20}")
    df_cleaned = optimize_memory_usage(df_cleaned)
    steps_log.append(f"ìµœì í™” í›„: {df_cleaned.shape[0]:,}í–‰")

    # 6. ìµœì¢… í’ˆì§ˆ ê²€ì‚¬
    print(f"\n{'='*20} 6ë‹¨ê³„: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ {'='*20}")
    final_quality = comprehensive_data_quality_check(df_cleaned)

    # ì •ì œ ìš”ì•½
    print(f"\n{'='*20} ë°ì´í„° ì •ì œ ì™„ë£Œ ìš”ì•½ {'='*20}")
    for step in steps_log:
        print(f"ğŸ“‹ {step}")

    print(f"\nâœ… ìµœì¢… ì •ì œ ë°ì´í„°: {df_cleaned.shape[0]:,}í–‰ x {df_cleaned.shape[1]}ì—´")

    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    del df
    gc.collect()

    return df_cleaned, {
        'initial_quality': initial_quality,
        'game_violations': game_violations,
        'outliers_info': outliers_info,
        'fixes': fixes,
        'final_quality': final_quality,
        'steps_log': steps_log
    }
```
### 4. ì‹¤í–‰ í•¨ìˆ˜
``` python
# 4. ì‹¤í–‰ í•¨ìˆ˜

def run_phase2_pipeline(df_raw, sample_size=800000):
    """Phase 2 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("ğŸ® PUBG Phase 2: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œì‘!")
    print("="*60)

    start_time = time.time()

    # ë©”ëª¨ë¦¬ í™•ì¸
    check_memory_usage()

    # ì¢…í•© ë°ì´í„° ì •ì œ ì‹¤í–‰
    df_cleaned, cleaning_report = comprehensive_data_cleaning_pipeline(
        df_raw, sample_size=sample_size
    )

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    execution_time = time.time() - start_time

    print(f"\nâ° Phase 2 ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"âœ… Phase 2 ì™„ë£Œ! Phase 3 (EDA)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return df_cleaned, cleaning_report

# ì‹¤í–‰ ì˜ˆì‹œ
print("\nğŸ“‹ Phase 2 ì‹¤í–‰ ë°©ë²•:")
print("="*40)
print("# 1. ë°ì´í„° ë¡œë”© (Phase 1ì—ì„œ ìˆ˜í–‰)")
print("df_raw = load_pubg_data(sample_size=None)  # ë˜ëŠ” ì „ì²´ ë°ì´í„°")
print()
print("# 2. Phase 2 ì‹¤í–‰")
print("df_cleaned, report = run_phase2_pipeline(df_raw, sample_size=800000)")
print()
print("# 3. ê²°ê³¼ í™•ì¸")
print("print(f'ì •ì œëœ ë°ì´í„°: {df_cleaned.shape}')")

print("\nğŸ¯ Phase 2 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: Phase 3 - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)")
```
#### 4. ì‹¤í–‰ í•¨ìˆ˜ ê²°ê³¼

``` bash
ğŸ“‹ Phase 2 ì‹¤í–‰ ë°©ë²•:
========================================
# 1. ë°ì´í„° ë¡œë”© (Phase 1ì—ì„œ ìˆ˜í–‰)
df_raw = load_pubg_data(sample_size=None)  # ë˜ëŠ” ì „ì²´ ë°ì´í„°

# 2. Phase 2 ì‹¤í–‰
df_cleaned, report = run_phase2_pipeline(df_raw, sample_size=800000)

# 3. ê²°ê³¼ í™•ì¸
print(f'ì •ì œëœ ë°ì´í„°: {df_cleaned.shape}')

ğŸ¯ Phase 2 ì¤€ë¹„ ì™„ë£Œ!
ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: Phase 3 - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)
```

### ì‹¤í–‰
``` python
# Phase 1ì—ì„œ ë¡œë”©í•œ ë°ì´í„° ì‚¬ìš©
df_raw = load_pubg_data(sample_size=None)  # ì „ì²´ ë˜ëŠ” ìƒ˜í”Œ

# Phase 2 ì‹¤í–‰
df_cleaned, report = run_phase2_pipeline(df_raw, sample_size=800000)
```
#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ“Š PUBG ë°ì´í„° ë¡œë”© ì‹œì‘...
ğŸ“ íŒŒì¼ í¬ê¸°: 629.0MB
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 15.5% (1.7GB / 12.7GB)
ğŸ“ˆ ì „ì²´ ë°ì´í„° ë¡œë”©...
âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: 4,446,966í–‰ x 29ì—´
```
``` bash
ğŸ® PUBG Phase 2: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œì‘!
============================================================
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 28.8% (3.3GB / 12.7GB)
ğŸš€ ì¢…í•© ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ ì‹œì‘
```
``` bash
============================================================
ğŸ¯ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ 800,000í–‰ìœ¼ë¡œ ìƒ˜í”Œë§
```
``` bash
==================== 1ë‹¨ê³„: ì´ˆê¸° í’ˆì§ˆ ê²€ì‚¬ ====================
ğŸ“Š ì¢…í•© ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
----------------------------------------
ğŸ“ˆ ë°ì´í„° í¬ê¸°: 800,000í–‰ x 29ì—´

ğŸ’¥ ê²°ì¸¡ì¹˜ ë¶„ì„:
Empty DataFrame
Columns: [Column, Missing_Count, Missing_Percentage]
Index: []

ğŸ”„ ì¤‘ë³µ í–‰ ìˆ˜: 0ê°œ (0.00%)

ğŸ“ ë°ì´í„° íƒ€ì… ë¶„í¬:
int64      19
float64     6
object      4
Name: count, dtype: int64

ğŸ® ê²Œì„ ë¡œì§ ê¸°ë°˜ ë°ì´í„° ê²€ì¦
----------------------------------------
âŒ í‚¬ ìˆ˜ > ë‹¤ìš´ ìˆ˜: 187,390ê°œ
âš ï¸  ìµœëŒ€ í‚¬ ìˆ˜: 55, 30í‚¬ ì´ìƒ: 15ê°œ

ğŸ“Š ì´ 2ê°œì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë°œê²¬

ğŸ“ˆ í†µê³„ì  ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
----------------------------------------
ğŸ“Š rideDistance        : 199,765ê°œ ( 25.0%)
ğŸ“Š assists             : 139,896ê°œ ( 17.5%)
ğŸ“Š headshotKills       : 134,943ê°œ ( 16.9%)
ğŸ“Š maxPlace            : 126,033ê°œ ( 15.8%)
ğŸ“Š numGroups           : 125,441ê°œ ( 15.7%)
ğŸ“Š longestKill         : 110,638ê°œ ( 13.8%)
ğŸ“Š revives             : 105,804ê°œ ( 13.2%)
ğŸ“Š kills               : 92,899ê°œ ( 11.6%)
ğŸ“Š heals               : 58,582ê°œ (  7.3%)
ğŸ“Š DBNOs               : 53,107ê°œ (  6.6%)
```
``` bash
==================== 2ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ====================

ğŸ§¹ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì „ëµ: smart)
----------------------------------------
ğŸ“ winPlacePerc ê²°ì¸¡ì¹˜ ì œê±°: 0í–‰
âœ… ì •ì œ í›„ ë°ì´í„° í¬ê¸°: 800,000í–‰
```
``` bash
==================== 3ë‹¨ê³„: ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ ====================

ğŸ”„ ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ (ì „ëµ: remove)
----------------------------------------
ğŸ—‘ï¸ ì¤‘ë³µ í–‰ ì œê±°: 0í–‰
âœ… ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: 800,000í–‰
```
``` bash
==================== 4ë‹¨ê³„: ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì • ====================

ğŸ® ê²Œì„ ë¡œì§ ìœ„ë°˜ ìˆ˜ì •
----------------------------------------
ğŸ”§ kills: 3,653ê°œ ê·¹ë‹¨ê°’ì„ 8.0ë¡œ ì œí•œ
ğŸ”§ damageDealt: 4,000ê°œ ê·¹ë‹¨ê°’ì„ 922.2ë¡œ ì œí•œ
ğŸ”§ walkDistance: 3,994ê°œ ê·¹ë‹¨ê°’ì„ 4835.0ë¡œ ì œí•œ
ğŸ”§ rideDistance: 3,998ê°œ ê·¹ë‹¨ê°’ì„ 8068.0ë¡œ ì œí•œ
âœ… ì´ 4ê°œ ìœ í˜•ì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ìˆ˜ì •
```
``` bash
==================== 5ë‹¨ê³„: ë©”ëª¨ë¦¬ ìµœì í™” ====================

ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
----------------------------------------
ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 364.1MB â†’ 199.9MB
ğŸ’° ì ˆì•½ëœ ë©”ëª¨ë¦¬: 164.2MB (45.1%)
```
``` bash
==================== 6ë‹¨ê³„: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ====================
ğŸ“Š ì¢…í•© ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
----------------------------------------
ğŸ“ˆ ë°ì´í„° í¬ê¸°: 800,000í–‰ x 29ì—´

ğŸ’¥ ê²°ì¸¡ì¹˜ ë¶„ì„:
Empty DataFrame
Columns: [Column, Missing_Count, Missing_Percentage]
Index: []

ğŸ”„ ì¤‘ë³µ í–‰ ìˆ˜: 0ê°œ (0.00%)

ğŸ“ ë°ì´í„° íƒ€ì… ë¶„í¬:
int8        14
float32      6
int16        5
object       3
category     1
Name: count, dtype: int64
```
``` bash
==================== ë°ì´í„° ì •ì œ ì™„ë£Œ ìš”ì•½ ====================
ğŸ“‹ ì´ˆê¸° ë°ì´í„°: 800,000í–‰
ğŸ“‹ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„: 800,000í–‰
ğŸ“‹ ì¤‘ë³µ ì œê±° í›„: 800,000í–‰
ğŸ“‹ ë¡œì§ ìˆ˜ì • í›„: 800,000í–‰
ğŸ“‹ ìµœì í™” í›„: 800,000í–‰

âœ… ìµœì¢… ì •ì œ ë°ì´í„°: 800,000í–‰ x 29ì—´

â° Phase 2 ì‹¤í–‰ ì‹œê°„: 15.7ì´ˆ
âœ… Phase 2 ì™„ë£Œ! Phase 3 (EDA)ë¡œ ì§„í–‰ ê°€ëŠ¥
```

## Phase 3: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)

### 1. í”Œë ˆì´ì–´ í–‰ë™ íŠ¹ì„± ë¶„ë¥˜ ë° ê¸°ë³¸ ë¶„ì„
``` python

print("ğŸ“Š Phase 3: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘!")
print("="*60)

# 1. í”Œë ˆì´ì–´ í–‰ë™ íŠ¹ì„± ë¶„ë¥˜ ë° ê¸°ë³¸ ë¶„ì„

def categorize_player_features(df):
    """í”Œë ˆì´ì–´ í–‰ë™ íŠ¹ì„±ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    print("ğŸ¯ í”Œë ˆì´ì–´ í–‰ë™ íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜")
    print("-" * 40)

    # íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ì •ì˜
    feature_categories = {
        'Combat': ['kills', 'knockdowns', 'assists', 'damageDealt', 'longestKill',
                  'headshots', 'weaponsAcquired'],
        'Survival': ['heals', 'boosts', 'revives', 'teamKills', 'DBNOs'],
        'Movement': ['walkDistance', 'rideDistance', 'swimDistance'],
        'Interaction': ['vehicleDestroys', 'roadKills'],
        'Target': ['winPlacePerc'],
        'Meta': ['Id', 'groupId', 'matchId', 'matchType', 'numGroups', 'maxPlace', 'rankPoints']
    }

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    available_categories = {}
    for category, features in feature_categories.items():
        available_features = [f for f in features if f in df.columns]
        if available_features:
            available_categories[category] = available_features
            print(f"ğŸ“‹ {category:<12}: {len(available_features)}ê°œ íŠ¹ì„± - {', '.join(available_features[:3])}{'...' if len(available_features) > 3 else ''}")

    return available_categories

def basic_statistics_analysis(df, categories):
    """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„ ë¶„ì„")
    print("-" * 40)

    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    numeric_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId']]

    stats_summary = df[numeric_cols].describe().round(2)
    print("ğŸ“Š ì£¼ìš” í†µê³„ ì§€í‘œ:")
    print(stats_summary)

    # ì¹´í…Œê³ ë¦¬ë³„ í‰ê· ê°’
    print(f"\nğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ í‰ê· ê°’:")
    for category, features in categories.items():
        if category in ['Combat', 'Survival', 'Movement']:
            available_features = [f for f in features if f in numeric_cols]
            if available_features:
                category_mean = df[available_features].mean()
                print(f"\n{category} í‰ê· :")
                for feature in available_features:
                    print(f"  {feature:<15}: {category_mean[feature]:.2f}")

    return stats_summary
```

### 2. ê³ ê¸‰ ì‹œê°í™” í•¨ìˆ˜ë“¤
``` python
# 2. ê³ ê¸‰ ì‹œê°í™” í•¨ìˆ˜ë“¤

def create_target_distribution_plots(df):
    """íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ì‹œê°í™”"""
    print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (winPlacePerc) ë¶„í¬ ë¶„ì„")
    print("-" * 40)

    if 'winPlacePerc' not in df.columns:
        print("âŒ winPlacePerc ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Win Place Percentage Distribution Analysis', fontsize=16, fontweight='bold')

    # 1. íˆìŠ¤í† ê·¸ë¨
    axes[0,0].hist(df['winPlacePerc'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0,0].set_title('Histogram of Win Place Percentage')
    axes[0,0].set_xlabel('Win Place Percentage')
    axes[0,0].set_ylabel('Frequency')
    axes[0,0].grid(True, alpha=0.3)

    # 2. ë°•ìŠ¤ í”Œë¡¯
    axes[0,1].boxplot(df['winPlacePerc'], vert=True, patch_artist=True,
                     boxprops=dict(facecolor='lightcoral', alpha=0.7))
    axes[0,1].set_title('Box Plot of Win Place Percentage')
    axes[0,1].set_ylabel('Win Place Percentage')
    axes[0,1].grid(True, alpha=0.3)

    # 3. ëˆ„ì  ë¶„í¬
    sorted_data = np.sort(df['winPlacePerc'])
    y = np.arange(1, len(sorted_data) + 1) / len(sorted_data)
    axes[1,0].plot(sorted_data, y, linewidth=2, color='green')
    axes[1,0].set_title('Cumulative Distribution Function')
    axes[1,0].set_xlabel('Win Place Percentage')
    axes[1,0].set_ylabel('Cumulative Probability')
    axes[1,0].grid(True, alpha=0.3)

    # 4. ë°€ë„ í”Œë¡¯
    axes[1,1].hist(df['winPlacePerc'], bins=50, density=True, alpha=0.7,
                   color='orange', edgecolor='black', label='Histogram')
    # KDE ì¶”ê°€
    from scipy.stats import gaussian_kde
    kde = gaussian_kde(df['winPlacePerc'].dropna())
    x_range = np.linspace(0, 1, 100)
    axes[1,1].plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')
    axes[1,1].set_title('Probability Density Function')
    axes[1,1].set_xlabel('Win Place Percentage')
    axes[1,1].set_ylabel('Density')
    axes[1,1].legend()
    axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # ê¸°ë³¸ í†µê³„
    print(f"ğŸ“Š winPlacePerc ê¸°ë³¸ í†µê³„:")
    print(f"  í‰ê· : {df['winPlacePerc'].mean():.3f}")
    print(f"  ì¤‘ì•™ê°’: {df['winPlacePerc'].median():.3f}")
    print(f"  í‘œì¤€í¸ì°¨: {df['winPlacePerc'].std():.3f}")
    print(f"  ì™œë„: {df['winPlacePerc'].skew():.3f}")
    print(f"  ì²¨ë„: {df['winPlacePerc'].kurtosis():.3f}")

def create_combat_analysis_plots(df, categories):
    """ì „íˆ¬ ê´€ë ¨ íŠ¹ì„± ë¶„ì„"""
    print(f"\nâš”ï¸ ì „íˆ¬ í–‰ë™ íŠ¹ì„± ë¶„ì„")
    print("-" * 40)

    combat_features = categories.get('Combat', [])
    available_combat = [f for f in combat_features if f in df.columns][:6]  # ìƒìœ„ 6ê°œë§Œ

    if len(available_combat) < 2:
        print("âŒ ë¶„ì„í•  ì „íˆ¬ íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    # 2x3 ì„œë¸Œí”Œë¡¯
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Combat Behavior Analysis', fontsize=16, fontweight='bold')

    for i, feature in enumerate(available_combat):
        row, col = i // 3, i % 3

        # íˆìŠ¤í† ê·¸ë¨ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        data = df[feature][df[feature] > 0]  # 0ë³´ë‹¤ í° ê°’ë§Œ
        if len(data) > 0:
            axes[row, col].hist(data, bins=50, alpha=0.7, color=plt.cm.Set3(i), edgecolor='black')
            axes[row, col].set_title(f'{feature} Distribution (>0)')
            axes[row, col].set_xlabel(feature)
            axes[row, col].set_ylabel('Frequency')

            # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš© (ê·¹ë‹¨ê°’ì´ ë§ì€ ê²½ìš°)
            if data.max() / data.mean() > 10:
                axes[row, col].set_yscale('log')
                axes[row, col].set_title(f'{feature} Distribution (Log Scale)')

        axes[row, col].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # ì „íˆ¬ íŠ¹ì„± ìƒê´€ê´€ê³„
    if len(available_combat) >= 2:
        combat_corr = df[available_combat].corr()

        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(combat_corr, dtype=bool))
        sns.heatmap(combat_corr, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, fmt='.2f', cbar_kws={"shrink": .8})
        plt.title('Combat Features Correlation Matrix', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.show()

def create_performance_group_analysis(df):
    """ì„±ê³¼ ê·¸ë£¹ë³„ í–‰ë™ íŒ¨í„´ ë¶„ì„"""
    print(f"\nğŸ† ì„±ê³¼ ê·¸ë£¹ë³„ í–‰ë™ íŒ¨í„´ ë¶„ì„")
    print("-" * 40)

    if 'winPlacePerc' not in df.columns:
        print("âŒ winPlacePerc ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì„±ê³¼ ê·¸ë£¹ ìƒì„±
    df_analysis = df.copy()
    df_analysis['performance_group'] = pd.cut(df_analysis['winPlacePerc'],
                                            bins=[0, 0.2, 0.5, 0.8, 1.0],
                                            labels=['Low (0-20%)', 'Medium (20-50%)',
                                                   'High (50-80%)', 'Top (80-100%)'])

    # ê·¸ë£¹ë³„ ë¶„í¬
    group_counts = df_analysis['performance_group'].value_counts()
    print("ğŸ“Š ì„±ê³¼ ê·¸ë£¹ ë¶„í¬:")
    for group, count in group_counts.items():
        pct = (count / len(df_analysis)) * 100
        print(f"  {group}: {count:,}ëª… ({pct:.1f}%)")

    # ì£¼ìš” íŠ¹ì„±ë³„ ê·¸ë£¹ ë¹„êµ
    key_features = ['kills', 'damageDealt', 'walkDistance', 'heals', 'boosts']
    available_features = [f for f in key_features if f in df.columns]

    if available_features:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Performance Group Comparison', fontsize=16, fontweight='bold')

        for i, feature in enumerate(available_features[:6]):
            row, col = i // 3, i % 3

            # ë°•ìŠ¤ í”Œë¡¯
            df_analysis.boxplot(column=feature, by='performance_group', ax=axes[row, col])
            axes[row, col].set_title(f'{feature} by Performance Group')
            axes[row, col].set_xlabel('Performance Group')
            axes[row, col].set_ylabel(feature)
            axes[row, col].tick_params(axis='x', rotation=45)

        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for i in range(len(available_features), 6):
            row, col = i // 3, i % 3
            axes[row, col].set_visible(False)

        plt.tight_layout()
        plt.show()

    # ê·¸ë£¹ë³„ í‰ê·  ë¹„êµ í…Œì´ë¸”
    if available_features:
        group_means = df_analysis.groupby('performance_group')[available_features].mean()
        print(f"\nğŸ“‹ ì„±ê³¼ ê·¸ë£¹ë³„ í‰ê·  ë¹„êµ:")
        print(group_means.round(2))

    return df_analysis

def create_correlation_heatmap(df, categories):
    """ì „ì²´ íŠ¹ì„± ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"""
    print(f"\nğŸ”— íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
    print("-" * 40)

    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ (ID ì»¬ëŸ¼ ì œì™¸)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    analysis_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', 'rankPoints']]

    if len(analysis_cols) < 2:
        print("âŒ ë¶„ì„í•  ìˆ˜ì¹˜í˜• íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlation_matrix = df[analysis_cols].corr()

    # í° íˆíŠ¸ë§µ ìƒì„±
    plt.figure(figsize=(16, 14))

    # ë§ˆìŠ¤í¬ ìƒì„± (ìƒì‚¼ê° ìˆ¨ê¸°ê¸°)
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

    # íˆíŠ¸ë§µ ìƒì„±
    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,
                square=True, fmt='.2f', cbar_kws={"shrink": .8},
                annot_kws={'size': 8})

    plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # ê°•í•œ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ ì°¾ê¸°
    strong_correlations = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.7:  # ê°•í•œ ìƒê´€ê´€ê³„ ê¸°ì¤€
                strong_correlations.append({
                    'feature1': correlation_matrix.columns[i],
                    'feature2': correlation_matrix.columns[j],
                    'correlation': corr_value
                })

    if strong_correlations:
        print(f"\nğŸ’ª ê°•í•œ ìƒê´€ê´€ê³„ (|r| > 0.7) íŠ¹ì„± ìŒ:")
        for item in sorted(strong_correlations, key=lambda x: abs(x['correlation']), reverse=True):
            print(f"  {item['feature1']} â†” {item['feature2']}: {item['correlation']:.3f}")

    return correlation_matrix
```
### 3. ê³ ê¸‰ ì‹œê°í™” - ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯
``` python
# 3. ê³ ê¸‰ ì‹œê°í™” - ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯

def create_interactive_scatter_plots(df):
    """ì¸í„°ë™í‹°ë¸Œ ì‚°ì ë„ ìƒì„±"""
    print(f"\nğŸ¨ ì¸í„°ë™í‹°ë¸Œ ì‚°ì ë„ ìƒì„±")
    print("-" * 40)

    if 'winPlacePerc' not in df.columns:
        print("âŒ winPlacePerc ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì£¼ìš” íŠ¹ì„± ì„ íƒ
    key_features = ['kills', 'damageDealt', 'walkDistance', 'heals']
    available_features = [f for f in key_features if f in df.columns]

    if len(available_features) < 2:
        print("âŒ ë¶„ì„í•  íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    # ìƒ˜í”Œë§ (ì„±ëŠ¥ì„ ìœ„í•´)
    sample_size = min(10000, len(df))
    df_sample = df.sample(n=sample_size, random_state=42)

    # Plotly ì‚°ì ë„
    for i, feature in enumerate(available_features[:3]):  # ìƒìœ„ 3ê°œë§Œ
        fig = px.scatter(
            df_sample,
            x=feature,
            y='winPlacePerc',
            color='winPlacePerc',
            title=f'{feature} vs Win Place Percentage',
            labels={feature: feature, 'winPlacePerc': 'Win Place Percentage'},
            color_continuous_scale='viridis',
            opacity=0.6
        )

        fig.update_layout(
            width=800,
            height=600,
            title_font_size=16
        )

        fig.show()

def create_feature_distribution_comparison(df):
    """íŠ¹ì„± ë¶„í¬ ë¹„êµ (ìƒìœ„ vs í•˜ìœ„ ì„±ëŠ¥)"""
    print(f"\nğŸ“Š ìƒìœ„/í•˜ìœ„ ì„±ëŠ¥ì íŠ¹ì„± ë¶„í¬ ë¹„êµ")
    print("-" * 40)

    if 'winPlacePerc' not in df.columns:
        print("âŒ winPlacePerc ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìƒìœ„ 10%ì™€ í•˜ìœ„ 10% ë¶„ë¦¬
    top_players = df[df['winPlacePerc'] >= df['winPlacePerc'].quantile(0.9)]
    bottom_players = df[df['winPlacePerc'] <= df['winPlacePerc'].quantile(0.1)]

    print(f"ğŸ” ìƒìœ„ 10%: {len(top_players):,}ëª…")
    print(f"ğŸ”» í•˜ìœ„ 10%: {len(bottom_players):,}ëª…")

    # ì£¼ìš” íŠ¹ì„± ë¹„êµ
    key_features = ['kills', 'damageDealt', 'walkDistance', 'heals', 'boosts', 'weaponsAcquired']
    available_features = [f for f in key_features if f in df.columns]

    if available_features:
        # ë¹„êµ í…Œì´ë¸” ìƒì„±
        comparison_stats = pd.DataFrame({
            'Top_10%_Mean': top_players[available_features].mean(),
            'Bottom_10%_Mean': bottom_players[available_features].mean(),
            'Top_10%_Median': top_players[available_features].median(),
            'Bottom_10%_Median': bottom_players[available_features].median()
        })

        comparison_stats['Ratio_Mean'] = comparison_stats['Top_10%_Mean'] / comparison_stats['Bottom_10%_Mean']
        comparison_stats = comparison_stats.round(3)

        print(f"\nğŸ“‹ ìƒìœ„/í•˜ìœ„ 10% ì„±ëŠ¥ì íŠ¹ì„± ë¹„êµ:")
        print(comparison_stats)

        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Top 10% vs Bottom 10% Players Feature Comparison', fontsize=16, fontweight='bold')

        for i, feature in enumerate(available_features[:6]):
            row, col = i // 3, i % 3

            # íˆìŠ¤í† ê·¸ë¨ ì˜¤ë²„ë ˆì´
            axes[row, col].hist(bottom_players[feature], bins=30, alpha=0.5,
                               label='Bottom 10%', color='red', density=True)
            axes[row, col].hist(top_players[feature], bins=30, alpha=0.5,
                               label='Top 10%', color='blue', density=True)

            axes[row, col].set_title(f'{feature} Distribution')
            axes[row, col].set_xlabel(feature)
            axes[row, col].set_ylabel('Density')
            axes[row, col].legend()
            axes[row, col].grid(True, alpha=0.3)

        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for i in range(len(available_features), 6):
            row, col = i // 3, i % 3
            axes[row, col].set_visible(False)

        plt.tight_layout()
        plt.show()

    return top_players, bottom_players, comparison_stats
```
### 4. ì¢…í•© EDA íŒŒì´í”„ë¼ì¸
``` python
# 4. ì¢…í•© EDA íŒŒì´í”„ë¼ì¸

def comprehensive_eda_pipeline(df):
    """ì¢…í•©ì ì¸ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹¤í–‰"""
    print("ğŸš€ ì¢…í•© íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘")
    print("="*60)

    start_time = time.time()
    eda_results = {}

    # 1. íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    print(f"\n{'='*20} 1ë‹¨ê³„: íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ {'='*20}")
    categories = categorize_player_features(df)
    eda_results['categories'] = categories

    # 2. ê¸°ë³¸ í†µê³„ ë¶„ì„
    print(f"\n{'='*20} 2ë‹¨ê³„: ê¸°ë³¸ í†µê³„ ë¶„ì„ {'='*20}")
    stats_summary = basic_statistics_analysis(df, categories)
    eda_results['basic_stats'] = stats_summary

    # 3. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„
    print(f"\n{'='*20} 3ë‹¨ê³„: íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„ {'='*20}")
    create_target_distribution_plots(df)

    # 4. ì „íˆ¬ í–‰ë™ ë¶„ì„
    print(f"\n{'='*20} 4ë‹¨ê³„: ì „íˆ¬ í–‰ë™ ë¶„ì„ {'='*20}")
    create_combat_analysis_plots(df, categories)

    # 5. ì„±ê³¼ ê·¸ë£¹ë³„ ë¶„ì„
    print(f"\n{'='*20} 5ë‹¨ê³„: ì„±ê³¼ ê·¸ë£¹ë³„ ë¶„ì„ {'='*20}")
    df_with_groups = create_performance_group_analysis(df)
    eda_results['performance_groups'] = df_with_groups

    # 6. ìƒê´€ê´€ê³„ ë¶„ì„
    print(f"\n{'='*20} 6ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„ {'='*20}")
    correlation_matrix = create_correlation_heatmap(df, categories)
    eda_results['correlation_matrix'] = correlation_matrix

    # 7. ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
    print(f"\n{'='*20} 7ë‹¨ê³„: ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™” {'='*20}")
    create_interactive_scatter_plots(df)

    # 8. ì„±ëŠ¥ ë¹„êµ ë¶„ì„
    print(f"\n{'='*20} 8ë‹¨ê³„: ì„±ëŠ¥ ë¹„êµ ë¶„ì„ {'='*20}")
    top_players, bottom_players, comparison_stats = create_feature_distribution_comparison(df)
    eda_results['performance_comparison'] = {
        'top_players': top_players,
        'bottom_players': bottom_players,
        'comparison_stats': comparison_stats
    }

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    execution_time = time.time() - start_time

    print(f"\n{'='*20} EDA ì™„ë£Œ ìš”ì•½ {'='*20}")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"ğŸ“Š ë¶„ì„ëœ íŠ¹ì„± ìˆ˜: {len([col for col in df.select_dtypes(include=[np.number]).columns if col not in ['Id', 'groupId', 'matchId']])}")
    print(f"ğŸ¯ ì„±ê³¼ ê·¸ë£¹: 4ê°œ (Low, Medium, High, Top)")
    print(f"âœ… Phase 3 ì™„ë£Œ! Phase 4 (íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return eda_results
```
### 5. ì‹¤í–‰ í•¨ìˆ˜
``` python
# 5. ì‹¤í–‰ í•¨ìˆ˜

def run_phase3_pipeline(df_cleaned):
    """Phase 3 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("ğŸ® PUBG Phase 3: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘!")
    print("="*60)

    # ë©”ëª¨ë¦¬ í™•ì¸
    check_memory_usage()

    # ì¢…í•© EDA ì‹¤í–‰
    eda_results = comprehensive_eda_pipeline(df_cleaned)

    return eda_results

# ì‹¤í–‰ ì˜ˆì‹œ
print("\nğŸ“‹ Phase 3 ì‹¤í–‰ ë°©ë²•:")
print("="*40)
print("# Phase 2ì—ì„œ ì •ì œëœ ë°ì´í„° ì‚¬ìš©")
print("eda_results = run_phase3_pipeline(df_cleaned)")
print()
print("# ê²°ê³¼ í™•ì¸")
print("print('EDA ê²°ê³¼:', list(eda_results.keys()))")

print("\nğŸ¯ Phase 3 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: Phase 4 - íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
```
#### 5. ì‹¤í–‰ í•¨ìˆ˜ ê²°ê³¼

``` bash
ğŸ“‹ Phase 3 ì‹¤í–‰ ë°©ë²•:
========================================
# Phase 2ì—ì„œ ì •ì œëœ ë°ì´í„° ì‚¬ìš©
eda_results = run_phase3_pipeline(df_cleaned)

# ê²°ê³¼ í™•ì¸
print('EDA ê²°ê³¼:', list(eda_results.keys()))

ğŸ¯ Phase 3 ì¤€ë¹„ ì™„ë£Œ!
ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: Phase 4 - íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
```

### ì‹¤í–‰
``` python
# Phase 2ì—ì„œ ì •ì œëœ ë°ì´í„°ë¡œ EDA ì‹¤í–‰
eda_results = run_phase3_pipeline(df_cleaned)

# ê²°ê³¼ í™•ì¸
print('EDA ê²°ê³¼:', list(eda_results.keys()))
```
#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ® PUBG Phase 3: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘!
============================================================
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 28.6% (3.3GB / 12.7GB)
ğŸš€ ì¢…í•© íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘
============================================================

==================== 1ë‹¨ê³„: íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ====================
ğŸ¯ í”Œë ˆì´ì–´ í–‰ë™ íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
----------------------------------------
ğŸ“‹ Combat      : 5ê°œ íŠ¹ì„± - kills, assists, damageDealt...
ğŸ“‹ Survival    : 5ê°œ íŠ¹ì„± - heals, boosts, revives...
ğŸ“‹ Movement    : 3ê°œ íŠ¹ì„± - walkDistance, rideDistance, swimDistance
ğŸ“‹ Interaction : 2ê°œ íŠ¹ì„± - vehicleDestroys, roadKills
ğŸ“‹ Target      : 1ê°œ íŠ¹ì„± - winPlacePerc
ğŸ“‹ Meta        : 7ê°œ íŠ¹ì„± - Id, groupId, matchId...
```

``` bash
==================== 2ë‹¨ê³„: ê¸°ë³¸ í†µê³„ ë¶„ì„ ====================

ğŸ“ˆ ê¸°ë³¸ í†µê³„ ë¶„ì„
----------------------------------------
ğŸ“Š ì£¼ìš” í†µê³„ ì§€í‘œ:
         assists     boosts  damageDealt      DBNOs  headshotKills      heals  \
count  800000.00  800000.00    800000.00  800000.00      800000.00  800000.00   
mean        0.23       1.10       129.19       0.66           0.23       1.37   
std         0.59       1.71       161.11       1.15           0.60       2.68   
min         0.00       0.00         0.00       0.00           0.00       0.00   
25%         0.00       0.00         0.00       0.00           0.00       0.00   
50%         0.00       0.00        84.00       0.00           0.00       0.00   
75%         0.00       2.00       185.80       1.00           0.00       2.00   
max        13.00      33.00       922.20      39.00          23.00      63.00   

       killPlace  killPoints      kills  killStreaks  ...    revives  \
count  800000.00   800000.00  800000.00    800000.00  ...  800000.00   
mean       47.64      504.77       0.91         0.54  ...       0.16   
std        27.47      627.37       1.46         0.71  ...       0.47   
min         1.00        0.00       0.00         0.00  ...       0.00   
25%        24.00        0.00       0.00         0.00  ...       0.00   
50%        47.00        0.00       0.00         0.00  ...       0.00   
75%        71.00     1171.00       1.00         1.00  ...       0.00   
max       100.00     2170.00       8.00        18.00  ...      23.00   

       rideDistance  roadKills  swimDistance  teamKills  vehicleDestroys  \
count     800000.00  800000.00     800000.00  800000.00        800000.00   
mean         596.45       0.00          4.50       0.02             0.01   
std         1445.07       0.08         30.65       0.17             0.09   
min            0.00       0.00          0.00       0.00             0.00   
25%            0.00       0.00          0.00       0.00             0.00   
50%            0.00       0.00          0.00       0.00             0.00   
75%            0.14       0.00          0.00       0.00             0.00   
max         8068.00      18.00       3823.00       4.00             4.00   

       walkDistance  weaponsAcquired  winPoints  winPlacePerc  
count     800000.00        800000.00  800000.00     800000.00  
mean        1147.40             3.66     606.26          0.47  
std         1164.22             2.46     739.67          0.31  
min            0.00             0.00       0.00          0.00  
25%          154.80             2.00       0.00          0.20  
50%          682.60             3.00       0.00          0.46  
75%         1971.00             5.00    1495.00          0.74  
max         4835.00           153.00    2013.00          1.00  

[8 rows x 25 columns]

ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ í‰ê· ê°’:

Combat í‰ê· :
  kills          : 0.91
  assists        : 0.23
  damageDealt    : 129.19
  longestKill    : 22.95
  weaponsAcquired: 3.66

Survival í‰ê· :
  heals          : 1.37
  boosts         : 1.10
  revives        : 0.16
  teamKills      : 0.02
  DBNOs          : 0.66

Movement í‰ê· :
  walkDistance   : 1147.40
  rideDistance   : 596.45
  swimDistance   : 4.50
```

``` bash
==================== 3ë‹¨ê³„: íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„ ====================

ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (winPlacePerc) ë¶„í¬ ë¶„ì„
----------------------------------------
```

![Screenshot](image/3ë‹¨ê³„_íƒ€ê²Ÿ_ë³€ìˆ˜_ë¶„í¬_ë¶„ì„.png)

``` bash
ğŸ“Š winPlacePerc ê¸°ë³¸ í†µê³„:
  í‰ê· : 0.473
  ì¤‘ì•™ê°’: 0.458
  í‘œì¤€í¸ì°¨: 0.307
  ì™œë„: 0.100
  ì²¨ë„: -1.245
```

``` bash
==================== 4ë‹¨ê³„: ì „íˆ¬ í–‰ë™ ë¶„ì„ ====================

âš”ï¸ ì „íˆ¬ í–‰ë™ íŠ¹ì„± ë¶„ì„
----------------------------------------
```

![Screenshot](image/4ë‹¨ê³„_ì „íˆ¬_í–‰ë™_ë¶„ì„.png)
![Screenshot](image/4ë‹¨ê³„_ì „íˆ¬_í–‰ë™_ë¶„ì„2.png)

``` bash
==================== 5ë‹¨ê³„: ì„±ê³¼ ê·¸ë£¹ë³„ ë¶„ì„ ====================

ğŸ† ì„±ê³¼ ê·¸ë£¹ë³„ í–‰ë™ íŒ¨í„´ ë¶„ì„
----------------------------------------
ğŸ“Š ì„±ê³¼ ê·¸ë£¹ ë¶„í¬:
  Medium (20-50%): 236,390ëª… (29.5%)
  High (50-80%): 203,204ëª… (25.4%)
  Top (80-100%): 161,073ëª… (20.1%)
  Low (0-20%): 159,570ëª… (19.9%)
```

![Screenshot](image/5ë‹¨ê³„_ì„±ê³¼_ê·¸ë£¹ë³„_ë¶„ì„.png)

``` bash
ğŸ“‹ ì„±ê³¼ ê·¸ë£¹ë³„ í‰ê·  ë¹„êµ:
                   kills  damageDealt  walkDistance  heals  boosts
performance_group                                                 
Low (0-20%)         0.29    56.910000    143.429993   0.13    0.07
Medium (20-50%)     0.59    94.580002    550.049988   0.69    0.40
High (50-80%)       1.00   142.610001   1659.219971   1.96    1.40
Top (80-100%)       2.06   259.019989   2645.280029   3.17    3.06
```

``` bash
==================== 6ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„ ====================

ğŸ”— íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
----------------------------------------
```

![Screenshot](image/6ë‹¨ê³„_ìƒê´€ê´€ê³„_ë¶„ì„.png)

``` bash
ğŸ’ª ê°•í•œ ìƒê´€ê´€ê³„ (|r| > 0.7) íŠ¹ì„± ìŒ:
  maxPlace â†” numGroups: 0.998
  killPoints â†” winPoints: 0.983
  damageDealt â†” kills: 0.881
  kills â†” killStreaks: 0.829
  walkDistance â†” winPlacePerc: 0.818
  killPlace â†” killStreaks: -0.810
  killPlace â†” kills: -0.765
  damageDealt â†” DBNOs: 0.735
  damageDealt â†” killStreaks: 0.720
  killPlace â†” winPlacePerc: -0.719
  DBNOs â†” kills: 0.712
  damageDealt â†” killPlace: -0.702
```

``` bash
==================== 7ë‹¨ê³„: ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™” ====================

ğŸ¨ ì¸í„°ë™í‹°ë¸Œ ì‚°ì ë„ ìƒì„±
----------------------------------------
```

``` bash
==================== 8ë‹¨ê³„: ì„±ëŠ¥ ë¹„êµ ë¶„ì„ ====================

ğŸ“Š ìƒìœ„/í•˜ìœ„ ì„±ëŠ¥ì íŠ¹ì„± ë¶„í¬ ë¹„êµ
----------------------------------------
ğŸ” ìƒìœ„ 10%: 80,687ëª…
ğŸ”» í•˜ìœ„ 10%: 80,133ëª…

ğŸ“‹ ìƒìœ„/í•˜ìœ„ 10% ì„±ëŠ¥ì íŠ¹ì„± ë¹„êµ:
                 Top_10%_Mean  Bottom_10%_Mean  Top_10%_Median  \
kills                   2.550            0.142             2.0   
damageDealt           312.465           35.800           261.3   
walkDistance         2800.155           58.581          2838.0   
heals                   3.377            0.032             2.0   
boosts                  3.574            0.016             3.0   
weaponsAcquired         5.491            1.107             5.0   

                 Bottom_10%_Median  Ratio_Mean  
kills                         0.00      17.944  
damageDealt                   0.00       8.728  
walkDistance                 31.02      47.799  
heals                         0.00     106.946  
boosts                        0.00     220.502  
weaponsAcquired               1.00       4.960  
```

![Screenshot](image/8ë‹¨ê³„_ì„±ëŠ¥_ë¹„êµ_ë¶„ì„.png)

``` bash
==================== EDA ì™„ë£Œ ìš”ì•½ ====================
â° ì‹¤í–‰ ì‹œê°„: 17.8ì´ˆ
ğŸ“Š ë¶„ì„ëœ íŠ¹ì„± ìˆ˜: 25
ğŸ¯ ì„±ê³¼ ê·¸ë£¹: 4ê°œ (Low, Medium, High, Top)
âœ… Phase 3 ì™„ë£Œ! Phase 4 (íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§)ë¡œ ì§„í–‰ ê°€ëŠ¥
EDA ê²°ê³¼: ['categories', 'basic_stats', 'performance_groups', 'correlation_matrix', 'performance_comparison']
```

## Phase 4: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)

### 0. ì§„í–‰ë„ ì¶”ì  ì‹œìŠ¤í…œ

``` python

print("ğŸ”§ Phase 4: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘!")
print("="*60)

import time
from datetime import datetime

class ProgressTracker:
    """ì§„í–‰ë„ ì¶”ì  í´ë˜ìŠ¤"""

    def __init__(self, total_steps, description="Processing"):
        self.total_steps = total_steps
        self.current_step = 0
        self.description = description
        self.start_time = time.time()
        self.step_times = []

    def update(self, step_name="", details=""):
        """ì§„í–‰ë„ ì—…ë°ì´íŠ¸"""
        self.current_step += 1
        current_time = time.time()
        elapsed = current_time - self.start_time

        if len(self.step_times) > 0:
            avg_step_time = sum(self.step_times) / len(self.step_times)
            remaining_steps = self.total_steps - self.current_step
            eta = remaining_steps * avg_step_time
            eta_str = f"ETA: {eta:.0f}ì´ˆ"
        else:
            eta_str = "ETA: ê³„ì‚°ì¤‘..."

        progress_pct = (self.current_step / self.total_steps) * 100
        progress_bar = "â–ˆ" * int(progress_pct // 5) + "â–‘" * (20 - int(progress_pct // 5))

        step_time = elapsed - sum(self.step_times) if self.step_times else elapsed
        self.step_times.append(step_time)

        print(f"\r[{progress_bar}] {progress_pct:.1f}% | {self.current_step}/{self.total_steps} | "
              f"{step_name} | {details} | {eta_str} | ê²½ê³¼: {elapsed:.0f}ì´ˆ", end="")

        if self.current_step == self.total_steps:
            print(f"\nâœ… ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")

def show_memory_progress():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ"""
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB)")
    except:
        print("ğŸ’¾ ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ë¶ˆê°€")
```
### 1. íŒŒìƒ íŠ¹ì„± ìƒì„± í•¨ìˆ˜ë“¤
``` python
def create_efficiency_features(df):
    """íš¨ìœ¨ì„± ì§€í‘œ íŠ¹ì„± ìƒì„±"""
    print("âš¡ íš¨ìœ¨ì„± ì§€í‘œ íŠ¹ì„± ìƒì„±")
    print("-" * 40)

    df_enhanced = df.copy()
    new_features = []

    # 1. í‚¬ íš¨ìœ¨ì„± ì§€í‘œ
    if 'kills' in df.columns and 'damageDealt' in df.columns:
        # ë°ë¯¸ì§€ë‹¹ í‚¬ ìˆ˜ (í‚¬ íš¨ìœ¨ì„±)
        df_enhanced['kill_efficiency'] = df_enhanced['kills'] / (df_enhanced['damageDealt'] + 1)
        new_features.append('kill_efficiency')

        # í‚¬ë‹¹ í‰ê·  ë°ë¯¸ì§€
        df_enhanced['damage_per_kill'] = df_enhanced['damageDealt'] / (df_enhanced['kills'] + 1)
        new_features.append('damage_per_kill')

    # 2. ì´ë™ íš¨ìœ¨ì„± ì§€í‘œ
    distance_cols = ['walkDistance', 'rideDistance', 'swimDistance']
    available_distance = [col for col in distance_cols if col in df.columns]

    if len(available_distance) >= 2:
        # ì´ ì´ë™ ê±°ë¦¬
        df_enhanced['total_distance'] = df_enhanced[available_distance].sum(axis=1)
        new_features.append('total_distance')

        # ì´ë™ ê±°ë¦¬ë‹¹ í‚¬ ìˆ˜
        if 'kills' in df.columns:
            df_enhanced['kills_per_distance'] = df_enhanced['kills'] / (df_enhanced['total_distance'] + 1)
            new_features.append('kills_per_distance')

        # ì´ë™ ê±°ë¦¬ë‹¹ ë°ë¯¸ì§€
        if 'damageDealt' in df.columns:
            df_enhanced['damage_per_distance'] = df_enhanced['damageDealt'] / (df_enhanced['total_distance'] + 1)
            new_features.append('damage_per_distance')

    # 3. ìƒì¡´ íš¨ìœ¨ì„± ì§€í‘œ
    survival_cols = ['heals', 'boosts']
    available_survival = [col for col in survival_cols if col in df.columns]

    if len(available_survival) >= 2:
        # ì´ ìƒì¡´ ì•„ì´í…œ ì‚¬ìš©
        df_enhanced['total_heals'] = df_enhanced[available_survival].sum(axis=1)
        new_features.append('total_heals')

        # ìƒì¡´ ì•„ì´í…œë‹¹ ìƒì¡´ ì‹œê°„ (ëŒ€ë¦¬ ì§€í‘œ)
        if 'total_distance' in df_enhanced.columns:
            df_enhanced['heal_efficiency'] = df_enhanced['total_distance'] / (df_enhanced['total_heals'] + 1)
            new_features.append('heal_efficiency')

    # 4. ì „íˆ¬ ì°¸ì—¬ë„
    combat_cols = ['kills', 'assists', 'knockdowns']
    available_combat = [col for col in combat_cols if col in df.columns]

    if len(available_combat) >= 2:
        # ì´ ì „íˆ¬ ì°¸ì—¬
        df_enhanced['total_combat'] = df_enhanced[available_combat].sum(axis=1)
        new_features.append('total_combat')

        # ì „íˆ¬ ì°¸ì—¬ ë¹„ìœ¨
        if 'kills' in df.columns:
            df_enhanced['kill_participation'] = df_enhanced['kills'] / (df_enhanced['total_combat'] + 1)
            new_features.append('kill_participation')

    print(f"âœ… ìƒì„±ëœ íš¨ìœ¨ì„± íŠ¹ì„±: {len(new_features)}ê°œ")
    for feature in new_features:
        print(f"  ğŸ“Š {feature}")

    return df_enhanced, new_features

def create_ratio_features(df):
    """ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì„± ìƒì„±"""
    print("\nğŸ“Š ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì„± ìƒì„±")
    print("-" * 40)

    df_enhanced = df.copy()
    new_features = []

    # 1. í—¤ë“œìƒ· ë¹„ìœ¨
    if 'headshots' in df.columns and 'kills' in df.columns:
        df_enhanced['headshot_rate'] = df_enhanced['headshots'] / (df_enhanced['kills'] + 1)
        new_features.append('headshot_rate')

    # 2. ì–´ì‹œìŠ¤íŠ¸ ë¹„ìœ¨
    if 'assists' in df.columns and 'kills' in df.columns:
        df_enhanced['assist_rate'] = df_enhanced['assists'] / (df_enhanced['kills'] + df_enhanced['assists'] + 1)
        new_features.append('assist_rate')

    # 3. ì´ë™ ë°©ì‹ ë¹„ìœ¨
    distance_cols = ['walkDistance', 'rideDistance', 'swimDistance']
    available_distance = [col for col in distance_cols if col in df.columns]

    if 'total_distance' in df_enhanced.columns:
        for col in available_distance:
            ratio_name = f'{col}_ratio'
            df_enhanced[ratio_name] = df_enhanced[col] / (df_enhanced['total_distance'] + 1)
            new_features.append(ratio_name)

    # 4. ìƒì¡´ ì•„ì´í…œ ë¹„ìœ¨
    if 'heals' in df.columns and 'boosts' in df.columns:
        df_enhanced['heal_boost_ratio'] = df_enhanced['heals'] / (df_enhanced['heals'] + df_enhanced['boosts'] + 1)
        new_features.append('heal_boost_ratio')

    # 5. ë¬´ê¸° ìŠµë“ íš¨ìœ¨ì„±
    if 'weaponsAcquired' in df.columns and 'kills' in df.columns:
        df_enhanced['weapons_per_kill'] = df_enhanced['weaponsAcquired'] / (df_enhanced['kills'] + 1)
        new_features.append('weapons_per_kill')

    print(f"âœ… ìƒì„±ëœ ë¹„ìœ¨ íŠ¹ì„±: {len(new_features)}ê°œ")
    for feature in new_features:
        print(f"  ğŸ“Š {feature}")

    return df_enhanced, new_features

def create_game_style_features(df):
    """ê²Œì„ ìŠ¤íƒ€ì¼ ì§€í‘œ ìƒì„±"""
    print("\nğŸ® ê²Œì„ ìŠ¤íƒ€ì¼ ì§€í‘œ ìƒì„±")
    print("-" * 40)

    df_enhanced = df.copy()
    new_features = []

    # 1. ê³µê²©ì„± ì§€í‘œ (Aggressiveness Score)
    combat_features = ['kills', 'damageDealt', 'longestKill']
    available_combat = [col for col in combat_features if col in df.columns]

    if len(available_combat) >= 2:
        # í‘œì¤€í™”ëœ ê³µê²©ì„± ì ìˆ˜
        combat_score = 0
        weights = {'kills': 0.4, 'damageDealt': 0.0001, 'longestKill': 0.01}  # ìŠ¤ì¼€ì¼ ì¡°ì •

        for feature in available_combat:
            if feature in weights:
                combat_score += df_enhanced[feature] * weights[feature]

        df_enhanced['aggressiveness_score'] = combat_score
        new_features.append('aggressiveness_score')

    # 2. ìƒì¡´ì„± ì§€í‘œ (Survival Score)
    survival_features = ['heals', 'boosts', 'revives']
    available_survival = [col for col in survival_features if col in df.columns]

    if len(available_survival) >= 2:
        survival_score = df_enhanced[available_survival].sum(axis=1)
        df_enhanced['survival_score'] = survival_score
        new_features.append('survival_score')

    # 3. ì´ë™ì„± ì§€í‘œ (Mobility Score)
    if 'total_distance' in df_enhanced.columns:
        # ì´ë™ ê±°ë¦¬ë¥¼ ë¡œê·¸ ë³€í™˜í•˜ì—¬ ìŠ¤ì½”ì–´í™”
        df_enhanced['mobility_score'] = np.log1p(df_enhanced['total_distance'])
        new_features.append('mobility_score')

    # 4. íŒ€í”Œë ˆì´ ì§€í‘œ (Teamplay Score)
    teamplay_features = ['assists', 'revives', 'teamKills']
    available_teamplay = [col for col in teamplay_features if col in df.columns]

    if len(available_teamplay) >= 2:
        # íŒ€í‚¬ì€ ìŒìˆ˜ë¡œ ì²˜ë¦¬ (í˜ë„í‹°)
        teamplay_score = df_enhanced[['assists', 'revives']].sum(axis=1) if 'assists' in df.columns and 'revives' in df.columns else 0
        if 'teamKills' in df.columns:
            teamplay_score -= df_enhanced['teamKills'] * 2  # íŒ€í‚¬ í˜ë„í‹°
        df_enhanced['teamplay_score'] = teamplay_score
        new_features.append('teamplay_score')

    # 5. ì¢…í•© í”Œë ˆì´ ìŠ¤íƒ€ì¼ (Composite Style)
    style_components = ['aggressiveness_score', 'survival_score', 'mobility_score']
    available_styles = [col for col in style_components if col in df_enhanced.columns]

    if len(available_styles) >= 2:
        # ê° ìŠ¤íƒ€ì¼ì˜ í‘œì¤€í™”ëœ í•©
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()

        style_matrix = scaler.fit_transform(df_enhanced[available_styles])
        df_enhanced['composite_style'] = np.mean(style_matrix, axis=1)
        new_features.append('composite_style')

    print(f"âœ… ìƒì„±ëœ ê²Œì„ ìŠ¤íƒ€ì¼ íŠ¹ì„±: {len(new_features)}ê°œ")
    for feature in new_features:
        print(f"  ğŸ¯ {feature}")

    return df_enhanced, new_features

def create_advanced_features(df):
    """ê³ ê¸‰ íŒŒìƒ íŠ¹ì„± ìƒì„±"""
    print("\nğŸš€ ê³ ê¸‰ íŒŒìƒ íŠ¹ì„± ìƒì„±")
    print("-" * 40)

    df_enhanced = df.copy()
    new_features = []

    # 1. í”Œë ˆì´ì–´ ìˆœìœ„ ê´€ë ¨ íŠ¹ì„±
    if 'numGroups' in df.columns and 'maxPlace' in df.columns:
        # ìƒëŒ€ì  ê·¸ë£¹ í¬ê¸°
        df_enhanced['relative_group_size'] = df_enhanced['maxPlace'] / df_enhanced['numGroups']
        new_features.append('relative_group_size')

        # ê²½ìŸ ê°•ë„ (ê·¸ë£¹ ìˆ˜ ëŒ€ë¹„ ìµœëŒ€ ìˆœìœ„)
        df_enhanced['competition_intensity'] = df_enhanced['numGroups'] / df_enhanced['maxPlace']
        new_features.append('competition_intensity')

    # 2. ìƒí˜¸ì‘ìš© íŠ¹ì„± (Feature Interactions)
    if 'kills' in df.columns and 'damageDealt' in df.columns:
        # í‚¬ê³¼ ë°ë¯¸ì§€ì˜ ìƒí˜¸ì‘ìš©
        df_enhanced['kill_damage_interaction'] = df_enhanced['kills'] * df_enhanced['damageDealt']
        new_features.append('kill_damage_interaction')

    # 3. ë¡œê·¸ ë³€í™˜ íŠ¹ì„± (ì¤‘ìš”í•œ íŠ¹ì„±ë“¤ì˜ ë¡œê·¸ ë³€í™˜)
    log_candidates = ['damageDealt', 'walkDistance', 'rideDistance']
    for feature in log_candidates:
        if feature in df.columns:
            log_feature_name = f'{feature}_log'
            df_enhanced[log_feature_name] = np.log1p(df_enhanced[feature])
            new_features.append(log_feature_name)

    # 4. ì´ì§„ íŠ¹ì„± (Binary Features)
    # íŠ¹ì • í–‰ë™ì„ í–ˆëŠ”ì§€ ì—¬ë¶€
    binary_candidates = ['kills', 'vehicleDestroys', 'roadKills', 'swimDistance']
    for feature in binary_candidates:
        if feature in df.columns:
            binary_feature_name = f'has_{feature}'
            df_enhanced[binary_feature_name] = (df_enhanced[feature] > 0).astype(int)
            new_features.append(binary_feature_name)

    # 5. êµ¬ê°„í™” íŠ¹ì„± (Binning)
    if 'kills' in df.columns:
        # í‚¬ ìˆ˜ë¥¼ êµ¬ê°„ë³„ë¡œ ë¶„ë¥˜
        df_enhanced['kill_category'] = pd.cut(df_enhanced['kills'],
                                            bins=[-1, 0, 2, 5, 10, float('inf')],
                                            labels=['No_Kill', 'Low_Kill', 'Medium_Kill', 'High_Kill', 'Very_High_Kill'])
        # ì›-í•« ì¸ì½”ë”©
        kill_dummies = pd.get_dummies(df_enhanced['kill_category'], prefix='kill_cat')
        df_enhanced = pd.concat([df_enhanced, kill_dummies], axis=1)
        new_features.extend(kill_dummies.columns.tolist())

    print(f"âœ… ìƒì„±ëœ ê³ ê¸‰ íŠ¹ì„±: {len(new_features)}ê°œ")
    for feature in new_features[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
        print(f"  ğŸ”¬ {feature}")
    if len(new_features) > 10:
        print(f"  ... ë° {len(new_features)-10}ê°œ ì¶”ê°€ íŠ¹ì„±")

    return df_enhanced, new_features
```
#### 1-1. ë¹ ë¥¸ ë²„ì „ íŠ¹ì„± ìƒì„± í•¨ìˆ˜ë“¤ (ì§„í–‰ë„ í‘œì‹œìš©)
``` python
print("\nğŸš€ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìµœì í™” í•¨ìˆ˜ë“¤")
print("-" * 50)

def create_efficiency_features_fast(df):
    """íš¨ìœ¨ì„± ì§€í‘œ íŠ¹ì„± ìƒì„± (ë¹ ë¥¸ ë²„ì „)"""
    df_enhanced = df.copy()
    new_features = []

    # í•µì‹¬ íŠ¹ì„±ë§Œ ìƒì„±
    if 'kills' in df.columns and 'damageDealt' in df.columns:
        df_enhanced['kill_efficiency'] = df_enhanced['kills'] / (df_enhanced['damageDealt'] + 1)
        df_enhanced['damage_per_kill'] = df_enhanced['damageDealt'] / (df_enhanced['kills'] + 1)
        new_features.extend(['kill_efficiency', 'damage_per_kill'])

    distance_cols = ['walkDistance', 'rideDistance', 'swimDistance']
    available_distance = [col for col in distance_cols if col in df.columns]
    if len(available_distance) >= 2:
        df_enhanced['total_distance'] = df_enhanced[available_distance].sum(axis=1)
        new_features.append('total_distance')

    return df_enhanced, new_features

def create_ratio_features_fast(df):
    """ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì„± ìƒì„± (ë¹ ë¥¸ ë²„ì „)"""
    df_enhanced = df.copy()
    new_features = []

    if 'heals' in df.columns and 'boosts' in df.columns:
        df_enhanced['total_heals'] = df_enhanced['heals'] + df_enhanced['boosts']
        df_enhanced['heal_boost_ratio'] = df_enhanced['heals'] / (df_enhanced['total_heals'] + 1)
        new_features.extend(['total_heals', 'heal_boost_ratio'])

    return df_enhanced, new_features

def create_game_style_features_fast(df):
    """ê²Œì„ ìŠ¤íƒ€ì¼ ì§€í‘œ ìƒì„± (ë¹ ë¥¸ ë²„ì „)"""
    df_enhanced = df.copy()
    new_features = []

    if 'kills' in df.columns and 'damageDealt' in df.columns:
        df_enhanced['aggressiveness_score'] = (
            df_enhanced['kills'] * 0.4 +
            df_enhanced['damageDealt'] * 0.001
        )
        new_features.append('aggressiveness_score')

    return df_enhanced, new_features

def create_advanced_features_fast(df):
    """ê³ ê¸‰ íŒŒìƒ íŠ¹ì„± ìƒì„± (ë¹ ë¥¸ ë²„ì „)"""
    df_enhanced = df.copy()
    new_features = []

    # ë¡œê·¸ ë³€í™˜
    log_candidates = ['damageDealt', 'walkDistance']
    for feature in log_candidates:
        if feature in df.columns:
            df_enhanced[f'{feature}_log'] = np.log1p(df_enhanced[feature])
            new_features.append(f'{feature}_log')

    # ì´ì§„ íŠ¹ì„±
    binary_candidates = ['kills', 'swimDistance']
    for feature in binary_candidates:
        if feature in df.columns:
            df_enhanced[f'has_{feature}'] = (df_enhanced[feature] > 0).astype(int)
            new_features.append(f'has_{feature}')

    return df_enhanced, new_features

print("âœ… ë¹ ë¥¸ ë²„ì „ íŠ¹ì„± ìƒì„± í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ!")
```
### 2. íŠ¹ì„± ì„ íƒ ë° í•„í„°ë§ í•¨ìˆ˜ë“¤
``` python
def detect_multicollinearity(df, threshold=0.95):
    """ë‹¤ì¤‘ê³µì„ ì„± íƒì§€ ë° ì œê±°"""
    print(f"\nğŸ”— ë‹¤ì¤‘ê³µì„ ì„± íƒì§€ (ì„ê³„ê°’: {threshold})")
    print("-" * 40)

    # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    analysis_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', 'winPlacePerc']]

    if len(analysis_cols) < 2:
        print("âŒ ë¶„ì„í•  íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return df, []

    # ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    corr_matrix = df[analysis_cols].corr().abs()

    # ìƒì‚¼ê° ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

    # ì œê±°í•  íŠ¹ì„± ì°¾ê¸°
    high_corr_features = []
    for column in upper_triangle.columns:
        if any(upper_triangle[column] > threshold):
            high_corr_features.append(column)

    print(f"ğŸ” ë†’ì€ ìƒê´€ê´€ê³„ ({threshold} ì´ìƒ) íŠ¹ì„± ìŒ:")
    removed_features = []

    for i, column in enumerate(upper_triangle.columns):
        correlated_features = upper_triangle.index[upper_triangle[column] > threshold].tolist()
        if correlated_features:
            print(f"  ğŸ“Š {column} â†” {correlated_features}")
            # ë” ë§ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ íŠ¹ì„± ì œê±°
            if column not in removed_features:
                removed_features.append(column)

    # ì¤‘ë³µ ì œê±°ëœ íŠ¹ì„±ë“¤ ì œê±°
    df_filtered = df.drop(columns=removed_features)

    print(f"ğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: {len(removed_features)}ê°œ")
    print(f"âœ… í•„í„°ë§ í›„ íŠ¹ì„± ìˆ˜: {df_filtered.shape[1]}ê°œ")

    return df_filtered, removed_features

def select_features_by_importance(df, target_col='winPlacePerc', method='random_forest', top_k=50):
    """íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ"""
    print(f"\nâ­ íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ ({method}, Top {top_k})")
    print("-" * 40)

    if target_col not in df.columns:
        print(f"âŒ íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_col}'ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df, []

    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    feature_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', target_col]]

    if len(feature_cols) < top_k:
        print(f"âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±({len(feature_cols)})ì´ ìš”ì²­ëœ ìˆ˜({top_k})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤.")
        top_k = len(feature_cols)

    X = df[feature_cols]
    y = df[target_col]

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    X = X.fillna(0)
    y = y.fillna(y.median())

    if method == 'random_forest':
        from sklearn.ensemble import RandomForestRegressor
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X, y)
        importances = model.feature_importances_

    elif method == 'mutual_info':
        from sklearn.feature_selection import mutual_info_regression
        importances = mutual_info_regression(X, y, random_state=42)

    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': importances
    }).sort_values('importance', ascending=False)

    # ìƒìœ„ íŠ¹ì„± ì„ íƒ
    top_features = feature_importance.head(top_k)['feature'].tolist()

    print(f"ğŸ“Š ìƒìœ„ {min(10, len(top_features))}ê°œ ì¤‘ìš” íŠ¹ì„±:")
    for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):
        print(f"  {i+1:2d}. {row['feature']:<25}: {row['importance']:.4f}")

    # ì„ íƒëœ íŠ¹ì„±ê³¼ ë©”íƒ€ ì»¬ëŸ¼ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
    meta_cols = ['Id', 'groupId', 'matchId', target_col]
    keep_cols = [col for col in meta_cols if col in df.columns] + top_features
    df_selected = df[keep_cols]

    print(f"âœ… ì„ íƒëœ íŠ¹ì„±: {len(top_features)}ê°œ")

    return df_selected, top_features

def handle_infinite_values(df):
    """ë¬´í•œê°’ ë° ê·¹ë‹¨ê°’ ì²˜ë¦¬"""
    print(f"\nâ™¾ï¸ ë¬´í•œê°’ ë° ê·¹ë‹¨ê°’ ì²˜ë¦¬")
    print("-" * 40)

    df_cleaned = df.copy()

    # ë¬´í•œê°’ íƒì§€
    numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns
    infinite_issues = {}

    for col in numeric_cols:
        inf_count = np.isinf(df_cleaned[col]).sum()
        if inf_count > 0:
            infinite_issues[col] = inf_count
            # ë¬´í•œê°’ì„ í•´ë‹¹ ì»¬ëŸ¼ì˜ ìµœëŒ€ê°’ìœ¼ë¡œ ëŒ€ì²´
            finite_values = df_cleaned[col][np.isfinite(df_cleaned[col])]
            if len(finite_values) > 0:
                max_finite = finite_values.max()
                df_cleaned.loc[np.isinf(df_cleaned[col]), col] = max_finite
            print(f"ğŸ”§ {col}: {inf_count}ê°œ ë¬´í•œê°’ì„ {max_finite:.2f}ë¡œ ëŒ€ì²´")

    # NaN ê°’ íƒì§€ ë° ì²˜ë¦¬
    nan_issues = df_cleaned.isnull().sum()
    nan_issues = nan_issues[nan_issues > 0]

    for col, nan_count in nan_issues.items():
        if col in numeric_cols:
            median_val = df_cleaned[col].median()
            df_cleaned[col] = df_cleaned[col].fillna(median_val)
            print(f"ğŸ”§ {col}: {nan_count}ê°œ NaNê°’ì„ {median_val:.2f}ë¡œ ëŒ€ì²´")

    if not infinite_issues and len(nan_issues) == 0:
        print("âœ… ë¬´í•œê°’ ë° NaNê°’ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    return df_cleaned
```
#### 2-1. ë¹ ë¥¸ ë²„ì „ íŠ¹ì„± ì„ íƒ í•¨ìˆ˜ë“¤ (ì§„í–‰ë„ í‘œì‹œìš©)
``` python
def detect_multicollinearity_fast(df, threshold=0.95):
    """ë‹¤ì¤‘ê³µì„ ì„± íƒì§€ (ë¹ ë¥¸ ë²„ì „)"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    analysis_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', 'winPlacePerc']]

    if len(analysis_cols) < 2:
        return df, []

    # ê°„ë‹¨í•œ ìƒê´€ê´€ê³„ ì²´í¬
    corr_matrix = df[analysis_cols].corr().abs()
    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]

    df_filtered = df.drop(columns=high_corr_features)
    print(f"ğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: {len(high_corr_features)}ê°œ")

    return df_filtered, high_corr_features

def select_features_by_correlation(df, target_col='winPlacePerc', top_k=30):
    """ìƒê´€ê´€ê³„ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ (RandomForest ëŒ€ì‹  ë¹ ë¥¸ ë°©ë²•)"""
    if target_col not in df.columns:
        return df, []

    numeric_cols = df.select_dtypes(include=[np.number]).columns
    feature_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', target_col]]

    # ìƒê´€ê´€ê³„ ê³„ì‚° (RandomForest ëŒ€ì‹ )
    target_corr = df[feature_cols + [target_col]].corr()[target_col].abs()
    target_corr = target_corr.drop(target_col).sort_values(ascending=False)

    top_k = min(top_k, len(target_corr))
    top_features = target_corr.head(top_k).index.tolist()

    print(f"â­ ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:")
    for i, feature in enumerate(top_features[:5], 1):
        print(f"  {i}. {feature}: {target_corr[feature]:.3f}")

    # ì„ íƒëœ íŠ¹ì„±ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
    meta_cols = ['Id', 'groupId', 'matchId', target_col]
    keep_cols = [col for col in meta_cols if col in df.columns] + top_features
    df_selected = df[keep_cols]

    return df_selected, top_features

print("âœ… ë¹ ë¥¸ ë²„ì „ íŠ¹ì„± ì„ íƒ í•¨ìˆ˜ë“¤ ì¤€ë¹„ ì™„ë£Œ!")
```
### 3. íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ë° ì „ì²˜ë¦¬
``` python
def apply_feature_scaling(df, target_col='winPlacePerc', method='standard'):
    """íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì ìš©"""
    print(f"\nâš–ï¸ íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì ìš© ({method})")
    print("-" * 40)

    df_scaled = df.copy()

    # ìŠ¤ì¼€ì¼ë§í•  íŠ¹ì„± ì„ íƒ (ìˆ˜ì¹˜í˜•, ë©”íƒ€ ì»¬ëŸ¼ ì œì™¸)
    numeric_cols = df_scaled.select_dtypes(include=[np.number]).columns
    scale_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', target_col]]

    if len(scale_cols) == 0:
        print("âŒ ìŠ¤ì¼€ì¼ë§í•  íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df_scaled, None

    # ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ
    if method == 'standard':
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
    elif method == 'robust':
        from sklearn.preprocessing import RobustScaler
        scaler = RobustScaler()
    elif method == 'minmax':
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¼ë§ ë°©ë²•: {method}")
        return df_scaled, None

    # ìŠ¤ì¼€ì¼ë§ ì ìš©
    scaled_data = scaler.fit_transform(df_scaled[scale_cols])
    df_scaled[scale_cols] = scaled_data

    print(f"âœ… {len(scale_cols)}ê°œ íŠ¹ì„±ì— {method} ìŠ¤ì¼€ì¼ë§ ì ìš©")
    print(f"ğŸ“Š ìŠ¤ì¼€ì¼ë§ í›„ íŠ¹ì„± ë²”ìœ„ ì˜ˆì‹œ:")
    for col in scale_cols[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        min_val, max_val = df_scaled[col].min(), df_scaled[col].max()
        print(f"  {col:<20}: [{min_val:.3f}, {max_val:.3f}]")

    return df_scaled, scaler

def prepare_modeling_data(df, target_col='winPlacePerc', test_size=0.2, random_state=42):
    """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
    print(f"\nğŸ¯ ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„")
    print("-" * 40)

    if target_col not in df.columns:
        print(f"âŒ íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_col}'ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    feature_cols = [col for col in df.columns if col not in ['Id', 'groupId', 'matchId', target_col]]

    X = df[feature_cols]
    y = df[target_col]

    print(f"ğŸ“Š íŠ¹ì„± ìˆ˜: {X.shape[1]}ê°œ")
    print(f"ğŸ“Š ìƒ˜í”Œ ìˆ˜: {X.shape[0]:,}ê°œ")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë¶„í¬:")
    print(f"  í‰ê· : {y.mean():.3f}")
    print(f"  í‘œì¤€í¸ì°¨: {y.std():.3f}")
    print(f"  ë²”ìœ„: [{y.min():.3f}, {y.max():.3f}]")

    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=None
    )

    print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
    print(f"  í›ˆë ¨ ì„¸íŠ¸: {X_train.shape[0]:,}ê°œ ({X_train.shape[0]/len(df)*100:.1f}%)")
    print(f"  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {X_test.shape[0]:,}ê°œ ({X_test.shape[0]/len(df)*100:.1f}%)")

    return {
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train,
        'y_test': y_test,
        'feature_names': feature_cols
    }
```
### 4. ì¢…í•© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ (ì§„í–‰ë„ í‘œì‹œ ë²„ì „)
``` python
def comprehensive_feature_engineering_pipeline(df, target_col='winPlacePerc', sample_size=100000):
    """ì§„í–‰ë„ í‘œì‹œê°€ í¬í•¨ëœ ì¢…í•©ì ì¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸"""
    print("ğŸš€ ì¢…í•© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘ (ì§„í–‰ë„ í‘œì‹œ)")
    print("="*60)

    # ì§„í–‰ë„ ì¶”ì ê¸° ì´ˆê¸°í™” (ì´ 9ë‹¨ê³„)
    progress = ProgressTracker(9, "Phase 4")
    start_time = time.time()
    pipeline_results = {'original_shape': df.shape}

    # 0. ë°ì´í„° ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
    print("\nğŸ¯ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    if len(df) > sample_size:
        df_work = df.sample(n=sample_size, random_state=42).reset_index(drop=True)
        print(f"ğŸ“Š ìƒ˜í”Œë§: {len(df_work):,}í–‰ (ì›ë³¸: {len(df):,}í–‰)")
    else:
        df_work = df.copy()

    show_memory_progress()

    # 1. íŒŒìƒ íŠ¹ì„± ìƒì„±
    progress.update("íš¨ìœ¨ì„± íŠ¹ì„±", "í‚¬ íš¨ìœ¨ì„±, ì´ë™ íš¨ìœ¨ì„± ê³„ì‚°")
    df_enhanced, efficiency_features = create_efficiency_features_fast(df_work)
    pipeline_results['efficiency_features'] = efficiency_features

    progress.update("ë¹„ìœ¨ íŠ¹ì„±", f"{len(efficiency_features)}ê°œ íš¨ìœ¨ì„± íŠ¹ì„± ìƒì„±ë¨")
    df_enhanced, ratio_features = create_ratio_features_fast(df_enhanced)
    pipeline_results['ratio_features'] = ratio_features

    progress.update("ê²Œì„ ìŠ¤íƒ€ì¼", f"ì´ {len(efficiency_features + ratio_features)}ê°œ íŒŒìƒ íŠ¹ì„±")
    df_enhanced, style_features = create_game_style_features_fast(df_enhanced)
    pipeline_results['style_features'] = style_features

    progress.update("ê³ ê¸‰ íŠ¹ì„±", "ë¡œê·¸ ë³€í™˜ ë° ì´ì§„ íŠ¹ì„± ìƒì„±")
    df_enhanced, advanced_features = create_advanced_features_fast(df_enhanced)
    pipeline_results['advanced_features'] = advanced_features

    show_memory_progress()

    # 2. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
    progress.update("ë°ì´í„° ì •ì œ", f"{len(advanced_features)}ê°œ ìƒˆ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
    df_enhanced = handle_infinite_values(df_enhanced)

    progress.update("íŠ¹ì„± ì„ íƒ", "ìƒê´€ê´€ê³„ ê¸°ë°˜ íŠ¹ì„± í•„í„°ë§")
    df_enhanced, removed_features = detect_multicollinearity_fast(df_enhanced, threshold=0.95)
    pipeline_results['removed_multicollinear'] = removed_features

    # 3. íŠ¹ì„± ì„ íƒ (ë¹ ë¥¸ ë°©ë²•)
    progress.update("íŠ¹ì„± ì¤‘ìš”ë„", "ìƒê´€ê´€ê³„ ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚°")
    df_selected, important_features = select_features_by_correlation(
        df_enhanced, target_col=target_col, top_k=30  # 30ê°œë¡œ ì œí•œ
    )
    pipeline_results['important_features'] = important_features

    # 4. íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
    progress.update("ìŠ¤ì¼€ì¼ë§", f"{len(important_features)}ê°œ íŠ¹ì„± í‘œì¤€í™”")
    df_scaled, scaler = apply_feature_scaling(df_selected, target_col=target_col, method='standard')
    pipeline_results['scaler'] = scaler

    # 5. ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„
    progress.update("ë°ì´í„° ë¶„í• ", "í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìƒì„±")
    modeling_data = prepare_modeling_data(df_scaled, target_col=target_col)
    pipeline_results['modeling_data'] = modeling_data

    total_time = time.time() - start_time

    print(f"\nğŸ‰ Phase 4 ì™„ë£Œ!")
    print(f"â° ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")
    print(f"ğŸ“Š ì›ë³¸ íŠ¹ì„±: {df.shape[1]}ê°œ")
    print(f"ğŸ“ˆ ìƒì„±ëœ íŠ¹ì„±: {len(efficiency_features + ratio_features + style_features + advanced_features)}ê°œ")
    print(f"ğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: {len(removed_features)}ê°œ")
    print(f"â­ ìµœì¢… ì„ íƒëœ íŠ¹ì„±: {len(important_features)}ê°œ")
    print(f"ğŸ¯ ìµœì¢… ë°ì´í„° í¬ê¸°: {df_scaled.shape[0]:,}í–‰ x {df_scaled.shape[1]}ì—´")
    print(f"âœ… Phase 4 ì™„ë£Œ! Phase 5 (í´ëŸ¬ìŠ¤í„°ë§)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return df_scaled, pipeline_results

# ê¸°ì¡´ ë²„ì „ë„ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
def comprehensive_feature_engineering_pipeline_original(df, target_col='winPlacePerc'):
    """ì¢…í•©ì ì¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ (ì›ë³¸ ë²„ì „)"""
    print("ğŸš€ ì¢…í•© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*60)

    start_time = time.time()
    pipeline_results = {'original_shape': df.shape}

    # 1. íŒŒìƒ íŠ¹ì„± ìƒì„±
    print(f"\n{'='*20} 1ë‹¨ê³„: íš¨ìœ¨ì„± íŠ¹ì„± ìƒì„± {'='*20}")
    df_enhanced, efficiency_features = create_efficiency_features(df)
    pipeline_results['efficiency_features'] = efficiency_features

    print(f"\n{'='*20} 2ë‹¨ê³„: ë¹„ìœ¨ íŠ¹ì„± ìƒì„± {'='*20}")
    df_enhanced, ratio_features = create_ratio_features(df_enhanced)
    pipeline_results['ratio_features'] = ratio_features

    print(f"\n{'='*20} 3ë‹¨ê³„: ê²Œì„ ìŠ¤íƒ€ì¼ íŠ¹ì„± ìƒì„± {'='*20}")
    df_enhanced, style_features = create_game_style_features(df_enhanced)
    pipeline_results['style_features'] = style_features

    print(f"\n{'='*20} 4ë‹¨ê³„: ê³ ê¸‰ íŠ¹ì„± ìƒì„± {'='*20}")
    df_enhanced, advanced_features = create_advanced_features(df_enhanced)
    pipeline_results['advanced_features'] = advanced_features

    # 2. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
    print(f"\n{'='*20} 5ë‹¨ê³„: ë¬´í•œê°’ ì²˜ë¦¬ {'='*20}")
    df_enhanced = handle_infinite_values(df_enhanced)

    print(f"\n{'='*20} 6ë‹¨ê³„: ë‹¤ì¤‘ê³µì„ ì„± ì œê±° {'='*20}")
    df_enhanced, removed_features = detect_multicollinearity(df_enhanced, threshold=0.95)
    pipeline_results['removed_multicollinear'] = removed_features

    # 3. íŠ¹ì„± ì„ íƒ
    print(f"\n{'='*20} 7ë‹¨ê³„: íŠ¹ì„± ì¤‘ìš”ë„ ì„ íƒ {'='*20}")
    df_selected, important_features = select_features_by_importance(
        df_enhanced, target_col=target_col, method='random_forest', top_k=50
    )
    pipeline_results['important_features'] = important_features

    # 4. íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
    print(f"\n{'='*20} 8ë‹¨ê³„: íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ {'='*20}")
    df_scaled, scaler = apply_feature_scaling(df_selected, target_col=target_col, method='standard')
    pipeline_results['scaler'] = scaler

    # 5. ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„
    print(f"\n{'='*20} 9ë‹¨ê³„: ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ {'='*20}")
    modeling_data = prepare_modeling_data(df_scaled, target_col=target_col)
    pipeline_results['modeling_data'] = modeling_data

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    execution_time = time.time() - start_time

    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*20} íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ ìš”ì•½ {'='*20}")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"ğŸ“Š ì›ë³¸ íŠ¹ì„±: {df.shape[1]}ê°œ")
    print(f"ğŸ“ˆ ìƒì„±ëœ íŠ¹ì„±: {len(efficiency_features + ratio_features + style_features + advanced_features)}ê°œ")
    print(f"ğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: {len(removed_features)}ê°œ")
    print(f"â­ ìµœì¢… ì„ íƒëœ íŠ¹ì„±: {len(important_features)}ê°œ")
    print(f"ğŸ¯ ìµœì¢… ë°ì´í„° í¬ê¸°: {df_scaled.shape[0]:,}í–‰ x {df_scaled.shape[1]}ì—´")
    print(f"âœ… Phase 4 ì™„ë£Œ! Phase 5 (í´ëŸ¬ìŠ¤í„°ë§)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return df_scaled, pipeline_results
```
### 5. ì‹¤í–‰ í•¨ìˆ˜
``` python
# 5. ì‹¤í–‰ í•¨ìˆ˜

def run_phase4_pipeline(df_cleaned, target_col='winPlacePerc', use_progress=True, sample_size=100000):
    """Phase 4 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("ğŸ® PUBG Phase 4: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘!")
    print("="*60)

    # ë©”ëª¨ë¦¬ í™•ì¸
    check_memory_usage()

    # ì§„í–‰ë„ í‘œì‹œ ë²„ì „ ë˜ëŠ” ì›ë³¸ ë²„ì „ ì„ íƒ
    if use_progress:
        print("ğŸš€ ì§„í–‰ë„ í‘œì‹œ ë²„ì „ìœ¼ë¡œ ì‹¤í–‰ (ë¹ ë¥¸ ì²˜ë¦¬)")
        df_engineered, results = comprehensive_feature_engineering_pipeline(
            df_cleaned, target_col, sample_size=sample_size
        )
    else:
        print("ğŸ“Š ì›ë³¸ ë²„ì „ìœ¼ë¡œ ì‹¤í–‰ (ì „ì²´ íŠ¹ì„±)")
        df_engineered, results = comprehensive_feature_engineering_pipeline_original(
            df_cleaned, target_col
        )

    return df_engineered, results
```
### 6. íŠ¹ì„± í’ˆì§ˆ ê²€ì¦ í•¨ìˆ˜
``` python
# 6. íŠ¹ì„± í’ˆì§ˆ ê²€ì¦ í•¨ìˆ˜

def validate_engineered_features(df, pipeline_results):
    """ìƒì„±ëœ íŠ¹ì„±ì˜ í’ˆì§ˆ ê²€ì¦"""
    print("\nğŸ” íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ ê²€ì¦")
    print("="*50)

    # 1. ìƒì„±ëœ íŠ¹ì„± í†µê³„ ìš”ì•½
    print("ğŸ“Š ìƒì„±ëœ íŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½:")
    categories = {
        'Efficiency': pipeline_results.get('efficiency_features', []),
        'Ratio': pipeline_results.get('ratio_features', []),
        'Style': pipeline_results.get('style_features', []),
        'Advanced': pipeline_results.get('advanced_features', [])
    }

    for category, features in categories.items():
        if features:
            print(f"  {category:<12}: {len(features):2d}ê°œ íŠ¹ì„±")

    # 2. ìµœì¢… ì„ íƒëœ íŠ¹ì„± ë¶„ì„
    important_features = pipeline_results.get('important_features', [])
    if important_features:
        print(f"\nâ­ ìµœì¢… ì„ íƒëœ ìƒìœ„ íŠ¹ì„± ({len(important_features)}ê°œ):")

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        for category, features in categories.items():
            selected_in_category = [f for f in features if f in important_features]
            if selected_in_category:
                print(f"  {category} ({len(selected_in_category)}ê°œ): {', '.join(selected_in_category[:3])}{'...' if len(selected_in_category) > 3 else ''}")

    # 3. ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    feature_cols = [col for col in numeric_cols if col not in ['Id', 'groupId', 'matchId', 'winPlacePerc']]

    if feature_cols:
        print(f"\nğŸ“ˆ ìµœì¢… íŠ¹ì„± í’ˆì§ˆ ì§€í‘œ:")
        quality_stats = df[feature_cols].describe()

        # ê²°ì¸¡ì¹˜ í™•ì¸
        missing_count = df[feature_cols].isnull().sum().sum()
        print(f"  ê²°ì¸¡ì¹˜: {missing_count}ê°œ")

        # ë¬´í•œê°’ í™•ì¸
        inf_count = np.isinf(df[feature_cols]).sum().sum()
        print(f"  ë¬´í•œê°’: {inf_count}ê°œ")

        # ë³€ë™ì„± í™•ì¸ (í‘œì¤€í¸ì°¨ê°€ 0ì¸ íŠ¹ì„±)
        zero_var_features = quality_stats.loc['std'][quality_stats.loc['std'] == 0]
        print(f"  ë³€ë™ì„± ì—†ëŠ” íŠ¹ì„±: {len(zero_var_features)}ê°œ")

        if len(zero_var_features) > 0:
            print(f"    - {', '.join(zero_var_features.index.tolist())}")

    # 4. ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœ í™•ì¸
    modeling_data = pipeline_results.get('modeling_data')
    if modeling_data:
        print(f"\nğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœ:")
        print(f"  í›ˆë ¨ ì„¸íŠ¸: {modeling_data['X_train'].shape}")
        print(f"  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {modeling_data['X_test'].shape}")
        print(f"  íŠ¹ì„± ìˆ˜: {len(modeling_data['feature_names'])}ê°œ")
        print(f"  íƒ€ê²Ÿ ë²”ìœ„: [{modeling_data['y_train'].min():.3f}, {modeling_data['y_train'].max():.3f}]")

    print(f"\nâœ… íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
```
### 7. ì‹¤í–‰ ì˜ˆì‹œ ë° ê°€ì´ë“œ
``` python
def display_feature_engineering_guide():
    """íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹¤í–‰ ê°€ì´ë“œ"""
    print("\nğŸ“‹ Phase 4 ì‹¤í–‰ ë°©ë²•:")
    print("="*50)
    print("# 1. ë¹ ë¥¸ ë²„ì „ (ì§„í–‰ë„ í‘œì‹œ, ê¶Œì¥)")
    print("df_engineered, results = run_phase4_pipeline(df_cleaned, use_progress=True, sample_size=100000)")
    print()
    print("# 2. ì›ë³¸ ë²„ì „ (ì „ì²´ íŠ¹ì„±, ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼)")
    print("df_engineered, results = run_phase4_pipeline(df_cleaned, use_progress=False)")
    print()
    print("# 3. íŠ¹ì„± í’ˆì§ˆ ê²€ì¦")
    print("validate_engineered_features(df_engineered, results)")
    print()
    print("# 4. ëª¨ë¸ë§ ë°ì´í„° ì¶”ì¶œ")
    print("modeling_data = results['modeling_data']")
    print("X_train = modeling_data['X_train']")
    print("y_train = modeling_data['y_train']")
    print()
    print("# 5. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰")
    print("# Phase 5: í´ëŸ¬ìŠ¤í„°ë§ (ë¹„ì§€ë„ í•™ìŠµ)")
    print("# Phase 6: ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ë§")

# ê°€ì´ë“œ í‘œì‹œ
display_feature_engineering_guide()

print("\nğŸ¯ Phase 4 ì§„í–‰ë„ í‘œì‹œ ì™„ì „íŒ ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: Phase 5 - ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§)")
```
#### 7. ì‹¤í–‰ ì˜ˆì‹œ ë° ê°€ì´ë“œ ê²°ê³¼

``` bash
ğŸ“‹ Phase 4 ì‹¤í–‰ ë°©ë²•:
==================================================
# 1. ë¹ ë¥¸ ë²„ì „ (ì§„í–‰ë„ í‘œì‹œ, ê¶Œì¥)
df_engineered, results = run_phase4_pipeline(df_cleaned, use_progress=True, sample_size=100000)

# 2. ì›ë³¸ ë²„ì „ (ì „ì²´ íŠ¹ì„±, ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼)
df_engineered, results = run_phase4_pipeline(df_cleaned, use_progress=False)

# 3. íŠ¹ì„± í’ˆì§ˆ ê²€ì¦
validate_engineered_features(df_engineered, results)

# 4. ëª¨ë¸ë§ ë°ì´í„° ì¶”ì¶œ
modeling_data = results['modeling_data']
X_train = modeling_data['X_train']
y_train = modeling_data['y_train']

# 5. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
# Phase 5: í´ëŸ¬ìŠ¤í„°ë§ (ë¹„ì§€ë„ í•™ìŠµ)
# Phase 6: ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ë§

ğŸ¯ Phase 4 ì§„í–‰ë„ í‘œì‹œ ì™„ì „íŒ ì¤€ë¹„ ì™„ë£Œ!
ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: Phase 5 - ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§)
```

### 8. ì‚¬ìš© ì˜ˆì‹œ
``` python
print("\nğŸ“ ì‚¬ìš© ì˜ˆì‹œ:")
print("="*30)
print("# ë¹ ë¥¸ ì‹¤í–‰ (ê¶Œì¥)")
print("df_engineered, results = run_phase4_pipeline(df_cleaned)")
print()
print("# ê²°ê³¼ í™•ì¸")
print("print('ìµœì¢… íŠ¹ì„± ìˆ˜:', len(results['important_features']))")
print("print('ëª¨ë¸ë§ ë°ì´í„°:', results['modeling_data']['X_train'].shape)")
```
#### 8. ì‚¬ìš© ì˜ˆì‹œ ê²°ê³¼

``` bash
ğŸ“ ì‚¬ìš© ì˜ˆì‹œ:
==============================
# ë¹ ë¥¸ ì‹¤í–‰ (ê¶Œì¥)
df_engineered, results = run_phase4_pipeline(df_cleaned)

# ê²°ê³¼ í™•ì¸
print('ìµœì¢… íŠ¹ì„± ìˆ˜:', len(results['important_features']))
print('ëª¨ë¸ë§ ë°ì´í„°:', results['modeling_data']['X_train'].shape)
```

### ì‹¤í–‰
``` python
# Phase 4 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
df_engineered, results = run_phase4_pipeline(df_cleaned)

# íŠ¹ì„± í’ˆì§ˆ ê²€ì¦
validate_engineered_features(df_engineered, results)

# ëª¨ë¸ë§ ë°ì´í„° ì¶”ì¶œ
modeling_data = results['modeling_data']
X_train, y_train = modeling_data['X_train'], modeling_data['y_train']
```

#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ® PUBG Phase 4: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘!
============================================================
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 30.2% (3.5GB / 12.7GB)
ğŸš€ ì§„í–‰ë„ í‘œì‹œ ë²„ì „ìœ¼ë¡œ ì‹¤í–‰ (ë¹ ë¥¸ ì²˜ë¦¬)
ğŸš€ ì¢…í•© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘ (ì§„í–‰ë„ í‘œì‹œ)
============================================================

ğŸ¯ ë°ì´í„° ì¤€ë¹„ ì¤‘...
ğŸ“Š ìƒ˜í”Œë§: 100,000í–‰ (ì›ë³¸: 800,000í–‰)
ğŸ’¾ ë©”ëª¨ë¦¬: 30.0% (3.5GB/12.7GB)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 44.4% | 4/9 | ê³ ê¸‰ íŠ¹ì„± | ë¡œê·¸ ë³€í™˜ ë° ì´ì§„ íŠ¹ì„± ìƒì„± | ETA: 1ì´ˆ | ê²½ê³¼: 0ì´ˆğŸ’¾ ë©”ëª¨ë¦¬: 30.0% (3.5GB/12.7GB)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 55.6% | 5/9 | ë°ì´í„° ì •ì œ | 4ê°œ ìƒˆ íŠ¹ì„± ìƒì„± ì™„ë£Œ | ETA: 0ì´ˆ | ê²½ê³¼: 0ì´ˆ
â™¾ï¸ ë¬´í•œê°’ ë° ê·¹ë‹¨ê°’ ì²˜ë¦¬
----------------------------------------
âœ… ë¬´í•œê°’ ë° NaNê°’ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘] 66.7% | 6/9 | íŠ¹ì„± ì„ íƒ | ìƒê´€ê´€ê³„ ê¸°ë°˜ íŠ¹ì„± í•„í„°ë§ | ETA: 0ì´ˆ | ê²½ê³¼: 1ì´ˆğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: 4ê°œ
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 77.8% | 7/9 | íŠ¹ì„± ì¤‘ìš”ë„ | ìƒê´€ê´€ê³„ ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚° | ETA: 0ì´ˆ | ê²½ê³¼: 1ì´ˆâ­ ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:
  1. walkDistance: 0.817
  2. walkDistance_log: 0.794
  3. killPlace: 0.721
  4. total_distance: 0.685
  5. boosts: 0.633
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘] 88.9% | 8/9 | ìŠ¤ì¼€ì¼ë§ | 30ê°œ íŠ¹ì„± í‘œì¤€í™” | ETA: 0ì´ˆ | ê²½ê³¼: 1ì´ˆ
âš–ï¸ íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì ìš© (standard)
----------------------------------------
âœ… 30ê°œ íŠ¹ì„±ì— standard ìŠ¤ì¼€ì¼ë§ ì ìš©
ğŸ“Š ìŠ¤ì¼€ì¼ë§ í›„ íŠ¹ì„± ë²”ìœ„ ì˜ˆì‹œ:
  walkDistance        : [-0.985, 3.154]
  walkDistance_log    : [-3.360, 1.306]
  killPlace           : [-1.700, 1.904]
  total_distance      : [-0.820, 5.237]
  boosts              : [-0.643, 8.626]
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% | 9/9 | ë°ì´í„° ë¶„í•  | í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìƒì„± | ETA: 0ì´ˆ | ê²½ê³¼: 2ì´ˆ
âœ… ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: 1.5ì´ˆ

ğŸ¯ ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„
----------------------------------------
ğŸ“Š íŠ¹ì„± ìˆ˜: 30ê°œ
ğŸ“Š ìƒ˜í”Œ ìˆ˜: 100,000ê°œ
ğŸ¯ íƒ€ê²Ÿ ë¶„í¬:
  í‰ê· : 0.473
  í‘œì¤€í¸ì°¨: 0.308
  ë²”ìœ„: [0.000, 1.000]
âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:
  í›ˆë ¨ ì„¸íŠ¸: 80,000ê°œ (80.0%)
  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 20,000ê°œ (20.0%)

ğŸ‰ Phase 4 ì™„ë£Œ!
â° ì´ ì†Œìš”ì‹œê°„: 1.6ì´ˆ
ğŸ“Š ì›ë³¸ íŠ¹ì„±: 29ê°œ
ğŸ“ˆ ìƒì„±ëœ íŠ¹ì„±: 10ê°œ
ğŸ—‘ï¸ ì œê±°ëœ íŠ¹ì„±: 4ê°œ
â­ ìµœì¢… ì„ íƒëœ íŠ¹ì„±: 30ê°œ
ğŸ¯ ìµœì¢… ë°ì´í„° í¬ê¸°: 100,000í–‰ x 34ì—´
âœ… Phase 4 ì™„ë£Œ! Phase 5 (í´ëŸ¬ìŠ¤í„°ë§)ë¡œ ì§„í–‰ ê°€ëŠ¥

ğŸ” íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ ê²€ì¦
==================================================
ğŸ“Š ìƒì„±ëœ íŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½:
  Efficiency  :  3ê°œ íŠ¹ì„±
  Ratio       :  2ê°œ íŠ¹ì„±
  Style       :  1ê°œ íŠ¹ì„±
  Advanced    :  4ê°œ íŠ¹ì„±

â­ ìµœì¢… ì„ íƒëœ ìƒìœ„ íŠ¹ì„± (30ê°œ):
  Efficiency (3ê°œ): kill_efficiency, damage_per_kill, total_distance
  Ratio (2ê°œ): total_heals, heal_boost_ratio
  Advanced (4ê°œ): damageDealt_log, walkDistance_log, has_kills...

ğŸ“ˆ ìµœì¢… íŠ¹ì„± í’ˆì§ˆ ì§€í‘œ:
  ê²°ì¸¡ì¹˜: 0ê°œ
  ë¬´í•œê°’: 0ê°œ
  ë³€ë™ì„± ì—†ëŠ” íŠ¹ì„±: 0ê°œ

ğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœ:
  í›ˆë ¨ ì„¸íŠ¸: (80000, 30)
  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: (20000, 30)
  íŠ¹ì„± ìˆ˜: 30ê°œ
  íƒ€ê²Ÿ ë²”ìœ„: [0.000, 1.000]

âœ… íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ
```

## Phase 5: ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§)

### 0. ì§„í–‰ë„ í‘œì‹œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
``` python

import time
from tqdm.auto import tqdm
import sys
from IPython.display import display, HTML, clear_output

# ì§„í–‰ë„ í‘œì‹œ ê´€ë ¨ í•¨ìˆ˜ë“¤
def show_progress_bar(current, total, description="Processing", bar_length=50):
    """ì§„í–‰ë„ ë°” í‘œì‹œ"""
    progress = current / total
    filled_length = int(bar_length * progress)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)

    percentage = progress * 100
    print(f'\r{description}: |{bar}| {percentage:.1f}% ({current}/{total})', end='', flush=True)

    if current == total:
        print()  # ì™„ë£Œ ì‹œ ì¤„ë°”ê¿ˆ

def create_phase_tracker():
    """ì „ì²´ Phase 5 ì§„í–‰ ìƒí™© ì¶”ì ê¸°"""
    phases = {
        1: {"name": "ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰", "status": "ëŒ€ê¸°ì¤‘", "progress": 0},
        2: {"name": "K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰", "status": "ëŒ€ê¸°ì¤‘", "progress": 0},
        3: {"name": "í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¶„ì„", "status": "ëŒ€ê¸°ì¤‘", "progress": 0},
        4: {"name": "í´ëŸ¬ìŠ¤í„° ì‹œê°í™”", "status": "ëŒ€ê¸°ì¤‘", "progress": 0},
        5: {"name": "í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì œì•ˆ", "status": "ëŒ€ê¸°ì¤‘", "progress": 0}
    }
    return phases

def update_phase_status(phases, phase_num, status, progress=None):
    """ë‹¨ê³„ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    phases[phase_num]["status"] = status
    if progress is not None:
        phases[phase_num]["progress"] = progress

    display_phase_status(phases)

def display_phase_status(phases):
    """Phase ì§„í–‰ ìƒí™© í‘œì‹œ"""
    clear_output(wait=True)

    print("ğŸ¯ Phase 5: ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§) ì§„í–‰ ìƒí™©")
    print("="*60)

    status_icons = {
        "ëŒ€ê¸°ì¤‘": "â³",
        "ì§„í–‰ì¤‘": "ğŸ”„",
        "ì™„ë£Œ": "âœ…",
        "ì˜¤ë¥˜": "âŒ"
    }

    for phase_num, info in phases.items():
        icon = status_icons.get(info["status"], "â“")
        progress_bar = ""

        if info["progress"] > 0:
            bar_length = 20
            filled = int(bar_length * info["progress"] / 100)
            progress_bar = f" |{'â–ˆ' * filled}{'â–‘' * (bar_length - filled)}| {info['progress']}%"

        print(f"{icon} {phase_num}ë‹¨ê³„: {info['name']} - {info['status']}{progress_bar}")

    print("-"*60)

def show_clustering_progress(current_step, total_steps, step_name, sub_progress=None):
    """ì„¸ë¶€ ì§„í–‰ë„ í‘œì‹œ"""
    main_progress = (current_step / total_steps) * 100

    progress_msg = f"ğŸ”„ {step_name} ({current_step}/{total_steps})"
    if sub_progress is not None:
        progress_msg += f" - {sub_progress}%"

    print(f"\r{progress_msg}", end='', flush=True)

    if current_step == total_steps:
        print(f"\nâœ… {step_name} ì™„ë£Œ!")

print("ğŸ“Š ì§„í–‰ë„ í‘œì‹œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ!")
```
### 1. ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • í•¨ìˆ˜ë“¤
``` python
print("ğŸ¯ Phase 5: ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§) ì‹œì‘!")
print("="*60)

# 1. ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • í•¨ìˆ˜ë“¤ (ì§„í–‰ë„ í¬í•¨)

def find_optimal_clusters_elbow(X, max_clusters=15, random_state=42, phases=None, phase_num=1):
    """Elbow Methodë¥¼ ì‚¬ìš©í•œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° (ì§„í–‰ë„ í¬í•¨)"""
    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 0)

    print("ğŸ“ˆ Elbow Methodë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰")
    print("-" * 40)

    # ìƒ˜í”Œë§ (ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´)
    if len(X) > 10000:
        sample_size = 10000
        X_sample = X.sample(n=sample_size, random_state=random_state)
        print(f"ğŸ¯ ì„±ëŠ¥ì„ ìœ„í•´ {sample_size:,}ê°œ ìƒ˜í”Œ ì‚¬ìš©")
    else:
        X_sample = X

    # í´ëŸ¬ìŠ¤í„° ìˆ˜ë³„ WCSS (Within-Cluster Sum of Squares) ê³„ì‚°
    wcss = []
    k_range = range(2, max_clusters + 1)
    total_steps = len(k_range)

    print("ğŸ”„ í´ëŸ¬ìŠ¤í„° ìˆ˜ë³„ WCSS ê³„ì‚° ì¤‘...")

    # tqdmì„ ì‚¬ìš©í•œ ì§„í–‰ë„ ë°”
    with tqdm(k_range, desc="Elbow Method", unit="cluster") as pbar:
        for i, k in enumerate(pbar):
            kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)
            kmeans.fit(X_sample)
            wcss.append(kmeans.inertia_)

            # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
            progress = ((i + 1) / total_steps) * 50  # 50%ê¹Œì§€ ë°°ì •
            if phases:
                update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", progress)

            pbar.set_postfix({'K': k, 'WCSS': f'{kmeans.inertia_:,.0f}'})
            time.sleep(0.1)  # ì§„í–‰ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

    # Elbow Point ê³„ì‚° (2ì°¨ ë¯¸ë¶„ ë°©ë²•)
    def calculate_elbow_point(wcss_values):
        if len(wcss_values) < 3:
            return len(wcss_values) + 1

        # 1ì°¨ ë° 2ì°¨ ì°¨ë¶„ ê³„ì‚°
        first_diff = np.diff(wcss_values)
        second_diff = np.diff(first_diff)

        # 2ì°¨ ì°¨ë¶„ì´ ìµœëŒ€ì¸ ì§€ì ì„ elbowë¡œ ì„ íƒ
        elbow_idx = np.argmax(second_diff) + 2  # +2ëŠ” ì¸ë±ìŠ¤ ë³´ì •
        return elbow_idx + 2  # këŠ” 2ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +2

    print("ğŸ”„ Elbow Point ê³„ì‚° ì¤‘...")
    optimal_k_elbow = calculate_elbow_point(wcss)

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 75)

    # ì‹œê°í™”
    print("ğŸ¨ Elbow Curve ì‹œê°í™” ì¤‘...")
    plt.figure(figsize=(12, 5))

    # Elbow Curve
    plt.subplot(1, 2, 1)
    plt.plot(k_range, wcss, 'bo-', linewidth=2, markersize=8)
    plt.axvline(x=optimal_k_elbow, color='red', linestyle='--',
                label=f'Optimal K = {optimal_k_elbow}')
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
    plt.title('Elbow Method for Optimal K')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # WCSS ê°ì†Œìœ¨
    plt.subplot(1, 2, 2)
    if len(wcss) > 1:
        reduction_rate = [abs(wcss[i-1] - wcss[i]) / wcss[i-1] * 100 for i in range(1, len(wcss))]
        plt.plot(k_range[1:], reduction_rate, 'go-', linewidth=2, markersize=8)
        plt.xlabel('Number of Clusters (K)')
        plt.ylabel('WCSS Reduction Rate (%)')
        plt.title('WCSS Reduction Rate')
        plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    if phases:
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    print(f"ğŸ¯ Elbow Method ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {optimal_k_elbow}")
    return optimal_k_elbow, wcss

def find_optimal_clusters_silhouette(X, max_clusters=15, random_state=42, phases=None, phase_num=1):
    """Silhouette Analysisë¥¼ ì‚¬ìš©í•œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° (ì§„í–‰ë„ í¬í•¨)"""
    print("\nğŸ“Š Silhouette Analysisë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰")
    print("-" * 40)

    # ìƒ˜í”Œë§ (ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´)
    if len(X) > 5000:  # SilhouetteëŠ” ë” ë§ì€ ê³„ì‚°ì´ í•„ìš”
        sample_size = 5000
        X_sample = X.sample(n=sample_size, random_state=random_state)
        print(f"ğŸ¯ ì„±ëŠ¥ì„ ìœ„í•´ {sample_size:,}ê°œ ìƒ˜í”Œ ì‚¬ìš©")
    else:
        X_sample = X

    # í´ëŸ¬ìŠ¤í„° ìˆ˜ë³„ Silhouette Score ê³„ì‚°
    silhouette_scores = []
    k_range = range(2, max_clusters + 1)
    total_steps = len(k_range)

    print("ğŸ”„ í´ëŸ¬ìŠ¤í„° ìˆ˜ë³„ Silhouette Score ê³„ì‚° ì¤‘...")

    # tqdmì„ ì‚¬ìš©í•œ ì§„í–‰ë„ ë°”
    with tqdm(k_range, desc="Silhouette Analysis", unit="cluster") as pbar:
        for i, k in enumerate(pbar):
            kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)
            cluster_labels = kmeans.fit_predict(X_sample)
            silhouette_avg = silhouette_score(X_sample, cluster_labels)
            silhouette_scores.append(silhouette_avg)

            # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
            progress = 50 + ((i + 1) / total_steps) * 50  # 50%ë¶€í„° 100%ê¹Œì§€
            if phases:
                update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", progress)

            pbar.set_postfix({'K': k, 'Silhouette': f'{silhouette_avg:.4f}'})
            time.sleep(0.1)  # ì§„í–‰ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

    # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ (Silhouette Scoreê°€ ìµœëŒ€ì¸ ì§€ì )
    optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]
    max_silhouette = max(silhouette_scores)

    # ì‹œê°í™”
    print("ğŸ¨ Silhouette Score ì‹œê°í™” ì¤‘...")
    plt.figure(figsize=(12, 5))

    # Silhouette Score
    plt.subplot(1, 2, 1)
    plt.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)
    plt.axvline(x=optimal_k_silhouette, color='blue', linestyle='--',
                label=f'Optimal K = {optimal_k_silhouette}')
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Average Silhouette Score')
    plt.title('Silhouette Analysis for Optimal K')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Bar plot
    plt.subplot(1, 2, 2)
    colors = ['red' if k == optimal_k_silhouette else 'skyblue' for k in k_range]
    plt.bar(k_range, silhouette_scores, color=colors, alpha=0.7)
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Average Silhouette Score')
    plt.title('Silhouette Scores Comparison')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print(f"ğŸ¯ Silhouette Analysis ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {optimal_k_silhouette} (ì ìˆ˜: {max_silhouette:.4f})")
    return optimal_k_silhouette, silhouette_scores

def determine_final_cluster_number(elbow_k, silhouette_k, silhouette_scores, wcss):
    """ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •"""
    print(f"\nğŸ¯ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •")
    print("-" * 40)

    print(f"ğŸ“ˆ Elbow Method ì¶”ì²œ: K = {elbow_k}")
    print(f"ğŸ“Š Silhouette Analysis ì¶”ì²œ: K = {silhouette_k}")

    # ê²°ì • ë¡œì§
    if abs(elbow_k - silhouette_k) <= 1:
        # ë‘ ë°©ë²•ì´ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ë©´ í‰ê·  ì‚¬ìš©
        final_k = int((elbow_k + silhouette_k) / 2)
        decision_reason = "ë‘ ë°©ë²•ì˜ ê²°ê³¼ê°€ ìœ ì‚¬í•¨"
    elif silhouette_k <= len(silhouette_scores) + 1 and silhouette_scores[silhouette_k - 2] > 0.3:  # ì¸ë±ìŠ¤ ë³´ì •
        # Silhouette Scoreê°€ ì¶©ë¶„íˆ ë†’ìœ¼ë©´ Silhouette ë°©ë²• ìš°ì„ 
        final_k = silhouette_k
        decision_reason = f"Silhouette Scoreê°€ ì–‘í˜¸í•¨ ({silhouette_scores[silhouette_k - 2]:.3f})"
    else:
        # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Elbow ë°©ë²• ìš°ì„ 
        final_k = elbow_k
        decision_reason = "Elbow Methodë¥¼ ìš°ì„  ì ìš©"

    # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš© (4-8ê°œ í´ëŸ¬ìŠ¤í„°ê°€ í•´ì„í•˜ê¸° ì¢‹ìŒ)
    if final_k < 4:
        final_k = 4
        decision_reason += " (ìµœì†Œ 4ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¡°ì •)"
    elif final_k > 8:
        final_k = 8
        decision_reason += " (ìµœëŒ€ 8ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¡°ì •)"

    print(f"ğŸ¯ ìµœì¢… ê²°ì •: K = {final_k}")
    print(f"ğŸ“ ê²°ì • ê·¼ê±°: {decision_reason}")

    return final_k
```
### 2. K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ í•¨ìˆ˜ë“¤
``` python
# 2. K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ í•¨ìˆ˜ë“¤

def perform_kmeans_clustering(X, n_clusters, random_state=42, phases=None, phase_num=2):
    """K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰"""
    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 0)

    print(f"\nğŸ¯ K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ (K = {n_clusters})")
    print("-" * 40)

    # K-Means ëª¨ë¸ í›ˆë ¨
    print("ğŸ”„ í´ëŸ¬ìŠ¤í„°ë§ ì§„í–‰ ì¤‘...")

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 25)

    kmeans = KMeans(
        n_clusters=n_clusters,
        random_state=random_state,
        n_init=20,  # ë” ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ìœ„í•´ ì´ˆê¸°í™” íšŸìˆ˜ ì¦ê°€
        max_iter=1000
    )

    # ì§„í–‰ë„ í‘œì‹œì™€ í•¨ê»˜ ì‹¤í–‰
    start_time = time.time()

    print("ğŸ”„ K-Means ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì¤‘...")
    with tqdm(total=100, desc="K-Means Clustering", unit="%") as pbar:
        # ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” fit_predictê°€ í•œë²ˆì— ì‹¤í–‰ë¨)
        for i in range(0, 101, 10):
            if i == 0:
                cluster_labels = kmeans.fit_predict(X)
            pbar.update(10)
            time.sleep(0.05)  # ì§„í–‰ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ì§€ì—°

            if phases and i <= 90:
                update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 25 + (i * 0.75))

    execution_time = time.time() - start_time

    print(f"â° í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")

    # í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ í‰ê°€
    print("ğŸ”„ í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ í‰ê°€ ì¤‘...")
    silhouette_avg = silhouette_score(X, cluster_labels)
    inertia = kmeans.inertia_

    if phases:
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    print(f"ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ ì§€í‘œ:")
    print(f"  Silhouette Score: {silhouette_avg:.4f}")
    print(f"  Inertia (WCSS): {inertia:,.0f}")

    # í´ëŸ¬ìŠ¤í„°ë³„ í¬ê¸° í™•ì¸
    unique, counts = np.unique(cluster_labels, return_counts=True)
    cluster_sizes = dict(zip(unique, counts))

    print(f"ğŸ“ˆ í´ëŸ¬ìŠ¤í„°ë³„ í¬ê¸°:")
    for cluster_id, size in cluster_sizes.items():
        percentage = (size / len(cluster_labels)) * 100
        print(f"  í´ëŸ¬ìŠ¤í„° {cluster_id}: {size:,}ê°œ ({percentage:.1f}%)")

    return kmeans, cluster_labels, {
        'silhouette_score': silhouette_avg,
        'inertia': inertia,
        'cluster_sizes': cluster_sizes,
        'execution_time': execution_time
    }

def analyze_cluster_characteristics(X, cluster_labels, feature_names, phases=None, phase_num=3):
    """í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„ (ì§„í–‰ë„ í¬í•¨)"""
    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 0)

    print(f"\nğŸ” í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„")
    print("-" * 40)

    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    print("ğŸ”„ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    df_analysis = X.copy()
    df_analysis['cluster'] = cluster_labels

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 25)

    # í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„ ê³„ì‚°
    print("ğŸ”„ í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„ ê³„ì‚° ì¤‘...")
    cluster_stats = df_analysis.groupby('cluster').agg(['mean', 'std', 'median']).round(3)

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 50)

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ì£¼ìš” íŠ¹ì§• ì¶”ì¶œ
    cluster_profiles = {}
    n_clusters = len(np.unique(cluster_labels))

    print("ğŸ”„ í´ëŸ¬ìŠ¤í„° í”„ë¡œíŒŒì¼ ìƒì„± ì¤‘...")

    with tqdm(range(n_clusters), desc="Cluster Analysis", unit="cluster") as pbar:
        for i, cluster_id in enumerate(pbar):
            cluster_data = df_analysis[df_analysis['cluster'] == cluster_id]
            cluster_mean = cluster_data.drop('cluster', axis=1).mean()

            # ì „ì²´ í‰ê· ê³¼ ë¹„êµí•˜ì—¬ ìƒìœ„/í•˜ìœ„ íŠ¹ì„± ì°¾ê¸°
            overall_mean = X.mean()
            feature_ratios = cluster_mean / (overall_mean + 1e-8)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

            # ìƒìœ„ 5ê°œì™€ í•˜ìœ„ 5ê°œ íŠ¹ì„±
            top_features = feature_ratios.nlargest(5)
            bottom_features = feature_ratios.nsmallest(5)

            cluster_profiles[cluster_id] = {
                'size': len(cluster_data),
                'percentage': len(cluster_data) / len(df_analysis) * 100,
                'top_features': top_features,
                'bottom_features': bottom_features,
                'mean_values': cluster_mean
            }

            pbar.set_postfix({'cluster': cluster_id, 'size': len(cluster_data)})

            # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
            progress = 50 + ((i + 1) / n_clusters) * 50
            if phases:
                update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", progress)

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ìš”ì•½:")
    for cluster_id, profile in cluster_profiles.items():
        print(f"\nğŸ¯ í´ëŸ¬ìŠ¤í„° {cluster_id} íŠ¹ì„±:")
        print(f"  í¬ê¸°: {profile['size']:,}ê°œ ({profile['percentage']:.1f}%)")
        print(f"  ìƒìœ„ íŠ¹ì„± (í‰ê·  ëŒ€ë¹„):")
        for feature, ratio in profile['top_features'].head(3).items():
            print(f"    {feature:<20}: {ratio:.2f}ë°°")
        print(f"  í•˜ìœ„ íŠ¹ì„± (í‰ê·  ëŒ€ë¹„):")
        for feature, ratio in profile['bottom_features'].head(3).items():
            print(f"    {feature:<20}: {ratio:.2f}ë°°")

    if phases:
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    return cluster_profiles, cluster_stats

def create_cluster_visualization(X, cluster_labels, method='pca', phases=None, phase_num=4):
    """í´ëŸ¬ìŠ¤í„° ì‹œê°í™” (ì°¨ì› ì¶•ì†Œ) (ì§„í–‰ë„ í¬í•¨)"""
    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 0)

    print(f"\nğŸ¨ í´ëŸ¬ìŠ¤í„° ì‹œê°í™” ({method.upper()})")
    print("-" * 40)

    n_clusters = len(np.unique(cluster_labels))

    if method == 'pca':
        # PCAë¥¼ ì‚¬ìš©í•œ 2D ì‹œê°í™”
        print("ğŸ”„ PCA ì°¨ì› ì¶•ì†Œ ì¤‘...")
        from sklearn.decomposition import PCA
        pca = PCA(n_components=2, random_state=42)

        if phases:
            update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 25)

        X_reduced = pca.fit_transform(X)

        explained_variance = pca.explained_variance_ratio_
        print(f"ğŸ“Š PCA ì„¤ëª… ë¶„ì‚°: PC1={explained_variance[0]:.3f}, PC2={explained_variance[1]:.3f}")
        print(f"ğŸ“Š ì´ ì„¤ëª… ë¶„ì‚°: {sum(explained_variance):.3f}")

    elif method == 'tsne':
        # t-SNEë¥¼ ì‚¬ìš©í•œ 2D ì‹œê°í™”
        from sklearn.manifold import TSNE

        # ìƒ˜í”Œë§ (t-SNEëŠ” ê³„ì‚°ì´ ì˜¤ë˜ ê±¸ë¦¼)
        if len(X) > 5000:
            sample_idx = np.random.choice(len(X), 5000, replace=False)
            X_sample = X.iloc[sample_idx]
            labels_sample = cluster_labels[sample_idx]
        else:
            X_sample = X
            labels_sample = cluster_labels

        if phases:
            update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 25)

        print("ğŸ”„ t-SNE ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        X_reduced = tsne.fit_transform(X_sample)
        cluster_labels = labels_sample

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 60)

    # ì‹œê°í™”
    print("ğŸ¨ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    plt.figure(figsize=(15, 5))

    # 1. í´ëŸ¬ìŠ¤í„°ë³„ ì‚°ì ë„
    plt.subplot(1, 3, 1)
    colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))

    for i in range(n_clusters):
        mask = cluster_labels == i
        plt.scatter(X_reduced[mask, 0], X_reduced[mask, 1],
                   c=[colors[i]], label=f'Cluster {i}', alpha=0.6, s=50)

    plt.title(f'Clusters Visualization ({method.upper()})')
    plt.xlabel(f'{method.upper()} Component 1')
    plt.ylabel(f'{method.upper()} Component 2')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)

    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 75)

    # 2. í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ê³¼ í•¨ê»˜ í‘œì‹œ
    plt.subplot(1, 3, 2)
    for i in range(n_clusters):
        mask = cluster_labels == i
        plt.scatter(X_reduced[mask, 0], X_reduced[mask, 1],
                   c=[colors[i]], label=f'Cluster {i}', alpha=0.6, s=30)

        # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê³„ì‚° ë° í‘œì‹œ
        if np.sum(mask) > 0:  # í´ëŸ¬ìŠ¤í„°ì— ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
            center_x = np.mean(X_reduced[mask, 0])
            center_y = np.mean(X_reduced[mask, 1])
            plt.scatter(center_x, center_y, c='black', marker='x', s=200, linewidths=3)
            plt.annotate(f'C{i}', (center_x, center_y), xytext=(5, 5),
                        textcoords='offset points', fontweight='bold')

    plt.title(f'Clusters with Centroids ({method.upper()})')
    plt.xlabel(f'{method.upper()} Component 1')
    plt.ylabel(f'{method.upper()} Component 2')
    plt.grid(True, alpha=0.3)

    # 3. í´ëŸ¬ìŠ¤í„° í¬ê¸° ë¹„êµ
    plt.subplot(1, 3, 3)
    unique, counts = np.unique(cluster_labels, return_counts=True)
    plt.pie(counts, labels=[f'Cluster {i}' for i in unique], autopct='%1.1f%%',
            colors=colors[:len(unique)])
    plt.title('Cluster Size Distribution')

    plt.tight_layout()
    plt.show()

    if phases:
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    return X_reduced

def suggest_cluster_names(cluster_profiles, phases=None, phase_num=5):
    """í´ëŸ¬ìŠ¤í„° íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì´ë¦„ ì œì•ˆ (ì§„í–‰ë„ í¬í•¨)"""
    if phases:
        update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", 0)

    print(f"\nğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ì˜ë¯¸ ë¶„ì„ ë° ì´ë¦„ ì œì•ˆ")
    print("-" * 40)

    cluster_names = {}
    total_clusters = len(cluster_profiles)

    # íŠ¹ì„± ê¸°ë°˜ ì´ë¦„ ì œì•ˆ ë¡œì§
    feature_keywords = {
        'kill': ['Aggressive', 'Fighter', 'Killer'],
        'damage': ['Damager', 'Combatant', 'Attacker'],
        'heal': ['Survivor', 'Medic', 'Cautious'],
        'distance': ['Explorer', 'Wanderer', 'Mobile'],
        'boost': ['Strategic', 'Prepared', 'Tactical'],
        'weapon': ['Collector', 'Arsenal', 'Armed'],
        'assist': ['Supporter', 'Team Player', 'Helper'],
        'efficiency': ['Efficient', 'Optimal', 'Skilled']
    }

    print("ğŸ”„ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ìƒì„± ì¤‘...")

    with tqdm(cluster_profiles.items(), desc="Naming Clusters", unit="cluster") as pbar:
        for i, (cluster_id, profile) in enumerate(pbar):
            top_features = profile['top_features'].head(3)

            # ìƒìœ„ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
            keyword_scores = {}
            for keyword_group, names in feature_keywords.items():
                score = 0
                for feature_name in top_features.index:
                    if keyword_group in feature_name.lower():
                        score += top_features[feature_name]

                if score > 0:
                    for name in names:
                        keyword_scores[name] = keyword_scores.get(name, 0) + score

            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í‚¤ì›Œë“œ ì„ íƒ
            if keyword_scores:
                suggested_name = max(keyword_scores.items(), key=lambda x: x[1])[0]
            else:
                suggested_name = f"Type_{cluster_id}"

            cluster_names[cluster_id] = suggested_name

            pbar.set_postfix({'cluster': cluster_id, 'name': suggested_name})

            # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
            progress = ((i + 1) / total_clusters) * 100
            if phases:
                update_phase_status(phases, phase_num, "ì§„í–‰ì¤‘", progress)

    print("\nğŸ¯ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì œì•ˆ ê²°ê³¼:")
    for cluster_id, name in cluster_names.items():
        profile = cluster_profiles[cluster_id]
        top_features = profile['top_features'].head(2)
        print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° {cluster_id}: '{name}' í”Œë ˆì´ì–´")
        print(f"  ì£¼ìš” íŠ¹ì§•: {', '.join(top_features.index)}")
        print(f"  í¬ê¸°: {profile['size']:,}ëª… ({profile['percentage']:.1f}%)")

    if phases:
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    return cluster_names
```
### 3. ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸
``` python
# 3. ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸

def comprehensive_clustering_pipeline(X, feature_names, max_clusters=12):
    """ì¢…í•©ì ì¸ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (ì§„í–‰ë„ í¬í•¨)"""
    print("ğŸš€ ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*60)

    # ì „ì²´ ì§„í–‰ë„ ì¶”ì ê¸° ì´ˆê¸°í™”
    phases = create_phase_tracker()
    display_phase_status(phases)

    start_time = time.time()
    clustering_results = {}

    # 1. ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰
    print(f"\n{'='*20} 1ë‹¨ê³„: ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰ {'='*20}")
    update_phase_status(phases, 1, "ì§„í–‰ì¤‘", 0)

    optimal_k_elbow, wcss = find_optimal_clusters_elbow(X, max_clusters, phases=phases, phase_num=1)
    optimal_k_silhouette, silhouette_scores = find_optimal_clusters_silhouette(X, max_clusters, phases=phases, phase_num=1)

    # ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
    final_k = determine_final_cluster_number(optimal_k_elbow, optimal_k_silhouette,
                                           silhouette_scores, wcss)

    clustering_results['optimal_clusters'] = {
        'elbow_method': optimal_k_elbow,
        'silhouette_method': optimal_k_silhouette,
        'final_decision': final_k,
        'wcss_values': wcss,
        'silhouette_scores': silhouette_scores
    }

    # 2. K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
    print(f"\n{'='*20} 2ë‹¨ê³„: K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ {'='*20}")
    kmeans_model, cluster_labels, clustering_metrics = perform_kmeans_clustering(
        X, final_k, phases=phases, phase_num=2)

    clustering_results['kmeans_model'] = kmeans_model
    clustering_results['cluster_labels'] = cluster_labels
    clustering_results['clustering_metrics'] = clustering_metrics

    # 3. í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¶„ì„
    print(f"\n{'='*20} 3ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¶„ì„ {'='*20}")
    cluster_profiles, cluster_stats = analyze_cluster_characteristics(
        X, cluster_labels, feature_names, phases=phases, phase_num=3)

    clustering_results['cluster_profiles'] = cluster_profiles
    clustering_results['cluster_stats'] = cluster_stats

    # 4. í´ëŸ¬ìŠ¤í„° ì‹œê°í™”
    print(f"\n{'='*20} 4ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì‹œê°í™” {'='*20}")
    X_reduced_pca = create_cluster_visualization(
        X, cluster_labels, method='pca', phases=phases, phase_num=4)

    clustering_results['visualization_data'] = {
        'pca_components': X_reduced_pca,
        'cluster_labels': cluster_labels
    }

    # 5. í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì œì•ˆ
    print(f"\n{'='*20} 5ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì œì•ˆ {'='*20}")
    cluster_names = suggest_cluster_names(cluster_profiles, phases=phases, phase_num=5)

    clustering_results['cluster_names'] = cluster_names

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    execution_time = time.time() - start_time

    # ìµœì¢… ì™„ë£Œ ìƒíƒœ í‘œì‹œ
    for phase_num in phases.keys():
        update_phase_status(phases, phase_num, "ì™„ë£Œ", 100)

    time.sleep(1)  # ìµœì¢… ìƒíƒœ í™•ì¸ì„ ìœ„í•œ ì ì‹œ ëŒ€ê¸°

    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*20} ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ ìš”ì•½ ğŸ‰ {'='*20}")
    print(f"â° ì´ ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"ğŸ¯ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜: {final_k}ê°œ")
    print(f"ğŸ“Š Silhouette Score: {clustering_metrics['silhouette_score']:.4f}")
    print(f"ğŸ·ï¸ ë°œê²¬ëœ í”Œë ˆì´ì–´ ìœ í˜•:")

    for cluster_id, name in cluster_names.items():
        size = cluster_profiles[cluster_id]['size']
        pct = cluster_profiles[cluster_id]['percentage']
        print(f"  ğŸ® í´ëŸ¬ìŠ¤í„° {cluster_id}: {name} ({size:,}ëª…, {pct:.1f}%)")

    print(f"âœ… Phase 5 ì™„ë£Œ! Phase 6 (ë”¥ëŸ¬ë‹ ë¶„ë¥˜)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return clustering_results

def run_phase5_pipeline(modeling_data):
    """Phase 5 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì§„í–‰ë„ í¬í•¨)"""
    print("ğŸ® PUBG Phase 5: ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§) ì‹œì‘!")
    print("="*60)

    # ë©”ëª¨ë¦¬ í™•ì¸
    check_memory_usage()

    # ëª¨ë¸ë§ ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (íƒ€ê²Ÿ ì œì™¸)
    X_train = modeling_data['X_train']
    feature_names = modeling_data['feature_names']

    print(f"ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„°: {X_train.shape[0]:,}í–‰ x {X_train.shape[1]}ì—´")

    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì•Œë¦¼
    print("\nğŸš€ 5ë‹¨ê³„ í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“‹ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5-10ë¶„")

    # ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
    clustering_results = comprehensive_clustering_pipeline(X_train, feature_names)

    return clustering_results
```
### 4. ì‹¤í–‰ ê°€ì´ë“œ
``` python
# 4. ì‹¤í–‰ ê°€ì´ë“œ

def display_phase5_guide():
    """Phase 5 ì‹¤í–‰ ê°€ì´ë“œ í‘œì‹œ"""
    print("\nğŸ“‹ Phase 5 ì‹¤í–‰ ë°©ë²•:")
    print("="*50)
    print("# 1. Phase 4ì—ì„œ ì¤€ë¹„ëœ ëª¨ë¸ë§ ë°ì´í„° ì‚¬ìš©")
    print("clustering_results = run_phase5_pipeline(modeling_data)")
    print()
    print("# 2. ê²°ê³¼ í™•ì¸")
    print("print('í´ëŸ¬ìŠ¤í„° ìˆ˜:', clustering_results['optimal_clusters']['final_decision'])")
    print("print('í´ëŸ¬ìŠ¤í„° ì´ë¦„:', clustering_results['cluster_names'])")
    print("print('í’ˆì§ˆ ì ìˆ˜:', clustering_results['clustering_metrics']['silhouette_score'])")
    print()
    print("# 3. í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ì¶”ì¶œ")
    print("cluster_labels = clustering_results['cluster_labels']")
    print("cluster_profiles = clustering_results['cluster_profiles']")

# ê°€ì´ë“œ í‘œì‹œ
display_phase5_guide()

print("\nğŸ¯ Phase 5 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ§  ë‹¤ìŒ ë‹¨ê³„: Phase 6 - ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸)")
```

#### 4. ì‹¤í–‰ ê°€ì´ë“œ ê²°ê³¼

``` bash
ğŸ“‹ Phase 5 ì‹¤í–‰ ë°©ë²•:
==================================================
# 1. Phase 4ì—ì„œ ì¤€ë¹„ëœ ëª¨ë¸ë§ ë°ì´í„° ì‚¬ìš©
clustering_results = run_phase5_pipeline(modeling_data)

# 2. ê²°ê³¼ í™•ì¸
print('í´ëŸ¬ìŠ¤í„° ìˆ˜:', clustering_results['optimal_clusters']['final_decision'])
print('í´ëŸ¬ìŠ¤í„° ì´ë¦„:', clustering_results['cluster_names'])
print('í’ˆì§ˆ ì ìˆ˜:', clustering_results['clustering_metrics']['silhouette_score'])

# 3. í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ì¶”ì¶œ
cluster_labels = clustering_results['cluster_labels']
cluster_profiles = clustering_results['cluster_profiles']

ğŸ¯ Phase 5 ì¤€ë¹„ ì™„ë£Œ!
ğŸ§  ë‹¤ìŒ ë‹¨ê³„: Phase 6 - ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸)
```

### 5. ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
``` python
# 5. ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def save_clustering_model(clustering_results, filename='pubg_clustering_model.pkl'):
    """í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥ (ì§„í–‰ë„ í¬í•¨)"""
    import pickle

    print("ğŸ’¾ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥ ì¤‘...")

    # ëª¨ë¸ê³¼ ì£¼ìš” ê²°ê³¼ë§Œ ì €ì¥ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
    save_data = {
        'kmeans_model': clustering_results['kmeans_model'],
        'cluster_names': clustering_results['cluster_names'],
        'cluster_profiles': clustering_results['cluster_profiles'],
        'optimal_clusters': clustering_results['optimal_clusters'],
        'clustering_metrics': clustering_results['clustering_metrics']
    }

    try:
        with tqdm(total=100, desc="Saving Model", unit="%") as pbar:
            with open(filename, 'wb') as f:
                pickle.dump(save_data, f)
                pbar.update(100)

        print(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filename}")
        return True
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def predict_player_cluster(kmeans_model, player_features, cluster_names=None):
    """ì‹ ê·œ í”Œë ˆì´ì–´ì˜ í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ (ì§„í–‰ë„ í¬í•¨)"""
    print("ğŸ”® í”Œë ˆì´ì–´ í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì¤‘...")

    with tqdm(total=100, desc="Predicting", unit="%") as pbar:
        pbar.update(50)
        cluster_id = kmeans_model.predict([player_features])[0]
        pbar.update(50)

    if cluster_names and cluster_id in cluster_names:
        cluster_name = cluster_names[cluster_id]
        print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: í´ëŸ¬ìŠ¤í„° {cluster_id} ({cluster_name})")
    else:
        print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: í´ëŸ¬ìŠ¤í„° {cluster_id}")

    return cluster_id

def generate_clustering_report(clustering_results):
    """í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
    print("ğŸ“„ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    with tqdm(total=100, desc="Generating Report", unit="%") as pbar:
        # ë³´ê³ ì„œ í…œí”Œë¦¿
        report = []
        report.append("=" * 60)
        report.append("ğŸ® PUBG í”Œë ˆì´ì–´ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ë³´ê³ ì„œ")
        report.append("=" * 60)

        pbar.update(20)

        # ê¸°ë³¸ ì •ë³´
        final_k = clustering_results['optimal_clusters']['final_decision']
        silhouette_score = clustering_results['clustering_metrics']['silhouette_score']

        report.append(f"\nğŸ“Š ë¶„ì„ ìš”ì•½:")
        report.append(f"â€¢ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜: {final_k}ê°œ")
        report.append(f"â€¢ í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ (Silhouette Score): {silhouette_score:.4f}")

        pbar.update(30)

        # í´ëŸ¬ìŠ¤í„°ë³„ ìƒì„¸ ì •ë³´
        report.append(f"\nğŸ¯ ë°œê²¬ëœ í”Œë ˆì´ì–´ ìœ í˜•:")

        for cluster_id, name in clustering_results['cluster_names'].items():
            profile = clustering_results['cluster_profiles'][cluster_id]
            report.append(f"\nğŸ® í´ëŸ¬ìŠ¤í„° {cluster_id}: {name}")
            report.append(f"   í¬ê¸°: {profile['size']:,}ëª… ({profile['percentage']:.1f}%)")

            top_features = profile['top_features'].head(3)
            report.append(f"   ì£¼ìš” íŠ¹ì„±:")
            for feature, ratio in top_features.items():
                report.append(f"   â€¢ {feature}: í‰ê·  ëŒ€ë¹„ {ratio:.2f}ë°°")

        pbar.update(30)

        # ì¶”ì²œì‚¬í•­
        report.append(f"\nğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸:")
        report.append("â€¢ ê° í”Œë ˆì´ì–´ ìœ í˜•ë³„ ë§ì¶¤í˜• ì»¨í…ì¸  ì œê³µ ê°€ëŠ¥")
        report.append("â€¢ í”Œë ˆì´ì–´ í–‰ë™ íŒ¨í„´ ê¸°ë°˜ ê²Œì„ ë°¸ëŸ°ì‹± ê°œì„ ")
        report.append("â€¢ ì‹ ê·œ í”Œë ˆì´ì–´ ì˜¨ë³´ë”© ì „ëµ ìµœì í™”")

        pbar.update(20)

        report_text = "\n".join(report)

        # íŒŒì¼ ì €ì¥
        try:
            with open("pubg_clustering_report.txt", "w", encoding="utf-8") as f:
                f.write(report_text)
            print("âœ… ë³´ê³ ì„œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: pubg_clustering_report.txt")
        except:
            pass

        print("\n" + report_text)

        return report_text
```
### ì‹¤í–‰
``` python
# ì§„í–‰ë„ê°€ í¬í•¨ëœ ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì‹¤í–‰
print("ğŸš€ ì§„í–‰ë„ í‘œì‹œì™€ í•¨ê»˜ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘!")

# ëŒ€ì‹œë³´ë“œ ìƒì„± (ì„ íƒì‚¬í•­)
# create_progress_dashboard() # Removed the call to the undefined function

# ì¢…í•© í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ (ëª¨ë“  ì§„í–‰ë„ í‘œì‹œ í¬í•¨)
final_results = run_phase5_pipeline(modeling_data)

# í•µì‹¬ ê²°ê³¼ í™•ì¸
print("\nğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
print('ğŸ“Š í´ëŸ¬ìŠ¤í„° ìˆ˜:', final_results['optimal_clusters']['final_decision'])
print('ğŸ“ˆ í’ˆì§ˆ í‰ê°€:', final_results['clustering_metrics']['silhouette_score'])
print('ğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ìœ í˜•:')
for cluster_id, name in final_results['cluster_names'].items():
    size = final_results['cluster_profiles'][cluster_id]['size']
    pct = final_results['cluster_profiles'][cluster_id]['percentage']
    print(f'   ğŸ® í´ëŸ¬ìŠ¤í„° {cluster_id}: {name} ({size:,}ëª…, {pct:.1f}%)')

# ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
print("\nğŸ“„ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±...")
clustering_report = generate_clustering_report(final_results)

# ëª¨ë¸ ì €ì¥ (ì„ íƒì‚¬í•­)
print("\nğŸ’¾ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥...")
save_success = save_clustering_model(final_results)

print("\nğŸ‰ Phase 5 í´ëŸ¬ìŠ¤í„°ë§ (ì§„í–‰ë„ í¬í•¨) ì™„ë£Œ!")
print("âœ… ë‹¤ìŒ ë‹¨ê³„: Phase 6 - ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ ê°œë°œ")
```

#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ¯ Phase 5: ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§) ì§„í–‰ ìƒí™©
============================================================
âœ… 1ë‹¨ê³„: ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰ - ì™„ë£Œ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
âœ… 2ë‹¨ê³„: K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ - ì™„ë£Œ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
âœ… 3ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¶„ì„ - ì™„ë£Œ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
âœ… 4ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì‹œê°í™” - ì™„ë£Œ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
âœ… 5ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì œì•ˆ - ì™„ë£Œ |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
------------------------------------------------------------

==================== ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ ìš”ì•½ ğŸ‰ ====================
â° ì´ ì‹¤í–‰ ì‹œê°„: 104.5ì´ˆ
ğŸ¯ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜: 8ê°œ
ğŸ“Š Silhouette Score: 0.1391
ğŸ·ï¸ ë°œê²¬ëœ í”Œë ˆì´ì–´ ìœ í˜•:
  ğŸ® í´ëŸ¬ìŠ¤í„° 0: Survivor (14,527ëª…, 18.2%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 1: Survivor (24,981ëª…, 31.2%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 2: Explorer (10,756ëª…, 13.4%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 3: Explorer (15,898ëª…, 19.9%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 4: Explorer (4,312ëª…, 5.4%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 5: Explorer (4,046ëª…, 5.1%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 6: Explorer (5,391ëª…, 6.7%)
  ğŸ® í´ëŸ¬ìŠ¤í„° 7: Aggressive (89ëª…, 0.1%)
âœ… Phase 5 ì™„ë£Œ! Phase 6 (ë”¥ëŸ¬ë‹ ë¶„ë¥˜)ë¡œ ì§„í–‰ ê°€ëŠ¥

ğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½:
ğŸ“Š í´ëŸ¬ìŠ¤í„° ìˆ˜: 8
ğŸ“ˆ í’ˆì§ˆ í‰ê°€: 0.1391231221671035
ğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ìœ í˜•:
   ğŸ® í´ëŸ¬ìŠ¤í„° 0: Survivor (14,527ëª…, 18.2%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 1: Survivor (24,981ëª…, 31.2%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 2: Explorer (10,756ëª…, 13.4%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 3: Explorer (15,898ëª…, 19.9%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 4: Explorer (4,312ëª…, 5.4%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 5: Explorer (4,046ëª…, 5.1%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 6: Explorer (5,391ëª…, 6.7%)
   ğŸ® í´ëŸ¬ìŠ¤í„° 7: Aggressive (89ëª…, 0.1%)

ğŸ“„ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±...
ğŸ“„ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...
Generatingâ€‡Report:â€‡100%
â€‡100/100â€‡[00:00<00:00,â€‡6477.39%/s]
âœ… ë³´ê³ ì„œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: pubg_clustering_report.txt

============================================================
ğŸ® PUBG í”Œë ˆì´ì–´ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ë³´ê³ ì„œ
============================================================

ğŸ“Š ë¶„ì„ ìš”ì•½:
â€¢ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìˆ˜: 8ê°œ
â€¢ í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ (Silhouette Score): 0.1391

ğŸ¯ ë°œê²¬ëœ í”Œë ˆì´ì–´ ìœ í˜•:

ğŸ® í´ëŸ¬ìŠ¤í„° 0: Survivor
   í¬ê¸°: 14,527ëª… (18.2%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ heal_boost_ratio: í‰ê·  ëŒ€ë¹„ 775.29ë°°
   â€¢ assists: í‰ê·  ëŒ€ë¹„ 479.86ë°°
   â€¢ has_swimDistance: í‰ê·  ëŒ€ë¹„ 294.02ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 1: Survivor
   í¬ê¸°: 24,981ëª… (31.2%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ heal_boost_ratio: í‰ê·  ëŒ€ë¹„ 1861.49ë°°
   â€¢ assists: í‰ê·  ëŒ€ë¹„ 964.62ë°°
   â€¢ damage_per_kill: í‰ê·  ëŒ€ë¹„ 864.65ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 2: Explorer
   í¬ê¸°: 10,756ëª… (13.4%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ walkDistance_log: í‰ê·  ëŒ€ë¹„ 3743.08ë°°
   â€¢ walkDistance: í‰ê·  ëŒ€ë¹„ 1179.09ë°°
   â€¢ revives: í‰ê·  ëŒ€ë¹„ 626.25ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 3: Explorer
   í¬ê¸°: 15,898ëª… (19.9%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ walkDistance_log: í‰ê·  ëŒ€ë¹„ 2245.80ë°°
   â€¢ longestKill: í‰ê·  ëŒ€ë¹„ 610.84ë°°
   â€¢ has_kills: í‰ê·  ëŒ€ë¹„ 501.94ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 4: Explorer
   í¬ê¸°: 4,312ëª… (5.4%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ walkDistance_log: í‰ê·  ëŒ€ë¹„ 4451.52ë°°
   â€¢ walkDistance: í‰ê·  ëŒ€ë¹„ 1845.04ë°°
   â€¢ revives: í‰ê·  ëŒ€ë¹„ 1551.02ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 5: Explorer
   í¬ê¸°: 4,046ëª… (5.1%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ walkDistance_log: í‰ê·  ëŒ€ë¹„ 4139.77ë°°
   â€¢ walkDistance: í‰ê·  ëŒ€ë¹„ 1544.91ë°°
   â€¢ weaponsAcquired: í‰ê·  ëŒ€ë¹„ 451.79ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 6: Explorer
   í¬ê¸°: 5,391ëª… (6.7%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ walkDistance_log: í‰ê·  ëŒ€ë¹„ 3995.30ë°°
   â€¢ matchDuration: í‰ê·  ëŒ€ë¹„ 1400.69ë°°
   â€¢ walkDistance: í‰ê·  ëŒ€ë¹„ 1327.73ë°°

ğŸ® í´ëŸ¬ìŠ¤í„° 7: Aggressive
   í¬ê¸°: 89ëª… (0.1%)
   ì£¼ìš” íŠ¹ì„±:
   â€¢ kill_efficiency: í‰ê·  ëŒ€ë¹„ 23396.88ë°°
   â€¢ damage_per_kill: í‰ê·  ëŒ€ë¹„ 1435.73ë°°
   â€¢ assists: í‰ê·  ëŒ€ë¹„ 920.03ë°°

ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸:
â€¢ ê° í”Œë ˆì´ì–´ ìœ í˜•ë³„ ë§ì¶¤í˜• ì»¨í…ì¸  ì œê³µ ê°€ëŠ¥
â€¢ í”Œë ˆì´ì–´ í–‰ë™ íŒ¨í„´ ê¸°ë°˜ ê²Œì„ ë°¸ëŸ°ì‹± ê°œì„ 
â€¢ ì‹ ê·œ í”Œë ˆì´ì–´ ì˜¨ë³´ë”© ì „ëµ ìµœì í™”

ğŸ’¾ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥...
ğŸ’¾ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥ ì¤‘...
Savingâ€‡Model:â€‡100%
â€‡100/100â€‡[00:00<00:00,â€‡4755.55%/s]
âœ… í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: pubg_clustering_model.pkl

ğŸ‰ Phase 5 í´ëŸ¬ìŠ¤í„°ë§ (ì§„í–‰ë„ í¬í•¨) ì™„ë£Œ!
âœ… ë‹¤ìŒ ë‹¨ê³„: Phase 6 - ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ ê°œë°œ
```

## Phase 6: ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸)

### 1. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
``` python

print("ğŸ§  Phase 6: ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸) ì‹œì‘!")
print("="*60)

# 1. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤

def prepare_classification_data(modeling_data, clustering_results):
    """ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
    print("ğŸ¯ ë¶„ë¥˜ ëª¨ë¸ìš© ë°ì´í„° ì¤€ë¹„")
    print("-" * 40)

    # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”ì„ íƒ€ê²Ÿìœ¼ë¡œ ì‚¬ìš©
    X_train = modeling_data['X_train']
    X_test = modeling_data['X_test']

    # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” (Phase 5ì—ì„œ ìƒì„±ëœ ê²ƒ)
    cluster_labels = clustering_results['cluster_labels']
    n_clusters = len(np.unique(cluster_labels))

    # í›ˆë ¨ ë°ì´í„°ì˜ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ì‚¬ìš©
    y_train_clusters = cluster_labels

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œë„ í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ (K-Means ëª¨ë¸ ì‚¬ìš©)
    kmeans_model = clustering_results['kmeans_model']
    y_test_clusters = kmeans_model.predict(X_test)

    print(f"ğŸ“Š ë¶„ë¥˜ ë°ì´í„° ì •ë³´:")
    print(f"  í›ˆë ¨ íŠ¹ì„±: {X_train.shape}")
    print(f"  í…ŒìŠ¤íŠ¸ íŠ¹ì„±: {X_test.shape}")
    print(f"  í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    print(f"  í´ëŸ¬ìŠ¤í„° ë¶„í¬ (í›ˆë ¨):")

    unique, counts = np.unique(y_train_clusters, return_counts=True)
    for cluster_id, count in zip(unique, counts):
        percentage = count / len(y_train_clusters) * 100
        cluster_name = clustering_results['cluster_names'].get(cluster_id, f'Cluster_{cluster_id}')
        print(f"    {cluster_name}: {count:,}ê°œ ({percentage:.1f}%)")

    return {
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train_clusters,
        'y_test': y_test_clusters,
        'n_classes': n_clusters,
        'feature_names': modeling_data['feature_names'],
        'cluster_names': clustering_results['cluster_names']
    }

def create_validation_split(X_train, y_train, validation_split=0.2, random_state=42):
    """ê²€ì¦ìš© ë°ì´í„° ë¶„í• """
    print(f"ğŸ”€ ê²€ì¦ ë°ì´í„° ë¶„í•  ({validation_split*100:.0f}%)")
    print("-" * 40)

    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
        X_train, y_train,
        test_size=validation_split,
        random_state=random_state,
        stratify=y_train  # í´ëŸ¬ìŠ¤í„° ë¹„ìœ¨ ìœ ì§€
    )

    print(f"ğŸ“Š ë¶„í•  ê²°ê³¼:")
    print(f"  í›ˆë ¨ ì„¸íŠ¸: {X_train_split.shape[0]:,}ê°œ")
    print(f"  ê²€ì¦ ì„¸íŠ¸: {X_val_split.shape[0]:,}ê°œ")

    return X_train_split, X_val_split, y_train_split, y_val_split
```
### 2. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì•„í‚¤í…ì²˜ í•¨ìˆ˜ë“¤
``` python
# 2. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì•„í‚¤í…ì²˜ í•¨ìˆ˜ë“¤

def create_basic_neural_network(input_dim, n_classes, hidden_units=[128, 64, 32]):
    """ê¸°ë³¸ ì‹ ê²½ë§ ëª¨ë¸ ìƒì„±"""
    print(f"ğŸ§  ê¸°ë³¸ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•")
    print(f"  ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"  ì¶œë ¥ í´ë˜ìŠ¤: {n_classes}")
    print(f"  ì€ë‹‰ì¸µ: {hidden_units}")
    print("-" * 40)

    model = keras.Sequential([
        # ì…ë ¥ì¸µ
        layers.Dense(hidden_units[0], activation='relu', input_shape=(input_dim,)),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ
        layers.Dense(hidden_units[1], activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ
        layers.Dense(hidden_units[2], activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.2),

        # ì¶œë ¥ì¸µ
        layers.Dense(n_classes, activation='softmax')
    ])

    return model

def create_advanced_neural_network(input_dim, n_classes):
    """ê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± (ë” ë³µì¡í•œ ì•„í‚¤í…ì²˜)"""
    print(f"ğŸš€ ê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•")
    print(f"  ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"  ì¶œë ¥ í´ë˜ìŠ¤: {n_classes}")
    print("-" * 40)

    # í•¨ìˆ˜í˜• API ì‚¬ìš©
    inputs = layers.Input(shape=(input_dim,))

    # ì²« ë²ˆì§¸ ë¸Œëœì¹˜
    x1 = layers.Dense(256, activation='relu')(inputs)
    x1 = layers.BatchNormalization()(x1)
    x1 = layers.Dropout(0.4)(x1)

    x1 = layers.Dense(128, activation='relu')(x1)
    x1 = layers.BatchNormalization()(x1)
    x1 = layers.Dropout(0.3)(x1)

    # ë‘ ë²ˆì§¸ ë¸Œëœì¹˜
    x2 = layers.Dense(128, activation='relu')(inputs)
    x2 = layers.BatchNormalization()(x2)
    x2 = layers.Dropout(0.3)(x2)

    x2 = layers.Dense(64, activation='relu')(x2)
    x2 = layers.BatchNormalization()(x2)
    x2 = layers.Dropout(0.2)(x2)

    # ë¸Œëœì¹˜ ê²°í•©
    combined = layers.concatenate([x1, x2])

    # ìµœì¢… ë ˆì´ì–´ë“¤
    x = layers.Dense(64, activation='relu')(combined)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Dense(32, activation='relu')(x)
    x = layers.Dropout(0.1)(x)

    # ì¶œë ¥ì¸µ
    outputs = layers.Dense(n_classes, activation='softmax')(x)

    model = Model(inputs=inputs, outputs=outputs)

    return model

def create_residual_network(input_dim, n_classes):
    """Residual Connectionì„ í¬í•¨í•œ ì‹ ê²½ë§"""
    print(f"ğŸ”— Residual ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•")
    print("-" * 40)

    inputs = layers.Input(shape=(input_dim,))

    # ì²« ë²ˆì§¸ ë¸”ë¡
    x = layers.Dense(128, activation='relu')(inputs)
    x = layers.BatchNormalization()(x)

    # Residual ë¸”ë¡ 1
    residual = x
    x = layers.Dense(128, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Add()([x, residual])  # Skip connection
    x = layers.Activation('relu')(x)

    # Residual ë¸”ë¡ 2
    residual = layers.Dense(64)(x)  # ì°¨ì› ë§ì¶¤
    x = layers.Dense(64, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.2)(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Add()([x, residual])
    x = layers.Activation('relu')(x)

    # ì¶œë ¥ì¸µ
    x = layers.Dense(32, activation='relu')(x)
    x = layers.Dropout(0.1)(x)
    outputs = layers.Dense(n_classes, activation='softmax')(x)

    model = Model(inputs=inputs, outputs=outputs)

    return model
```
### 3. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ë“¤
``` python
# 3. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ë“¤

def compile_and_train_model(model, X_train, y_train, X_val, y_val,
                           epochs=100, batch_size=256, learning_rate=0.001):
    """ëª¨ë¸ ì»´íŒŒì¼ ë° í›ˆë ¨"""
    print(f"ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print(f"  ì—í¬í¬: {epochs}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"  í•™ìŠµë¥ : {learning_rate}")
    print("-" * 40)

    # ëª¨ë¸ ì»´íŒŒì¼
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    # ì½œë°± ì„¤ì •
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        )
    ]

    # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
    print("ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜:")
    model.summary()

    # í›ˆë ¨ ì‹œì‘
    print("\nğŸ”„ ëª¨ë¸ í›ˆë ¨ ì§„í–‰ ì¤‘...")
    start_time = time.time()

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=callbacks,
        verbose=1
    )

    training_time = time.time() - start_time
    print(f"â° í›ˆë ¨ ì™„ë£Œ ì‹œê°„: {training_time:.1f}ì´ˆ")

    return model, history

def evaluate_model_performance(model, X_test, y_test, cluster_names):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    print("-" * 40)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred_proba = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_pred_proba, axis=1)

    # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ğŸ¯ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")

    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¦¬í¬íŠ¸
    class_names = [cluster_names.get(i, f'Cluster_{i}') for i in range(len(cluster_names))]
    classification_rep = classification_report(y_test, y_pred,
                                             target_names=class_names,
                                             output_dict=True)

    print(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    for class_name in class_names:
        if class_name in classification_rep:
            metrics = classification_rep[class_name]
            print(f"  {class_name:<15}: "
                  f"ì •ë°€ë„={metrics['precision']:.3f}, "
                  f"ì¬í˜„ìœ¨={metrics['recall']:.3f}, "
                  f"F1={metrics['f1-score']:.3f}")

    # ì „ì²´ í‰ê· 
    macro_avg = classification_rep['macro avg']
    weighted_avg = classification_rep['weighted avg']

    print(f"\nğŸ“Š ì „ì²´ í‰ê· :")
    print(f"  Macro Avg    : F1={macro_avg['f1-score']:.3f}")
    print(f"  Weighted Avg : F1={weighted_avg['f1-score']:.3f}")

    return {
        'accuracy': accuracy,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'classification_report': classification_rep
    }

def create_confusion_matrix_plot(y_test, y_pred, cluster_names):
    """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
    print(f"\nğŸ”„ í˜¼ë™ í–‰ë ¬ ìƒì„±")
    print("-" * 40)

    from sklearn.metrics import confusion_matrix

    # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
    cm = confusion_matrix(y_test, y_pred)

    # í´ë˜ìŠ¤ ì´ë¦„
    class_names = [cluster_names.get(i, f'C{i}') for i in range(len(cluster_names))]

    # ì‹œê°í™”
    plt.figure(figsize=(12, 10))

    # ì •ê·œí™”ëœ í˜¼ë™ í–‰ë ¬
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    # íˆíŠ¸ë§µ ìƒì„±
    sns.heatmap(cm_normalized,
                annot=True,
                fmt='.2f',
                cmap='Blues',
                xticklabels=class_names,
                yticklabels=class_names,
                square=True)

    plt.title('Confusion Matrix (Normalized)', fontsize=16, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # ë¶„ë¥˜ ì •í™•ë„ (ëŒ€ê°ì„  ì„±ë¶„)
    class_accuracies = cm.diagonal() / cm.sum(axis=1)

    print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ ì •í™•ë„:")
    for i, (class_name, acc) in enumerate(zip(class_names, class_accuracies)):
        print(f"  {class_name:<15}: {acc:.3f} ({acc*100:.1f}%)")

    return cm, cm_normalized

def plot_training_history(history):
    """í›ˆë ¨ ê³¼ì • ì‹œê°í™”"""
    print(f"\nğŸ“ˆ í›ˆë ¨ ê³¼ì • ì‹œê°í™”")
    print("-" * 40)

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # ì†ì‹¤ í•¨ìˆ˜
    axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)
    axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
    axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # ì •í™•ë„
    axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)
    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
    axes[1].set_title('Model Accuracy', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]

    print(f"ğŸ“Š ìµœì¢… í›ˆë ¨ ì„±ëŠ¥:")
    print(f"  í›ˆë ¨ ì •í™•ë„: {final_train_acc:.4f}")
    print(f"  ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f}")
    print(f"  í›ˆë ¨ ì†ì‹¤: {final_train_loss:.4f}")
    print(f"  ê²€ì¦ ì†ì‹¤: {final_val_loss:.4f}")

    # ê³¼ì í•© ì—¬ë¶€ í™•ì¸
    overfitting_gap = final_train_acc - final_val_acc
    if overfitting_gap > 0.1:
        print(f"âš ï¸ ê³¼ì í•© ì˜ì‹¬ (ì°¨ì´: {overfitting_gap:.3f})")
    else:
        print(f"âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ (ì°¨ì´: {overfitting_gap:.3f})")
```
### 4. ëª¨ë¸ í•´ì„ ë° íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
``` python
# 4. ëª¨ë¸ í•´ì„ ë° íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„

def analyze_feature_importance_with_permutation(model, X_test, y_test, feature_names):
    """Permutation Importanceë¥¼ ì‚¬ìš©í•œ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"""
    print(f"\nğŸ” Permutation Importance íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
    print("-" * 40)

    from sklearn.inspection import permutation_importance

    # ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥
    baseline_accuracy = model.evaluate(X_test, y_test, verbose=0)[1]

    # ê° íŠ¹ì„±ì„ í•˜ë‚˜ì”© ì…”í”Œí•˜ì—¬ ì„±ëŠ¥ ë³€í™” ì¸¡ì •
    feature_importance_scores = []

    print("ğŸ”„ íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...")
    for i, feature_name in enumerate(feature_names):
        if i % 10 == 0:  # ì§„í–‰ìƒí™© í‘œì‹œ
            print(f"  ì§„í–‰: {i+1}/{len(feature_names)}")

        # íŠ¹ì„± ë³µì‚¬ ë° ì…”í”Œ
        X_test_shuffled = X_test.copy()
        np.random.shuffle(X_test_shuffled.iloc[:, i].values)

        # ì…”í”Œëœ ë°ì´í„°ë¡œ ì„±ëŠ¥ ì¸¡ì •
        shuffled_accuracy = model.evaluate(X_test_shuffled, y_test, verbose=0)[1]

        # ì¤‘ìš”ë„ = ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ - ì…”í”Œëœ ì„±ëŠ¥
        importance = baseline_accuracy - shuffled_accuracy
        feature_importance_scores.append(importance)

    # ê²°ê³¼ ì •ë¦¬
    feature_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance_scores
    }).sort_values('importance', ascending=False)

    # ìƒìœ„ 15ê°œ íŠ¹ì„± ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    top_features = feature_importance_df.head(15)

    bars = plt.barh(range(len(top_features)), top_features['importance'],
                    color=plt.cm.viridis(np.linspace(0, 1, len(top_features))))

    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Feature Importance (Accuracy Drop)')
    plt.title('Top 15 Feature Importance (Permutation Method)',
              fontsize=14, fontweight='bold')
    plt.gca().invert_yaxis()

    # ê°’ í‘œì‹œ
    for i, (bar, importance) in enumerate(zip(bars, top_features['importance'])):
        plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
                f'{importance:.4f}', va='center', fontsize=9)

    plt.tight_layout()
    plt.show()

    print(f"ğŸ“Š ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:")
    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):
        print(f"  {i+1:2d}. {row['feature']:<25}: {row['importance']:.4f}")

    return feature_importance_df

def create_prediction_confidence_analysis(y_pred_proba, y_test, cluster_names):
    """ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„"""
    print(f"\nğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„")
    print("-" * 40)

    # ìµœëŒ€ í™•ë¥  (ì‹ ë¢°ë„)
    max_probabilities = np.max(y_pred_proba, axis=1)

    # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ì •í™•ë„ ë¶„ì„
    confidence_bins = np.linspace(0, 1, 11)  # 0.0, 0.1, 0.2, ..., 1.0
    bin_accuracies = []
    bin_counts = []

    for i in range(len(confidence_bins)-1):
        lower_bound = confidence_bins[i]
        upper_bound = confidence_bins[i+1]

        # í•´ë‹¹ ì‹ ë¢°ë„ êµ¬ê°„ì— ì†í•˜ëŠ” ì˜ˆì¸¡ë“¤
        mask = (max_probabilities >= lower_bound) & (max_probabilities < upper_bound)

        if np.sum(mask) > 0:
            bin_predictions = np.argmax(y_pred_proba[mask], axis=1)
            bin_true_labels = y_test[mask]
            bin_accuracy = np.mean(bin_predictions == bin_true_labels)
            bin_accuracies.append(bin_accuracy)
            bin_counts.append(np.sum(mask))
        else:
            bin_accuracies.append(0)
            bin_counts.append(0)

    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # ì‹ ë¢°ë„ ë¶„í¬
    axes[0].hist(max_probabilities, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0].axvline(np.mean(max_probabilities), color='red', linestyle='--',
                   label=f'Mean: {np.mean(max_probabilities):.3f}')
    axes[0].set_xlabel('Prediction Confidence')
    axes[0].set_ylabel('Frequency')
    axes[0].set_title('Distribution of Prediction Confidence')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # ì‹ ë¢°ë„ë³„ ì •í™•ë„
    bin_centers = (confidence_bins[:-1] + confidence_bins[1:]) / 2
    axes[1].bar(bin_centers, bin_accuracies, width=0.08, alpha=0.7,
               color='lightcoral', edgecolor='black')
    axes[1].set_xlabel('Confidence Interval')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_title('Accuracy by Confidence Level')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # í†µê³„ ìš”ì•½
    print(f"ğŸ“Š ì‹ ë¢°ë„ í†µê³„:")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {np.mean(max_probabilities):.3f}")
    print(f"  ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: {np.std(max_probabilities):.3f}")
    print(f"  ë†’ì€ ì‹ ë¢°ë„ (>0.8) ë¹„ìœ¨: {np.mean(max_probabilities > 0.8)*100:.1f}%")
    print(f"  ë‚®ì€ ì‹ ë¢°ë„ (<0.5) ë¹„ìœ¨: {np.mean(max_probabilities < 0.5)*100:.1f}%")

    return max_probabilities, bin_accuracies
```
### 5. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ë° ì•™ìƒë¸”
``` python
# 5. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ë° ì•™ìƒë¸”

def train_multiple_models(classification_data):
    """ì—¬ëŸ¬ ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ"""
    print(f"\nğŸ† ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ë¶„ì„")
    print("="*50)

    X_train = classification_data['X_train']
    y_train = classification_data['y_train']
    n_classes = classification_data['n_classes']
    input_dim = X_train.shape[1]

    # ê²€ì¦ ë°ì´í„° ë¶„í• 
    X_train_split, X_val_split, y_train_split, y_val_split = create_validation_split(
        X_train, y_train, validation_split=0.2
    )

    models = {}
    histories = {}

    # 1. ê¸°ë³¸ ëª¨ë¸
    print(f"\n{'='*20} ê¸°ë³¸ ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ {'='*20}")
    basic_model = create_basic_neural_network(input_dim, n_classes)
    basic_model, basic_history = compile_and_train_model(
        basic_model, X_train_split, y_train_split, X_val_split, y_val_split,
        epochs=50, batch_size=256
    )
    models['Basic'] = basic_model
    histories['Basic'] = basic_history

    # 2. ê³ ê¸‰ ëª¨ë¸
    print(f"\n{'='*20} ê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ {'='*20}")
    advanced_model = create_advanced_neural_network(input_dim, n_classes)
    advanced_model, advanced_history = compile_and_train_model(
        advanced_model, X_train_split, y_train_split, X_val_split, y_val_split,
        epochs=50, batch_size=256
    )
    models['Advanced'] = advanced_model
    histories['Advanced'] = advanced_history

    # 3. Residual ëª¨ë¸
    print(f"\n{'='*20} Residual ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ {'='*20}")
    residual_model = create_residual_network(input_dim, n_classes)
    residual_model, residual_history = compile_and_train_model(
        residual_model, X_train_split, y_train_split, X_val_split, y_val_split,
        epochs=50, batch_size=256
    )
    models['Residual'] = residual_model
    histories['Residual'] = residual_history

    return models, histories, (X_val_split, y_val_split)

def compare_model_performances(models, X_test, y_test, cluster_names):
    """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("="*50)

    model_performances = {}

    for model_name, model in models.items():
        print(f"\nğŸ” {model_name} ëª¨ë¸ í‰ê°€:")
        performance = evaluate_model_performance(model, X_test, y_test, cluster_names)
        model_performances[model_name] = performance

        print(f"  ì •í™•ë„: {performance['accuracy']:.4f}")
        print(f"  F1 (Macro): {performance['classification_report']['macro avg']['f1-score']:.4f}")

    # ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
    model_names = list(model_performances.keys())
    accuracies = [model_performances[name]['accuracy'] for name in model_names]
    f1_scores = [model_performances[name]['classification_report']['macro avg']['f1-score']
                 for name in model_names]

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # ì •í™•ë„ ë¹„êµ
    bars1 = axes[0].bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])
    axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_ylim(0, 1)

    for bar, acc in zip(bars1, accuracies):
        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

    # F1 ì ìˆ˜ ë¹„êµ
    bars2 = axes[1].bar(model_names, f1_scores, color=['skyblue', 'lightgreen', 'lightcoral'])
    axes[1].set_title('Model F1-Score Comparison', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('F1-Score (Macro Average)')
    axes[1].set_ylim(0, 1)

    for bar, f1 in zip(bars2, f1_scores):
        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.show()

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_model_name = max(model_performances.keys(),
                         key=lambda x: model_performances[x]['accuracy'])

    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"  ì •í™•ë„: {model_performances[best_model_name]['accuracy']:.4f}")

    return model_performances, best_model_name

def create_ensemble_model(models, X_test, y_test):
    """ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (ì†Œí”„íŠ¸ ë³´íŒ…)"""
    print(f"\nğŸ¤ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (ì†Œí”„íŠ¸ ë³´íŒ…)")
    print("-" * 40)

    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  ìˆ˜ì§‘
    model_predictions = []
    for model_name, model in models.items():
        pred_proba = model.predict(X_test, verbose=0)
        model_predictions.append(pred_proba)
        print(f"âœ… {model_name} ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ")

    # í‰ê·  ì•™ìƒë¸”
    ensemble_proba = np.mean(model_predictions, axis=0)
    ensemble_pred = np.argmax(ensemble_proba, axis=1)

    # ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
    ensemble_accuracy = accuracy_score(y_test, ensemble_pred)

    print(f"ğŸ“Š ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
    print(f"  ì •í™•ë„: {ensemble_accuracy:.4f}")

    # ê°œë³„ ëª¨ë¸ê³¼ ë¹„êµ
    print(f"\nğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ:")
    for model_name, model in models.items():
        individual_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
        individual_acc = accuracy_score(y_test, individual_pred)
        improvement = ensemble_accuracy - individual_acc
        print(f"  vs {model_name}: {improvement:+.4f} ({improvement*100:+.2f}%)")

    return ensemble_pred, ensemble_proba, ensemble_accuracy
```
### 6. ì¢…í•© ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
``` python
# 6. ì¢…í•© ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸

def comprehensive_deep_learning_pipeline(modeling_data, clustering_results):
    """ì¢…í•©ì ì¸ ë”¥ëŸ¬ë‹ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸"""
    print("ğŸš€ ì¢…í•© ë”¥ëŸ¬ë‹ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*60)

    start_time = time.time()
    dl_results = {}

    # 1. ë¶„ë¥˜ ë°ì´í„° ì¤€ë¹„
    print(f"\n{'='*20} 1ë‹¨ê³„: ë¶„ë¥˜ ë°ì´í„° ì¤€ë¹„ {'='*20}")
    classification_data = prepare_classification_data(modeling_data, clustering_results)
    dl_results['classification_data'] = classification_data

    # 2. ë‹¤ì¤‘ ëª¨ë¸ í›ˆë ¨
    print(f"\n{'='*20} 2ë‹¨ê³„: ë‹¤ì¤‘ ëª¨ë¸ í›ˆë ¨ {'='*20}")
    models, histories, validation_data = train_multiple_models(classification_data)
    dl_results['models'] = models
    dl_results['histories'] = histories

    # 3. í›ˆë ¨ ê³¼ì • ì‹œê°í™”
    print(f"\n{'='*20} 3ë‹¨ê³„: í›ˆë ¨ ê³¼ì • ì‹œê°í™” {'='*20}")
    for model_name, history in histories.items():
        print(f"\nğŸ“ˆ {model_name} ëª¨ë¸ í›ˆë ¨ ê³¼ì •:")
        plot_training_history(history)

    # 4. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ
    print(f"\n{'='*20} 4ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ {'='*20}")
    X_test = classification_data['X_test']
    y_test = classification_data['y_test']
    cluster_names = classification_data['cluster_names']

    model_performances, best_model_name = compare_model_performances(
        models, X_test, y_test, cluster_names
    )
    dl_results['model_performances'] = model_performances
    dl_results['best_model_name'] = best_model_name

    # 5. ìµœê³  ëª¨ë¸ ìƒì„¸ ë¶„ì„
    print(f"\n{'='*20} 5ë‹¨ê³„: ìµœê³  ëª¨ë¸ ìƒì„¸ ë¶„ì„ {'='*20}")
    best_model = models[best_model_name]

    # í˜¼ë™ í–‰ë ¬
    best_performance = model_performances[best_model_name]
    cm, cm_normalized = create_confusion_matrix_plot(
        y_test, best_performance['y_pred'], cluster_names
    )

    # ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„
    confidence_scores, bin_accuracies = create_prediction_confidence_analysis(
        best_performance['y_pred_proba'], y_test, cluster_names
    )

    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
    feature_importance = analyze_feature_importance_with_permutation(
        best_model, X_test, y_test, classification_data['feature_names']
    )

    dl_results['detailed_analysis'] = {
        'confusion_matrix': cm_normalized,
        'confidence_analysis': confidence_scores,
        'feature_importance': feature_importance
    }

    # 6. ì•™ìƒë¸” ëª¨ë¸
    print(f"\n{'='*20} 6ë‹¨ê³„: ì•™ìƒë¸” ëª¨ë¸ {'='*20}")
    ensemble_pred, ensemble_proba, ensemble_accuracy = create_ensemble_model(
        models, X_test, y_test
    )

    dl_results['ensemble'] = {
        'predictions': ensemble_pred,
        'probabilities': ensemble_proba,
        'accuracy': ensemble_accuracy
    }

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    execution_time = time.time() - start_time

    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*20} ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ìš”ì•½ {'='*20}")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"ğŸ¯ í›ˆë ¨ëœ ëª¨ë¸ ìˆ˜: {len(models)}ê°œ")
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"ğŸ“Š ìµœê³  ëª¨ë¸ ì„±ëŠ¥:")
    best_perf = model_performances[best_model_name]
    print(f"  ì •í™•ë„: {best_perf['accuracy']:.4f}")
    print(f"  F1 (Macro): {best_perf['classification_report']['macro avg']['f1-score']:.4f}")
    print(f"ğŸ¤ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥: {ensemble_accuracy:.4f}")

    # ì„±ëŠ¥ í–¥ìƒë„ ê³„ì‚°
    improvement = ensemble_accuracy - best_perf['accuracy']
    print(f"ğŸš€ ì•™ìƒë¸” í–¥ìƒë„: {improvement:+.4f} ({improvement*100:+.2f}%)")

    print(f"âœ… Phase 6 ì™„ë£Œ! Phase 7 (ëª¨ë¸ í•´ì„)ë¡œ ì§„í–‰ ê°€ëŠ¥")

    return dl_results
```
### 7. ì‹¤í–‰ í•¨ìˆ˜
``` python
# 7. ì‹¤í–‰ í•¨ìˆ˜

def run_phase6_pipeline(modeling_data, clustering_results):
    """Phase 6 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("ğŸ® PUBG Phase 6: ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜) ì‹œì‘!")
    print("="*60)

    # ë©”ëª¨ë¦¬ í™•ì¸
    check_memory_usage()

    # GPU ì‚¬ìš© í™•ì¸
    print(f"ğŸ”§ GPU ì‚¬ìš© ê°€ëŠ¥: {len(tf.config.list_physical_devices('GPU')) > 0}")

    # ì¢…í•© ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    dl_results = comprehensive_deep_learning_pipeline(modeling_data, clustering_results)

    return dl_results
```
### 8. ëª¨ë¸ ì €ì¥ ë° ë°°í¬ ì¤€ë¹„
``` python
# 8. ëª¨ë¸ ì €ì¥ ë° ë°°í¬ ì¤€ë¹„

def save_best_model(dl_results, save_path='pubg_best_model'):
    """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥"""
    print(f"\nğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥")
    print("-" * 40)

    best_model_name = dl_results['best_model_name']
    best_model = dl_results['models'][best_model_name]

    # ëª¨ë¸ ì €ì¥
    best_model.save(f'{save_path}.h5')
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}.h5")

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'model_name': best_model_name,
        'accuracy': dl_results['model_performances'][best_model_name]['accuracy'],
        'feature_names': dl_results['classification_data']['feature_names'],
        'cluster_names': dl_results['classification_data']['cluster_names'],
        'n_classes': dl_results['classification_data']['n_classes']
    }

    import json
    with open(f'{save_path}_metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)

    print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {save_path}_metadata.json")

    return save_path

def create_prediction_function(model_path, metadata_path):
    """ìƒˆë¡œìš´ í”Œë ˆì´ì–´ ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±"""
    print(f"\nğŸ¯ ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±")
    print("-" * 40)

    # ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
    model = keras.models.load_model(model_path)

    with open(metadata_path, 'r') as f:
        metadata = json.load(f)

    def predict_player_type(player_features):
        """
        ìƒˆë¡œìš´ í”Œë ˆì´ì–´ì˜ ìœ í˜•ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜

        Args:
            player_features: í”Œë ˆì´ì–´ íŠ¹ì„± ë²¡í„° (numpy array ë˜ëŠ” list)

        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼ (í´ëŸ¬ìŠ¤í„° ì´ë¦„, í™•ë¥  ë“±)
        """
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction_proba = model.predict(np.array([player_features]), verbose=0)[0]
        predicted_cluster = np.argmax(prediction_proba)
        confidence = np.max(prediction_proba)

        # ê²°ê³¼ ë°˜í™˜
        cluster_names = metadata['cluster_names']
        predicted_name = cluster_names.get(str(predicted_cluster), f'Cluster_{predicted_cluster}')

        return {
            'predicted_cluster': int(predicted_cluster),
            'predicted_type': predicted_name,
            'confidence': float(confidence),
            'all_probabilities': {
                cluster_names.get(str(i), f'Cluster_{i}'): float(prob)
                for i, prob in enumerate(prediction_proba)
            }
        }

    print(f"âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„± ì™„ë£Œ")
    print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"  íŠ¹ì„± ìˆ˜: {len(metadata['feature_names'])}")
    print(f"  í´ëŸ¬ìŠ¤í„° ìˆ˜: {metadata['n_classes']}")
    print(f"  ëª¨ë¸ ì •í™•ë„: {metadata['accuracy']:.4f}")

    return predict_player_type
```
### 9. ì‹¤í–‰ ê°€ì´ë“œ
``` python
# 9. ì‹¤í–‰ ê°€ì´ë“œ

def display_phase6_guide():
    """Phase 6 ì‹¤í–‰ ê°€ì´ë“œ í‘œì‹œ"""
    print("\nğŸ“‹ Phase 6 ì‹¤í–‰ ë°©ë²•:")
    print("="*50)
    print("# 1. Phase 4, 5ì—ì„œ ì¤€ë¹„ëœ ë°ì´í„° ì‚¬ìš©")
    print("dl_results = run_phase6_pipeline(modeling_data, clustering_results)")
    print()
    print("# 2. ê²°ê³¼ í™•ì¸")
    print("print('ìµœê³  ëª¨ë¸:', dl_results['best_model_name'])")
    print("print('ìµœê³  ì„±ëŠ¥:', dl_results['model_performances'][dl_results['best_model_name']]['accuracy'])")
    print("print('ì•™ìƒë¸” ì„±ëŠ¥:', dl_results['ensemble']['accuracy'])")
    print()
    print("# 3. ëª¨ë¸ ì €ì¥")
    print("model_path = save_best_model(dl_results)")
    print()
    print("# 4. ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±")
    print("predict_fn = create_prediction_function(f'{model_path}.h5', f'{model_path}_metadata.json')")

# ê°€ì´ë“œ í‘œì‹œ
display_phase6_guide()

print("\nâœ… Phase 6 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ§  ë‹¤ìŒ ë‹¨ê³„: Phase 7 - ëª¨ë¸ í•´ì„ ë° ê³ ë„í™”")
```
### 10. ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
``` python
# 10. ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def create_model_comparison_report(dl_results):
    """ëª¨ë¸ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
    print(f"\nğŸ“Š ëª¨ë¸ ë¹„êµ ë¦¬í¬íŠ¸")
    print("="*50)

    performances = dl_results['model_performances']

    # ì„±ëŠ¥ í…Œì´ë¸” ìƒì„±
    comparison_data = []
    for model_name, perf in performances.items():
        comparison_data.append({
            'Model': model_name,
            'Accuracy': f"{perf['accuracy']:.4f}",
            'F1_Macro': f"{perf['classification_report']['macro avg']['f1-score']:.4f}",
            'F1_Weighted': f"{perf['classification_report']['weighted avg']['f1-score']:.4f}",
            'Precision_Macro': f"{perf['classification_report']['macro avg']['precision']:.4f}",
            'Recall_Macro': f"{perf['classification_report']['macro avg']['recall']:.4f}"
        })

    # ì•™ìƒë¸” ëª¨ë¸ ì¶”ê°€
    if 'ensemble' in dl_results:
        comparison_data.append({
            'Model': 'Ensemble',
            'Accuracy': f"{dl_results['ensemble']['accuracy']:.4f}",
            'F1_Macro': 'N/A',
            'F1_Weighted': 'N/A',
            'Precision_Macro': 'N/A',
            'Recall_Macro': 'N/A'
        })

    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))

    return comparison_df

def analyze_misclassified_samples(dl_results, top_n=10):
    """ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œ ë¶„ì„"""
    print(f"\nğŸ” ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œ ë¶„ì„ (ìƒìœ„ {top_n}ê°œ)")
    print("-" * 40)

    best_model_name = dl_results['best_model_name']
    best_performance = dl_results['model_performances'][best_model_name]

    y_test = dl_results['classification_data']['y_test']
    y_pred = best_performance['y_pred']
    y_pred_proba = best_performance['y_pred_proba']
    cluster_names = dl_results['classification_data']['cluster_names']

    # ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œ ì°¾ê¸°
    misclassified_mask = y_test != y_pred
    misclassified_indices = np.where(misclassified_mask)[0]

    # ì‹ ë¢°ë„ê°€ ë†’ì€ ì˜ëª»ëœ ì˜ˆì¸¡ë“¤ (ê°€ì¥ ë¬¸ì œê°€ ë˜ëŠ” ì¼€ì´ìŠ¤)
    misclassified_confidence = np.max(y_pred_proba[misclassified_mask], axis=1)

    # ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_misclassified_idx = np.argsort(misclassified_confidence)[-top_n:]

    print(f"ğŸ“Š ì´ ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œ: {len(misclassified_indices):,}ê°œ")
    print(f"ğŸ¯ ìƒìœ„ {top_n}ê°œ ë†’ì€ ì‹ ë¢°ë„ ì˜¤ë¶„ë¥˜:")

    for i, idx in enumerate(top_misclassified_idx):
        original_idx = misclassified_indices[idx]
        true_label = y_test[original_idx]
        pred_label = y_pred[original_idx]
        confidence = misclassified_confidence[idx]

        true_name = cluster_names.get(true_label, f'Cluster_{true_label}')
        pred_name = cluster_names.get(pred_label, f'Cluster_{pred_label}')

        print(f"  {i+1:2d}. ì‹¤ì œ: {true_name} â†’ ì˜ˆì¸¡: {pred_name} (ì‹ ë¢°ë„: {confidence:.3f})")

    return misclassified_indices

print("\nğŸ¯ Phase 6 ì¤€ë¹„ ì™„ë£Œ!")
print("ğŸ“Š ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ì˜ ëª¨ë“  ê¸°ëŠ¥ì´ í¬í•¨ëœ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.")
```
### ì‹¤í–‰
``` python
# Phase 6 ì‹¤í–‰ ì „ í•„ìš”í•œ ë³€ìˆ˜ë“¤ í™•ì¸ ë° ì„¤ì •

print("ğŸ” Phase 6 ì‹¤í–‰ ì „ ë³€ìˆ˜ ìƒíƒœ í™•ì¸")
print("="*50)

# 1. í•„ìš”í•œ ë³€ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
required_vars = ['modeling_data', 'clustering_results', 'final_results']

for var_name in required_vars:
    if var_name in globals():
        print(f"âœ… {var_name}: ì¡´ì¬í•¨")
    else:
        print(f"âŒ {var_name}: ì¡´ì¬í•˜ì§€ ì•ŠìŒ")

print("\n" + "="*50)

# 2. clustering_resultsê°€ ì—†ëŠ” ê²½ìš° final_resultsì—ì„œ ê°€ì ¸ì˜¤ê¸°
if 'clustering_results' not in globals():
    if 'final_results' in globals():
        print("ğŸ”„ final_resultsì—ì„œ clustering_results ì¶”ì¶œ ì¤‘...")
        clustering_results = final_results
        print("âœ… clustering_results ì„¤ì • ì™„ë£Œ")
    else:
        print("âŒ clustering_resultsì™€ final_results ëª¨ë‘ ì—†ìŒ")
        print("ğŸ”„ Phase 5ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")

        # Phase 5 ê°„ë‹¨ ì¬ì‹¤í–‰ (clustering_results ìƒì„±ìš©)
        print("\nğŸš€ Phase 5 ê°„ë‹¨ ì¬ì‹¤í–‰ ì‹œì‘...")

        # modeling_dataê°€ ìˆëŠ”ì§€ í™•ì¸
        if 'modeling_data' not in globals():
            print("âŒ modeling_dataë„ ì—†ìŠµë‹ˆë‹¤. Phase 4ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
            print("ğŸ”„ Phase 4 ê°„ë‹¨ ì¬ì‹¤í–‰...")

            # Phase 4 ìµœì†Œ ì‹¤í–‰ (modeling_data ìƒì„±ìš©)
            if 'df_cleaned' in globals():
                # Phase 4 ìµœì†Œ ì‹¤í–‰
                from sklearn.model_selection import train_test_split
                from sklearn.preprocessing import StandardScaler

                print("ğŸ“Š modeling_data ê°„ë‹¨ ìƒì„± ì¤‘...")

                # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
                feature_cols = [col for col in df_cleaned.columns if col not in ['Id', 'groupId', 'matchId', 'winPlacePerc']]
                X = df_cleaned[feature_cols].fillna(0)
                y = df_cleaned['winPlacePerc'].fillna(df_cleaned['winPlacePerc'].median())

                # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                # ìŠ¤ì¼€ì¼ë§
                scaler = StandardScaler()
                X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
                X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)

                modeling_data = {
                    'X_train': X_train_scaled,
                    'X_test': X_test_scaled,
                    'y_train': y_train,
                    'y_test': y_test,
                    'feature_names': feature_cols
                }

                print(f"âœ… modeling_data ìƒì„± ì™„ë£Œ: {X_train_scaled.shape}")
            else:
                print("âŒ df_cleanedë„ ì—†ìŠµë‹ˆë‹¤. Phase 1-3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                raise NameError("í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Phase 1-3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        # Phase 5 ê°„ë‹¨ ì‹¤í–‰ (í´ëŸ¬ìŠ¤í„°ë§ë§Œ)
        print("\nğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ê°„ë‹¨ ì‹¤í–‰...")

        from sklearn.cluster import KMeans
        from sklearn.metrics import silhouette_score

        # K-Means í´ëŸ¬ìŠ¤í„°ë§ (ê°„ë‹¨ ë²„ì „)
        X_train = modeling_data['X_train']

        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê°„ë‹¨ ê²°ì • (5ê°œë¡œ ê³ ì •)
        n_clusters = 5

        print(f"ğŸ”„ K-Means í´ëŸ¬ìŠ¤í„°ë§ (K={n_clusters}) ì‹¤í–‰ ì¤‘...")
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_train)

        # í´ëŸ¬ìŠ¤í„° ì´ë¦„ ìƒì„±
        cluster_names = {
            0: "Aggressive Fighter",
            1: "Cautious Survivor",
            2: "Mobile Explorer",
            3: "Team Supporter",
            4: "Balanced Player"
        }

        # í´ëŸ¬ìŠ¤í„° í”„ë¡œíŒŒì¼ ìƒì„±
        cluster_profiles = {}
        for cluster_id in range(n_clusters):
            cluster_mask = cluster_labels == cluster_id
            cluster_size = np.sum(cluster_mask)
            cluster_percentage = (cluster_size / len(cluster_labels)) * 100

            if cluster_size > 0:
                cluster_data = X_train[cluster_mask]
                overall_mean = X_train.mean()
                cluster_mean = cluster_data.mean()
                feature_ratios = cluster_mean / (overall_mean + 1e-8)

                cluster_profiles[cluster_id] = {
                    'size': cluster_size,
                    'percentage': cluster_percentage,
                    'top_features': feature_ratios.nlargest(5),
                    'bottom_features': feature_ratios.nsmallest(5),
                    'mean_values': cluster_mean
                }

        # clustering_results êµ¬ì„±
        clustering_results = {
            'kmeans_model': kmeans,
            'cluster_labels': cluster_labels,
            'cluster_names': cluster_names,
            'cluster_profiles': cluster_profiles,
            'optimal_clusters': {'final_decision': n_clusters},
            'clustering_metrics': {
                'silhouette_score': silhouette_score(X_train, cluster_labels),
                'inertia': kmeans.inertia_
            }
        }

        print(f"âœ… clustering_results ìƒì„± ì™„ë£Œ")
        print(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}")
        print(f"ğŸ¯ Silhouette Score: {clustering_results['clustering_metrics']['silhouette_score']:.4f}")

# 3. ë³€ìˆ˜ ì¬í™•ì¸
print(f"\nğŸ” ë³€ìˆ˜ ì¬í™•ì¸:")
for var_name in required_vars:
    if var_name in globals():
        if var_name == 'modeling_data':
            print(f"âœ… {var_name}: {type(globals()[var_name])}, í‚¤: {list(globals()[var_name].keys())}")
        elif var_name == 'clustering_results':
            print(f"âœ… {var_name}: {type(globals()[var_name])}, í‚¤: {list(globals()[var_name].keys())}")
        else:
            print(f"âœ… {var_name}: ì¡´ì¬í•¨")
    else:
        print(f"âŒ {var_name}: ì—¬ì „íˆ ì—†ìŒ")

print(f"\nğŸ® Phase 6 ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!")
print("="*50)

# 4. Phase 6 ì‹¤í–‰
try:
    print("ğŸš€ Phase 6 ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")

    # Phase 6 ì‹¤í–‰
    dl_results = run_phase6_pipeline(modeling_data, clustering_results)

    # ê²°ê³¼ í™•ì¸
    print('\nğŸ“Š Phase 6 ì‹¤í–‰ ê²°ê³¼:')
    print('ìµœê³  ëª¨ë¸:', dl_results['best_model_name'])
    print('ìµœê³  ì„±ëŠ¥:', f"{dl_results['model_performances'][dl_results['best_model_name']]['accuracy']:.4f}")
    print('ì•™ìƒë¸” ì„±ëŠ¥:', f"{dl_results['ensemble']['accuracy']:.4f}")

    # ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
    model_path = save_best_model(dl_results)

    # ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±
    print("ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„± ì¤‘...")
    predict_fn = create_prediction_function(f'{model_path}.h5', f'{model_path}_metadata.json')

    print("\nğŸ‰ Phase 6 ì™„ë£Œ!")
    print("âœ… ë‹¤ìŒ ë‹¨ê³„: Phase 7 - ëª¨ë¸ í•´ì„ ë° ê³ ë„í™”")

except Exception as e:
    print(f"âŒ Phase 6 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:")
    import traceback
    traceback.print_exc()

    print(f"\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ì•ˆ:")
    print(f"1. Phase 1-5ë¥¼ ìˆœì„œëŒ€ë¡œ ë‹¤ì‹œ ì‹¤í–‰")
    print(f"2. ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ìƒ˜í”Œ í¬ê¸° ì¤„ì´ê¸°")
    print(f"3. GPU ëŸ°íƒ€ì„ ì‚¬ìš© ê¶Œì¥")

print(f"\nğŸ“ Phase 6 ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:")
print(f"â€¢ dl_results: ë”¥ëŸ¬ë‹ ê²°ê³¼")
print(f"â€¢ predict_fn: ìƒˆ í”Œë ˆì´ì–´ ì˜ˆì¸¡ í•¨ìˆ˜")
print(f"â€¢ model_path: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ")
```

#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ” Phase 6 ì‹¤í–‰ ì „ ë³€ìˆ˜ ìƒíƒœ í™•ì¸
==================================================
âœ… modeling_data: ì¡´ì¬í•¨
âŒ clustering_results: ì¡´ì¬í•˜ì§€ ì•ŠìŒ
âœ… final_results: ì¡´ì¬í•¨

==================================================
ğŸ”„ final_resultsì—ì„œ clustering_results ì¶”ì¶œ ì¤‘...
âœ… clustering_results ì„¤ì • ì™„ë£Œ

ğŸ” ë³€ìˆ˜ ì¬í™•ì¸:
âœ… modeling_data: <class 'dict'>, í‚¤: ['X_train', 'X_test', 'y_train', 'y_test', 'feature_names']
âœ… clustering_results: <class 'dict'>, í‚¤: ['optimal_clusters', 'kmeans_model', 'cluster_labels', 'clustering_metrics', 'cluster_profiles', 'cluster_stats', 'visualization_data', 'cluster_names']
âœ… final_results: ì¡´ì¬í•¨
```

``` bash
ğŸ® Phase 6 ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!
==================================================
ğŸš€ Phase 6 ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘!
ğŸ® PUBG Phase 6: ì§€ë„ í•™ìŠµ (ë”¥ëŸ¬ë‹ ë¶„ë¥˜) ì‹œì‘!
============================================================
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 30.3% (3.5GB / 12.7GB)
ğŸ”§ GPU ì‚¬ìš© ê°€ëŠ¥: False
ğŸš€ ì¢…í•© ë”¥ëŸ¬ë‹ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘
============================================================

==================== 1ë‹¨ê³„: ë¶„ë¥˜ ë°ì´í„° ì¤€ë¹„ ====================
ğŸ¯ ë¶„ë¥˜ ëª¨ë¸ìš© ë°ì´í„° ì¤€ë¹„
----------------------------------------
ğŸ“Š ë¶„ë¥˜ ë°ì´í„° ì •ë³´:
  í›ˆë ¨ íŠ¹ì„±: (80000, 30)
  í…ŒìŠ¤íŠ¸ íŠ¹ì„±: (20000, 30)
  í´ëŸ¬ìŠ¤í„° ìˆ˜: 8ê°œ
  í´ëŸ¬ìŠ¤í„° ë¶„í¬ (í›ˆë ¨):
    Survivor: 14,527ê°œ (18.2%)
    Survivor: 24,981ê°œ (31.2%)
    Explorer: 10,756ê°œ (13.4%)
    Explorer: 15,898ê°œ (19.9%)
    Explorer: 4,312ê°œ (5.4%)
    Explorer: 4,046ê°œ (5.1%)
    Explorer: 5,391ê°œ (6.7%)
    Aggressive: 89ê°œ (0.1%)
```

``` bash
==================== 2ë‹¨ê³„: ë‹¤ì¤‘ ëª¨ë¸ í›ˆë ¨ ====================

ğŸ† ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ë¶„ì„
==================================================
ğŸ”€ ê²€ì¦ ë°ì´í„° ë¶„í•  (20%)
----------------------------------------
ğŸ“Š ë¶„í•  ê²°ê³¼:
  í›ˆë ¨ ì„¸íŠ¸: 64,000ê°œ
  ê²€ì¦ ì„¸íŠ¸: 16,000ê°œ

==================== ê¸°ë³¸ ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ ====================
ğŸ§  ê¸°ë³¸ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•
  ì…ë ¥ ì°¨ì›: 30
  ì¶œë ¥ í´ë˜ìŠ¤: 8
  ì€ë‹‰ì¸µ: [128, 64, 32]
----------------------------------------
ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘
  ì—í¬í¬: 50
  ë°°ì¹˜ í¬ê¸°: 256
  í•™ìŠµë¥ : 0.001
----------------------------------------
ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜:
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ dense (Dense)                   â”‚ (None, 128)            â”‚         3,968 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 128)            â”‚           512 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 128)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 64)             â”‚         8,256 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 64)             â”‚           256 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)             â”‚ (None, 64)             â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 32)             â”‚         2,080 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_2           â”‚ (None, 32)             â”‚           128 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)             â”‚ (None, 32)             â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                 â”‚ (None, 8)              â”‚           264 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 15,464 (60.41 KB)
 Trainable params: 15,016 (58.66 KB)
 Non-trainable params: 448 (1.75 KB)
```

``` bash
ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì§„í–‰ ì¤‘...
Epoch 1/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 8ms/step - accuracy: 0.6824 - loss: 0.9892 - val_accuracy: 0.9664 - val_loss: 0.1198 - learning_rate: 0.0010
Epoch 2/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 5ms/step - accuracy: 0.9264 - loss: 0.2040 - val_accuracy: 0.9803 - val_loss: 0.0682 - learning_rate: 0.0010
Epoch 3/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9452 - loss: 0.1465 - val_accuracy: 0.9826 - val_loss: 0.0550 - learning_rate: 0.0010
Epoch 4/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9541 - loss: 0.1203 - val_accuracy: 0.9839 - val_loss: 0.0479 - learning_rate: 0.0010
Epoch 5/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9595 - loss: 0.1054 - val_accuracy: 0.9861 - val_loss: 0.0426 - learning_rate: 0.0010
Epoch 6/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9636 - loss: 0.0978 - val_accuracy: 0.9829 - val_loss: 0.0427 - learning_rate: 0.0010
Epoch 7/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 8ms/step - accuracy: 0.9650 - loss: 0.0912 - val_accuracy: 0.9858 - val_loss: 0.0388 - learning_rate: 0.0010
Epoch 8/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 6ms/step - accuracy: 0.9692 - loss: 0.0805 - val_accuracy: 0.9892 - val_loss: 0.0343 - learning_rate: 0.0010
Epoch 9/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9690 - loss: 0.0792 - val_accuracy: 0.9892 - val_loss: 0.0340 - learning_rate: 0.0010
Epoch 10/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9705 - loss: 0.0761 - val_accuracy: 0.9845 - val_loss: 0.0379 - learning_rate: 0.0010
Epoch 11/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9723 - loss: 0.0727 - val_accuracy: 0.9881 - val_loss: 0.0334 - learning_rate: 0.0010
Epoch 12/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9738 - loss: 0.0665 - val_accuracy: 0.9888 - val_loss: 0.0321 - learning_rate: 0.0010
Epoch 13/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9749 - loss: 0.0658 - val_accuracy: 0.9904 - val_loss: 0.0294 - learning_rate: 0.0010
Epoch 14/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9756 - loss: 0.0632 - val_accuracy: 0.9892 - val_loss: 0.0310 - learning_rate: 0.0010
Epoch 15/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 7ms/step - accuracy: 0.9751 - loss: 0.0639 - val_accuracy: 0.9851 - val_loss: 0.0344 - learning_rate: 0.0010
Epoch 16/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 6ms/step - accuracy: 0.9766 - loss: 0.0600 - val_accuracy: 0.9875 - val_loss: 0.0326 - learning_rate: 0.0010
Epoch 17/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9765 - loss: 0.0611 - val_accuracy: 0.9843 - val_loss: 0.0356 - learning_rate: 0.0010
Epoch 18/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9775 - loss: 0.0566 - val_accuracy: 0.9889 - val_loss: 0.0307 - learning_rate: 0.0010
Epoch 19/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9781 - loss: 0.0571 - val_accuracy: 0.9869 - val_loss: 0.0315 - learning_rate: 0.0010
Epoch 20/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9790 - loss: 0.0563 - val_accuracy: 0.9895 - val_loss: 0.0274 - learning_rate: 0.0010
Epoch 21/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9792 - loss: 0.0530 - val_accuracy: 0.9873 - val_loss: 0.0317 - learning_rate: 0.0010
Epoch 22/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.9798 - loss: 0.0529 - val_accuracy: 0.9891 - val_loss: 0.0283 - learning_rate: 0.0010
Epoch 23/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 6ms/step - accuracy: 0.9793 - loss: 0.0526 - val_accuracy: 0.9906 - val_loss: 0.0271 - learning_rate: 0.0010
Epoch 24/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 5ms/step - accuracy: 0.9793 - loss: 0.0545 - val_accuracy: 0.9912 - val_loss: 0.0247 - learning_rate: 0.0010
Epoch 25/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9804 - loss: 0.0507 - val_accuracy: 0.9875 - val_loss: 0.0308 - learning_rate: 0.0010
Epoch 26/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9796 - loss: 0.0528 - val_accuracy: 0.9903 - val_loss: 0.0255 - learning_rate: 0.0010
Epoch 27/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9806 - loss: 0.0517 - val_accuracy: 0.9911 - val_loss: 0.0246 - learning_rate: 0.0010
Epoch 28/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9823 - loss: 0.0458 - val_accuracy: 0.9896 - val_loss: 0.0264 - learning_rate: 0.0010
Epoch 29/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 9ms/step - accuracy: 0.9812 - loss: 0.0492 - val_accuracy: 0.9887 - val_loss: 0.0267 - learning_rate: 0.0010
Epoch 30/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 5ms/step - accuracy: 0.9813 - loss: 0.0489 - val_accuracy: 0.9916 - val_loss: 0.0241 - learning_rate: 0.0010
Epoch 31/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9836 - loss: 0.0442 - val_accuracy: 0.9860 - val_loss: 0.0317 - learning_rate: 0.0010
Epoch 32/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9825 - loss: 0.0461 - val_accuracy: 0.9900 - val_loss: 0.0277 - learning_rate: 0.0010
Epoch 33/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9822 - loss: 0.0453 - val_accuracy: 0.9894 - val_loss: 0.0256 - learning_rate: 0.0010
Epoch 34/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9820 - loss: 0.0457 - val_accuracy: 0.9896 - val_loss: 0.0253 - learning_rate: 0.0010
Epoch 35/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9820 - loss: 0.0469 - val_accuracy: 0.9905 - val_loss: 0.0239 - learning_rate: 0.0010
Epoch 36/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9829 - loss: 0.0442 - val_accuracy: 0.9889 - val_loss: 0.0266 - learning_rate: 0.0010
Epoch 37/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 6ms/step - accuracy: 0.9842 - loss: 0.0422 - val_accuracy: 0.9918 - val_loss: 0.0214 - learning_rate: 0.0010
Epoch 38/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.9828 - loss: 0.0444 - val_accuracy: 0.9899 - val_loss: 0.0255 - learning_rate: 0.0010
Epoch 39/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 5ms/step - accuracy: 0.9844 - loss: 0.0416 - val_accuracy: 0.9908 - val_loss: 0.0227 - learning_rate: 0.0010
Epoch 40/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9842 - loss: 0.0409 - val_accuracy: 0.9932 - val_loss: 0.0196 - learning_rate: 0.0010
Epoch 41/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9856 - loss: 0.0376 - val_accuracy: 0.9898 - val_loss: 0.0249 - learning_rate: 0.0010
Epoch 42/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9845 - loss: 0.0404 - val_accuracy: 0.9876 - val_loss: 0.0288 - learning_rate: 0.0010
Epoch 43/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9848 - loss: 0.0408 - val_accuracy: 0.9911 - val_loss: 0.0229 - learning_rate: 0.0010
Epoch 44/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9849 - loss: 0.0408 - val_accuracy: 0.9908 - val_loss: 0.0239 - learning_rate: 0.0010
Epoch 45/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 6ms/step - accuracy: 0.9849 - loss: 0.0417 - val_accuracy: 0.9889 - val_loss: 0.0258 - learning_rate: 0.0010
Epoch 46/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 8ms/step - accuracy: 0.9836 - loss: 0.0435 - val_accuracy: 0.9908 - val_loss: 0.0221 - learning_rate: 0.0010
Epoch 47/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 6ms/step - accuracy: 0.9852 - loss: 0.0384 - val_accuracy: 0.9893 - val_loss: 0.0245 - learning_rate: 0.0010
Epoch 48/50
246/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4ms/step - accuracy: 0.9865 - loss: 0.0355
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 5ms/step - accuracy: 0.9865 - loss: 0.0355 - val_accuracy: 0.9918 - val_loss: 0.0215 - learning_rate: 0.0010
Epoch 49/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9870 - loss: 0.0346 - val_accuracy: 0.9939 - val_loss: 0.0174 - learning_rate: 5.0000e-04
Epoch 50/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 5ms/step - accuracy: 0.9868 - loss: 0.0338 - val_accuracy: 0.9927 - val_loss: 0.0181 - learning_rate: 5.0000e-04
Restoring model weights from the end of the best epoch: 49.
â° í›ˆë ¨ ì™„ë£Œ ì‹œê°„: 90.6ì´ˆ
```

``` bash
==================== ê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ ====================
ğŸš€ ê³ ê¸‰ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•
  ì…ë ¥ ì°¨ì›: 30
  ì¶œë ¥ í´ë˜ìŠ¤: 8
----------------------------------------
ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘
  ì—í¬í¬: 50
  ë°°ì¹˜ í¬ê¸°: 256
  í•™ìŠµë¥ : 0.001
----------------------------------------
ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜:
Model: "functional_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_1       â”‚ (None, 30)        â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)     â”‚ (None, 256)       â”‚      7,936 â”‚ input_layer_1[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_6 (Dense)     â”‚ (None, 128)       â”‚      3,968 â”‚ input_layer_1[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 256)       â”‚      1,024 â”‚ dense_4[0][0]     â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 128)       â”‚        512 â”‚ dense_6[0][0]     â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 (Dropout) â”‚ (None, 256)       â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_5 (Dropout) â”‚ (None, 128)       â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_5 (Dense)     â”‚ (None, 128)       â”‚     32,896 â”‚ dropout_3[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_7 (Dense)     â”‚ (None, 64)        â”‚      8,256 â”‚ dropout_5[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 128)       â”‚        512 â”‚ dense_5[0][0]     â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 64)        â”‚        256 â”‚ dense_7[0][0]     â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_4 (Dropout) â”‚ (None, 128)       â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_6 (Dropout) â”‚ (None, 64)        â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate         â”‚ (None, 192)       â”‚          0 â”‚ dropout_4[0][0],  â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ dropout_6[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_8 (Dense)     â”‚ (None, 64)        â”‚     12,352 â”‚ concatenate[0][0] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 64)        â”‚        256 â”‚ dense_8[0][0]     â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_7 (Dropout) â”‚ (None, 64)        â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_9 (Dense)     â”‚ (None, 32)        â”‚      2,080 â”‚ dropout_7[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_8 (Dropout) â”‚ (None, 32)        â”‚          0 â”‚ dense_9[0][0]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_10 (Dense)    â”‚ (None, 8)         â”‚        264 â”‚ dropout_8[0][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 70,312 (274.66 KB)
 Trainable params: 69,032 (269.66 KB)
 Non-trainable params: 1,280 (5.00 KB)
```

``` bash
ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì§„í–‰ ì¤‘...
Epoch 1/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 12ms/step - accuracy: 0.7798 - loss: 0.6758 - val_accuracy: 0.9743 - val_loss: 0.0793 - learning_rate: 0.0010
Epoch 2/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9390 - loss: 0.1599 - val_accuracy: 0.9817 - val_loss: 0.0541 - learning_rate: 0.0010
Epoch 3/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9541 - loss: 0.1170 - val_accuracy: 0.9650 - val_loss: 0.0839 - learning_rate: 0.0010
Epoch 4/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 14ms/step - accuracy: 0.9567 - loss: 0.1104 - val_accuracy: 0.9818 - val_loss: 0.0464 - learning_rate: 0.0010
Epoch 5/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9618 - loss: 0.0981 - val_accuracy: 0.9841 - val_loss: 0.0411 - learning_rate: 0.0010
Epoch 6/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9662 - loss: 0.0891 - val_accuracy: 0.9879 - val_loss: 0.0378 - learning_rate: 0.0010
Epoch 7/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 17ms/step - accuracy: 0.9666 - loss: 0.0851 - val_accuracy: 0.9797 - val_loss: 0.0461 - learning_rate: 0.0010
Epoch 8/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9682 - loss: 0.0797 - val_accuracy: 0.9833 - val_loss: 0.0420 - learning_rate: 0.0010
Epoch 9/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 10ms/step - accuracy: 0.9703 - loss: 0.0737 - val_accuracy: 0.9862 - val_loss: 0.0370 - learning_rate: 0.0010
Epoch 10/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 15ms/step - accuracy: 0.9720 - loss: 0.0694 - val_accuracy: 0.9846 - val_loss: 0.0380 - learning_rate: 0.0010
Epoch 11/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 10ms/step - accuracy: 0.9705 - loss: 0.0724 - val_accuracy: 0.9843 - val_loss: 0.0377 - learning_rate: 0.0010
Epoch 12/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9732 - loss: 0.0674 - val_accuracy: 0.9887 - val_loss: 0.0335 - learning_rate: 0.0010
Epoch 13/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9751 - loss: 0.0636 - val_accuracy: 0.9854 - val_loss: 0.0334 - learning_rate: 0.0010
Epoch 14/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 15ms/step - accuracy: 0.9763 - loss: 0.0615 - val_accuracy: 0.9864 - val_loss: 0.0340 - learning_rate: 0.0010
Epoch 15/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9750 - loss: 0.0618 - val_accuracy: 0.9873 - val_loss: 0.0337 - learning_rate: 0.0010
Epoch 16/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9766 - loss: 0.0564 - val_accuracy: 0.9898 - val_loss: 0.0273 - learning_rate: 0.0010
Epoch 17/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9771 - loss: 0.0563 - val_accuracy: 0.9891 - val_loss: 0.0287 - learning_rate: 0.0010
Epoch 18/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 13ms/step - accuracy: 0.9779 - loss: 0.0557 - val_accuracy: 0.9901 - val_loss: 0.0283 - learning_rate: 0.0010
Epoch 19/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 11ms/step - accuracy: 0.9799 - loss: 0.0521 - val_accuracy: 0.9878 - val_loss: 0.0335 - learning_rate: 0.0010
Epoch 20/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 15ms/step - accuracy: 0.9781 - loss: 0.0553 - val_accuracy: 0.9891 - val_loss: 0.0300 - learning_rate: 0.0010
Epoch 21/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9799 - loss: 0.0509 - val_accuracy: 0.9829 - val_loss: 0.0382 - learning_rate: 0.0010
Epoch 22/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9806 - loss: 0.0489 - val_accuracy: 0.9902 - val_loss: 0.0281 - learning_rate: 0.0010
Epoch 23/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 16ms/step - accuracy: 0.9803 - loss: 0.0486 - val_accuracy: 0.9912 - val_loss: 0.0262 - learning_rate: 0.0010
Epoch 24/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9811 - loss: 0.0493 - val_accuracy: 0.9897 - val_loss: 0.0292 - learning_rate: 0.0010
Epoch 25/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 13ms/step - accuracy: 0.9817 - loss: 0.0456 - val_accuracy: 0.9894 - val_loss: 0.0276 - learning_rate: 0.0010
Epoch 26/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 16ms/step - accuracy: 0.9829 - loss: 0.0453 - val_accuracy: 0.9899 - val_loss: 0.0260 - learning_rate: 0.0010
Epoch 27/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9818 - loss: 0.0456 - val_accuracy: 0.9900 - val_loss: 0.0263 - learning_rate: 0.0010
Epoch 28/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9830 - loss: 0.0442 - val_accuracy: 0.9887 - val_loss: 0.0276 - learning_rate: 0.0010
Epoch 29/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 15ms/step - accuracy: 0.9808 - loss: 0.0451 - val_accuracy: 0.9875 - val_loss: 0.0309 - learning_rate: 0.0010
Epoch 30/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 12ms/step - accuracy: 0.9826 - loss: 0.0457 - val_accuracy: 0.9895 - val_loss: 0.0264 - learning_rate: 0.0010
Epoch 31/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 11ms/step - accuracy: 0.9817 - loss: 0.0450 - val_accuracy: 0.9879 - val_loss: 0.0284 - learning_rate: 0.0010
Epoch 32/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 16ms/step - accuracy: 0.9833 - loss: 0.0398 - val_accuracy: 0.9894 - val_loss: 0.0258 - learning_rate: 0.0010
Epoch 33/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9834 - loss: 0.0416 - val_accuracy: 0.9890 - val_loss: 0.0262 - learning_rate: 0.0010
Epoch 34/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 13ms/step - accuracy: 0.9841 - loss: 0.0394 - val_accuracy: 0.9927 - val_loss: 0.0237 - learning_rate: 0.0010
Epoch 35/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 15ms/step - accuracy: 0.9847 - loss: 0.0384 - val_accuracy: 0.9907 - val_loss: 0.0237 - learning_rate: 0.0010
Epoch 36/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9839 - loss: 0.0377 - val_accuracy: 0.9910 - val_loss: 0.0232 - learning_rate: 0.0010
Epoch 37/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9847 - loss: 0.0386 - val_accuracy: 0.9888 - val_loss: 0.0270 - learning_rate: 0.0010
Epoch 38/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 15ms/step - accuracy: 0.9847 - loss: 0.0398 - val_accuracy: 0.9919 - val_loss: 0.0227 - learning_rate: 0.0010
Epoch 39/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9849 - loss: 0.0379 - val_accuracy: 0.9887 - val_loss: 0.0300 - learning_rate: 0.0010
Epoch 40/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 12ms/step - accuracy: 0.9834 - loss: 0.0391 - val_accuracy: 0.9912 - val_loss: 0.0248 - learning_rate: 0.0010
Epoch 41/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 11ms/step - accuracy: 0.9858 - loss: 0.0353 - val_accuracy: 0.9919 - val_loss: 0.0227 - learning_rate: 0.0010
Epoch 42/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 11ms/step - accuracy: 0.9848 - loss: 0.0369 - val_accuracy: 0.9909 - val_loss: 0.0237 - learning_rate: 0.0010
Epoch 43/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6s 16ms/step - accuracy: 0.9872 - loss: 0.0337 - val_accuracy: 0.9906 - val_loss: 0.0234 - learning_rate: 0.0010
Epoch 44/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 11ms/step - accuracy: 0.9860 - loss: 0.0353 - val_accuracy: 0.9914 - val_loss: 0.0219 - learning_rate: 0.0010
Epoch 45/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 12ms/step - accuracy: 0.9856 - loss: 0.0353 - val_accuracy: 0.9923 - val_loss: 0.0216 - learning_rate: 0.0010
Epoch 46/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 17ms/step - accuracy: 0.9854 - loss: 0.0368 - val_accuracy: 0.9905 - val_loss: 0.0234 - learning_rate: 0.0010
Epoch 47/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9856 - loss: 0.0367 - val_accuracy: 0.9905 - val_loss: 0.0241 - learning_rate: 0.0010
Epoch 48/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 12ms/step - accuracy: 0.9853 - loss: 0.0365 - val_accuracy: 0.9918 - val_loss: 0.0217 - learning_rate: 0.0010
Epoch 49/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 17ms/step - accuracy: 0.9851 - loss: 0.0355 - val_accuracy: 0.9922 - val_loss: 0.0218 - learning_rate: 0.0010
Epoch 50/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9869 - loss: 0.0333 - val_accuracy: 0.9911 - val_loss: 0.0208 - learning_rate: 0.0010
Restoring model weights from the end of the best epoch: 50.
â° í›ˆë ¨ ì™„ë£Œ ì‹œê°„: 221.8ì´ˆ
```

``` bash
==================== Residual ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨ ====================
ğŸ”— Residual ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•
----------------------------------------
ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘
  ì—í¬í¬: 50
  ë°°ì¹˜ í¬ê¸°: 256
  í•™ìŠµë¥ : 0.001
----------------------------------------
ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜:
Model: "functional_2"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_2       â”‚ (None, 30)        â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_11 (Dense)    â”‚ (None, 128)       â”‚      3,968 â”‚ input_layer_2[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 128)       â”‚        512 â”‚ dense_11[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_12 (Dense)    â”‚ (None, 128)       â”‚     16,512 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 128)       â”‚        512 â”‚ dense_12[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_9 (Dropout) â”‚ (None, 128)       â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_13 (Dense)    â”‚ (None, 128)       â”‚     16,512 â”‚ dropout_9[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 128)       â”‚        512 â”‚ dense_13[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 128)       â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation          â”‚ (None, 128)       â”‚          0 â”‚ add[0][0]         â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_15 (Dense)    â”‚ (None, 64)        â”‚      8,256 â”‚ activation[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 64)        â”‚        256 â”‚ dense_15[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_10          â”‚ (None, 64)        â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_16 (Dense)    â”‚ (None, 64)        â”‚      4,160 â”‚ dropout_10[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 64)        â”‚        256 â”‚ dense_16[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_14 (Dense)    â”‚ (None, 64)        â”‚      8,256 â”‚ activation[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64)        â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ dense_14[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1        â”‚ (None, 64)        â”‚          0 â”‚ add_1[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_17 (Dense)    â”‚ (None, 32)        â”‚      2,080 â”‚ activation_1[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_11          â”‚ (None, 32)        â”‚          0 â”‚ dense_17[0][0]    â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_18 (Dense)    â”‚ (None, 8)         â”‚        264 â”‚ dropout_11[0][0]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 62,056 (242.41 KB)
 Trainable params: 61,032 (238.41 KB)
 Non-trainable params: 1,024 (4.00 KB)
 ```

``` bash
ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì§„í–‰ ì¤‘...
Epoch 1/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 17ms/step - accuracy: 0.7739 - loss: 0.6666 - val_accuracy: 0.9536 - val_loss: 0.1134 - learning_rate: 0.0010
Epoch 2/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 9ms/step - accuracy: 0.9556 - loss: 0.1187 - val_accuracy: 0.9668 - val_loss: 0.0774 - learning_rate: 0.0010
Epoch 3/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 10ms/step - accuracy: 0.9583 - loss: 0.1035 - val_accuracy: 0.9775 - val_loss: 0.0552 - learning_rate: 0.0010
Epoch 4/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9677 - loss: 0.0822 - val_accuracy: 0.9787 - val_loss: 0.0505 - learning_rate: 0.0010
Epoch 5/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 14ms/step - accuracy: 0.9705 - loss: 0.0755 - val_accuracy: 0.9826 - val_loss: 0.0452 - learning_rate: 0.0010
Epoch 6/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 12ms/step - accuracy: 0.9723 - loss: 0.0701 - val_accuracy: 0.9778 - val_loss: 0.0503 - learning_rate: 0.0010
Epoch 7/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 10ms/step - accuracy: 0.9740 - loss: 0.0658 - val_accuracy: 0.9872 - val_loss: 0.0388 - learning_rate: 0.0010
Epoch 8/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9745 - loss: 0.0624 - val_accuracy: 0.9871 - val_loss: 0.0379 - learning_rate: 0.0010
Epoch 9/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 13ms/step - accuracy: 0.9755 - loss: 0.0620 - val_accuracy: 0.9834 - val_loss: 0.0403 - learning_rate: 0.0010
Epoch 10/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 9ms/step - accuracy: 0.9757 - loss: 0.0605 - val_accuracy: 0.9834 - val_loss: 0.0394 - learning_rate: 0.0010
Epoch 11/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9781 - loss: 0.0551 - val_accuracy: 0.9819 - val_loss: 0.0434 - learning_rate: 0.0010
Epoch 12/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9774 - loss: 0.0549 - val_accuracy: 0.9772 - val_loss: 0.0572 - learning_rate: 0.0010
Epoch 13/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9801 - loss: 0.0506 - val_accuracy: 0.9867 - val_loss: 0.0361 - learning_rate: 0.0010
Epoch 14/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 15ms/step - accuracy: 0.9799 - loss: 0.0496 - val_accuracy: 0.9894 - val_loss: 0.0304 - learning_rate: 0.0010
Epoch 15/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9825 - loss: 0.0443 - val_accuracy: 0.9835 - val_loss: 0.0388 - learning_rate: 0.0010
Epoch 16/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9809 - loss: 0.0470 - val_accuracy: 0.9879 - val_loss: 0.0301 - learning_rate: 0.0010
Epoch 17/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 9ms/step - accuracy: 0.9831 - loss: 0.0421 - val_accuracy: 0.9854 - val_loss: 0.0350 - learning_rate: 0.0010
Epoch 18/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9825 - loss: 0.0421 - val_accuracy: 0.9872 - val_loss: 0.0328 - learning_rate: 0.0010
Epoch 19/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 15ms/step - accuracy: 0.9842 - loss: 0.0397 - val_accuracy: 0.9853 - val_loss: 0.0347 - learning_rate: 0.0010
Epoch 20/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 10ms/step - accuracy: 0.9836 - loss: 0.0393 - val_accuracy: 0.9882 - val_loss: 0.0293 - learning_rate: 0.0010
Epoch 21/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9842 - loss: 0.0398 - val_accuracy: 0.9889 - val_loss: 0.0286 - learning_rate: 0.0010
Epoch 22/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 9ms/step - accuracy: 0.9856 - loss: 0.0358 - val_accuracy: 0.9857 - val_loss: 0.0329 - learning_rate: 0.0010
Epoch 23/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 16ms/step - accuracy: 0.9844 - loss: 0.0384 - val_accuracy: 0.9831 - val_loss: 0.0379 - learning_rate: 0.0010
Epoch 24/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9855 - loss: 0.0357 - val_accuracy: 0.9898 - val_loss: 0.0258 - learning_rate: 0.0010
Epoch 25/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9855 - loss: 0.0352 - val_accuracy: 0.9896 - val_loss: 0.0257 - learning_rate: 0.0010
Epoch 26/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9864 - loss: 0.0334 - val_accuracy: 0.9851 - val_loss: 0.0345 - learning_rate: 0.0010
Epoch 27/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 10ms/step - accuracy: 0.9869 - loss: 0.0344 - val_accuracy: 0.9905 - val_loss: 0.0251 - learning_rate: 0.0010
Epoch 28/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 17ms/step - accuracy: 0.9865 - loss: 0.0327 - val_accuracy: 0.9887 - val_loss: 0.0261 - learning_rate: 0.0010
Epoch 29/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 9ms/step - accuracy: 0.9867 - loss: 0.0323 - val_accuracy: 0.9890 - val_loss: 0.0268 - learning_rate: 0.0010
Epoch 30/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9877 - loss: 0.0315 - val_accuracy: 0.9899 - val_loss: 0.0258 - learning_rate: 0.0010
Epoch 31/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 10ms/step - accuracy: 0.9881 - loss: 0.0297 - val_accuracy: 0.9891 - val_loss: 0.0256 - learning_rate: 0.0010
Epoch 32/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 13ms/step - accuracy: 0.9872 - loss: 0.0314 - val_accuracy: 0.9861 - val_loss: 0.0314 - learning_rate: 0.0010
Epoch 33/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 13ms/step - accuracy: 0.9869 - loss: 0.0309 - val_accuracy: 0.9899 - val_loss: 0.0274 - learning_rate: 0.0010
Epoch 34/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9899 - loss: 0.0264 - val_accuracy: 0.9904 - val_loss: 0.0252 - learning_rate: 0.0010
Epoch 35/50
246/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 8ms/step - accuracy: 0.9886 - loss: 0.0287
Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9886 - loss: 0.0287 - val_accuracy: 0.9873 - val_loss: 0.0302 - learning_rate: 0.0010
Epoch 36/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9898 - loss: 0.0254 - val_accuracy: 0.9905 - val_loss: 0.0231 - learning_rate: 5.0000e-04
Epoch 37/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 13ms/step - accuracy: 0.9914 - loss: 0.0207 - val_accuracy: 0.9890 - val_loss: 0.0266 - learning_rate: 5.0000e-04
Epoch 38/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 12ms/step - accuracy: 0.9912 - loss: 0.0216 - val_accuracy: 0.9905 - val_loss: 0.0246 - learning_rate: 5.0000e-04
Epoch 39/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 9ms/step - accuracy: 0.9919 - loss: 0.0198 - val_accuracy: 0.9883 - val_loss: 0.0301 - learning_rate: 5.0000e-04
Epoch 40/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9920 - loss: 0.0195 - val_accuracy: 0.9875 - val_loss: 0.0336 - learning_rate: 5.0000e-04
Epoch 41/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9927 - loss: 0.0194 - val_accuracy: 0.9903 - val_loss: 0.0236 - learning_rate: 5.0000e-04
Epoch 42/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 19ms/step - accuracy: 0.9913 - loss: 0.0212 - val_accuracy: 0.9912 - val_loss: 0.0231 - learning_rate: 5.0000e-04
Epoch 43/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 11ms/step - accuracy: 0.9925 - loss: 0.0189 - val_accuracy: 0.9914 - val_loss: 0.0215 - learning_rate: 5.0000e-04
Epoch 44/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9931 - loss: 0.0173 - val_accuracy: 0.9900 - val_loss: 0.0241 - learning_rate: 5.0000e-04
Epoch 45/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9933 - loss: 0.0185 - val_accuracy: 0.9908 - val_loss: 0.0238 - learning_rate: 5.0000e-04
Epoch 46/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 14ms/step - accuracy: 0.9919 - loss: 0.0199 - val_accuracy: 0.9908 - val_loss: 0.0245 - learning_rate: 5.0000e-04
Epoch 47/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 12ms/step - accuracy: 0.9931 - loss: 0.0170 - val_accuracy: 0.9901 - val_loss: 0.0242 - learning_rate: 5.0000e-04
Epoch 48/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - accuracy: 0.9930 - loss: 0.0169 - val_accuracy: 0.9896 - val_loss: 0.0271 - learning_rate: 5.0000e-04
Epoch 49/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9929 - loss: 0.0186 - val_accuracy: 0.9921 - val_loss: 0.0221 - learning_rate: 5.0000e-04
Epoch 50/50
250/250 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 10ms/step - accuracy: 0.9942 - loss: 0.0142 - val_accuracy: 0.9887 - val_loss: 0.0279 - learning_rate: 5.0000e-04
Restoring model weights from the end of the best epoch: 43.
â° í›ˆë ¨ ì™„ë£Œ ì‹œê°„: 154.9ì´ˆ
```

``` bash
==================== 3ë‹¨ê³„: í›ˆë ¨ ê³¼ì • ì‹œê°í™” ====================

ğŸ“ˆ Basic ëª¨ë¸ í›ˆë ¨ ê³¼ì •:

ğŸ“ˆ í›ˆë ¨ ê³¼ì • ì‹œê°í™”
----------------------------------------
```

![Screenshot](image/Basicëª¨ë¸_í›ˆë ¨_ê³¼ì •_í›ˆë ¨ê³¼ì •_ì‹œê°í™”.png)

``` bash
ğŸ“Š ìµœì¢… í›ˆë ¨ ì„±ëŠ¥:
  í›ˆë ¨ ì •í™•ë„: 0.9869
  ê²€ì¦ ì •í™•ë„: 0.9927
  í›ˆë ¨ ì†ì‹¤: 0.0347
  ê²€ì¦ ì†ì‹¤: 0.0181
âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ (ì°¨ì´: -0.006)

ğŸ“ˆ Advanced ëª¨ë¸ í›ˆë ¨ ê³¼ì •:

ğŸ“ˆ í›ˆë ¨ ê³¼ì • ì‹œê°í™”
----------------------------------------
```

![Screenshot](image/Advancedëª¨ë¸_í›ˆë ¨ê³¼ì •_ì‹œê°í™”.png)

``` bash

ğŸ“Š ìµœì¢… í›ˆë ¨ ì„±ëŠ¥:
  í›ˆë ¨ ì •í™•ë„: 0.9871
  ê²€ì¦ ì •í™•ë„: 0.9911
  í›ˆë ¨ ì†ì‹¤: 0.0327
  ê²€ì¦ ì†ì‹¤: 0.0208
âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ (ì°¨ì´: -0.004)

ğŸ“ˆ Residual ëª¨ë¸ í›ˆë ¨ ê³¼ì •:

ğŸ“ˆ í›ˆë ¨ ê³¼ì • ì‹œê°í™”
----------------------------------------
```

![Screenshot](image/Residualëª¨ë¸_í›ˆë ¨ê³¼ì •_ì‹œê°í™”.png)

``` bash
ğŸ“Š ìµœì¢… í›ˆë ¨ ì„±ëŠ¥:
  í›ˆë ¨ ì •í™•ë„: 0.9934
  ê²€ì¦ ì •í™•ë„: 0.9887
  í›ˆë ¨ ì†ì‹¤: 0.0167
  ê²€ì¦ ì†ì‹¤: 0.0279
âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ (ì°¨ì´: 0.005)

==================== 4ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ====================

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
==================================================

ğŸ” Basic ëª¨ë¸ í‰ê°€:

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
----------------------------------------
ğŸ¯ ì •í™•ë„: 0.9925 (99.25%)

ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:
  Survivor       : ì •ë°€ë„=0.997, ì¬í˜„ìœ¨=0.999, F1=0.998
  Survivor       : ì •ë°€ë„=0.997, ì¬í˜„ìœ¨=0.999, F1=0.998
  Explorer       : ì •ë°€ë„=0.992, ì¬í˜„ìœ¨=0.967, F1=0.979
  Explorer       : ì •ë°€ë„=0.992, ì¬í˜„ìœ¨=0.967, F1=0.979
  Explorer       : ì •ë°€ë„=0.992, ì¬í˜„ìœ¨=0.967, F1=0.979
  Explorer       : ì •ë°€ë„=0.992, ì¬í˜„ìœ¨=0.967, F1=0.979
  Explorer       : ì •ë°€ë„=0.992, ì¬í˜„ìœ¨=0.967, F1=0.979
  Aggressive     : ì •ë°€ë„=0.950, ì¬í˜„ìœ¨=1.000, F1=0.974

ğŸ“Š ì „ì²´ í‰ê· :
  Macro Avg    : F1=0.987
  Weighted Avg : F1=0.992
  ì •í™•ë„: 0.9925
  F1 (Macro): 0.9867

ğŸ” Advanced ëª¨ë¸ í‰ê°€:

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
----------------------------------------
ğŸ¯ ì •í™•ë„: 0.9896 (98.96%)

ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:
  Survivor       : ì •ë°€ë„=0.995, ì¬í˜„ìœ¨=0.999, F1=0.997
  Survivor       : ì •ë°€ë„=0.995, ì¬í˜„ìœ¨=0.999, F1=0.997
  Explorer       : ì •ë°€ë„=0.999, ì¬í˜„ìœ¨=0.939, F1=0.968
  Explorer       : ì •ë°€ë„=0.999, ì¬í˜„ìœ¨=0.939, F1=0.968
  Explorer       : ì •ë°€ë„=0.999, ì¬í˜„ìœ¨=0.939, F1=0.968
  Explorer       : ì •ë°€ë„=0.999, ì¬í˜„ìœ¨=0.939, F1=0.968
  Explorer       : ì •ë°€ë„=0.999, ì¬í˜„ìœ¨=0.939, F1=0.968
  Aggressive     : ì •ë°€ë„=1.000, ì¬í˜„ìœ¨=1.000, F1=1.000

ğŸ“Š ì „ì²´ í‰ê· :
  Macro Avg    : F1=0.987
  Weighted Avg : F1=0.990
  ì •í™•ë„: 0.9896
  F1 (Macro): 0.9870

ğŸ” Residual ëª¨ë¸ í‰ê°€:

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
----------------------------------------
ğŸ¯ ì •í™•ë„: 0.9899 (99.00%)

ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:
  Survivor       : ì •ë°€ë„=0.997, ì¬í˜„ìœ¨=0.996, F1=0.997
  Survivor       : ì •ë°€ë„=0.997, ì¬í˜„ìœ¨=0.996, F1=0.997
  Explorer       : ì •ë°€ë„=0.983, ì¬í˜„ìœ¨=0.966, F1=0.975
  Explorer       : ì •ë°€ë„=0.983, ì¬í˜„ìœ¨=0.966, F1=0.975
  Explorer       : ì •ë°€ë„=0.983, ì¬í˜„ìœ¨=0.966, F1=0.975
  Explorer       : ì •ë°€ë„=0.983, ì¬í˜„ìœ¨=0.966, F1=0.975
  Explorer       : ì •ë°€ë„=0.983, ì¬í˜„ìœ¨=0.966, F1=0.975
  Aggressive     : ì •ë°€ë„=1.000, ì¬í˜„ìœ¨=1.000, F1=1.000

ğŸ“Š ì „ì²´ í‰ê· :
  Macro Avg    : F1=0.987
  Weighted Avg : F1=0.990
  ì •í™•ë„: 0.9899
  F1 (Macro): 0.9874
```

![Screenshot](image/Residualëª¨ë¸í‰ê°€.png)

``` bash
ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: Basic
  ì •í™•ë„: 0.9925

==================== 5ë‹¨ê³„: ìµœê³  ëª¨ë¸ ìƒì„¸ ë¶„ì„ ====================

ğŸ”„ í˜¼ë™ í–‰ë ¬ ìƒì„±
----------------------------------------
```

![Screenshot](image/5ë‹¨ê³„_ìµœê³ ëª¨ë¸ìƒì„¸ë¶„ì„.png)

``` bash
ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ ì •í™•ë„:
  Survivor       : 0.996 (99.6%)
  Survivor       : 0.999 (99.9%)
  Explorer       : 0.990 (99.0%)
  Explorer       : 0.994 (99.4%)
  Explorer       : 0.969 (96.9%)
  Explorer       : 0.996 (99.6%)
  Explorer       : 0.967 (96.7%)
  Aggressive     : 1.000 (100.0%)

ğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„
----------------------------------------
```

![Screenshot](image/ì˜ˆì¸¡_ì‹ ë¢°ë„_ë¶„ì„.png)

``` bash
ğŸ“Š ì‹ ë¢°ë„ í†µê³„:
  í‰ê·  ì‹ ë¢°ë„: 0.990
  ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: 0.050
  ë†’ì€ ì‹ ë¢°ë„ (>0.8) ë¹„ìœ¨: 98.2%
  ë‚®ì€ ì‹ ë¢°ë„ (<0.5) ë¹„ìœ¨: 0.0%

ğŸ” Permutation Importance íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
----------------------------------------
ğŸ”„ íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...
  ì§„í–‰: 1/30
  ì§„í–‰: 11/30
  ì§„í–‰: 21/30
```

![Screenshot](image/Permutation_ImportanceíŠ¹ì„±_ì¤‘ìš”ë„_ë¶„ì„.png)

``` bash
ğŸ“Š ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:
   1. has_kills                : 0.3232
   2. walkDistance_log         : 0.0788
   3. walkDistance             : 0.0751
   4. total_distance           : 0.0634
   5. has_swimDistance         : 0.0609
   6. weaponsAcquired          : 0.0588
   7. killPlace                : 0.0573
   8. damageDealt              : 0.0519
   9. rideDistance             : 0.0512
  10. heal_boost_ratio         : 0.0501

==================== 6ë‹¨ê³„: ì•™ìƒë¸” ëª¨ë¸ ====================

ğŸ¤ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (ì†Œí”„íŠ¸ ë³´íŒ…)
----------------------------------------
âœ… Basic ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ
âœ… Advanced ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ
âœ… Residual ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ
ğŸ“Š ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:
  ì •í™•ë„: 0.9927

ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ:
  vs Basic: +0.0002 (+0.02%)
  vs Advanced: +0.0031 (+0.31%)
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
  vs Residual: +0.0028 (+0.28%)

==================== ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ìš”ì•½ ====================
â° ì‹¤í–‰ ì‹œê°„: 525.6ì´ˆ
ğŸ¯ í›ˆë ¨ëœ ëª¨ë¸ ìˆ˜: 3ê°œ
ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: Basic
ğŸ“Š ìµœê³  ëª¨ë¸ ì„±ëŠ¥:
  ì •í™•ë„: 0.9925
  F1 (Macro): 0.9867
ğŸ¤ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥: 0.9927
ğŸš€ ì•™ìƒë¸” í–¥ìƒë„: +0.0002 (+0.02%)
âœ… Phase 6 ì™„ë£Œ! Phase 7 (ëª¨ë¸ í•´ì„)ë¡œ ì§„í–‰ ê°€ëŠ¥

ğŸ“Š Phase 6 ì‹¤í–‰ ê²°ê³¼:
ìµœê³  ëª¨ë¸: Basic
ìµœê³  ì„±ëŠ¥: 0.9925
ì•™ìƒë¸” ì„±ëŠ¥: 0.9927

ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...

ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
----------------------------------------
âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: pubg_best_model.h5
âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: pubg_best_model_metadata.json
ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„± ì¤‘...

ğŸ¯ ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±
----------------------------------------
âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„± ì™„ë£Œ
ğŸ“Š ëª¨ë¸ ì •ë³´:
  íŠ¹ì„± ìˆ˜: 30
  í´ëŸ¬ìŠ¤í„° ìˆ˜: 8
  ëª¨ë¸ ì •í™•ë„: 0.9925

ğŸ‰ Phase 6 ì™„ë£Œ!
âœ… ë‹¤ìŒ ë‹¨ê³„: Phase 7 - ëª¨ë¸ í•´ì„ ë° ê³ ë„í™”

ğŸ“ Phase 6 ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:
â€¢ dl_results: ë”¥ëŸ¬ë‹ ê²°ê³¼
â€¢ predict_fn: ìƒˆ í”Œë ˆì´ì–´ ì˜ˆì¸¡ í•¨ìˆ˜
â€¢ model_path: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
```

## Phase 7: ëª¨ë¸ í•´ì„ ë° ê³ ë„í™”

### 1. í•„ìš”í•œ ë³€ìˆ˜ë“¤ í™•ì¸ ë° ì„¤ì •
``` python

print("ğŸ” Phase 7: ëª¨ë¸ í•´ì„ ë° ê³ ë„í™” ")
print("="*60)

import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‹ Phase 7 ì‹¤í–‰ ì „ ë³€ìˆ˜ í™•ì¸...")

required_vars = ['dl_results', 'clustering_results', 'modeling_data']
missing_vars = []

for var_name in required_vars:
    if var_name in globals():
        print(f"âœ… {var_name}: ì¡´ì¬í•¨")
    else:
        print(f"âŒ {var_name}: ì—†ìŒ")
        missing_vars.append(var_name)

if missing_vars:
    print(f"âš ï¸ ëˆ„ë½ëœ ë³€ìˆ˜: {missing_vars}")
    print("ğŸ”„ Phase 6ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
else:
    print("âœ… ëª¨ë“  í•„ìš” ë³€ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!")

print("\n" + "="*60)
```
### 2. ê°„ì†Œí™”ëœ SHAP ë¶„ì„ í•¨ìˆ˜
``` python
def simplified_shap_analysis(model, X_sample, feature_names, max_samples=50):
    """ê°„ì†Œí™”ëœ SHAP ë¶„ì„ (ì˜¤ë¥˜ ë°©ì§€ìš©)"""
    print("ğŸ” ê°„ì†Œí™”ëœ SHAP ë¶„ì„ ì‹œì‘...")

    try:
        # SHAP ì„¤ì¹˜ í™•ì¸
        try:
            import shap
            print("âœ… SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
        except ImportError:
            print("ğŸ“¦ SHAP ì„¤ì¹˜ ì¤‘...")
            import subprocess
            import sys
            subprocess.check_call([sys.executable, "-m", "pip", "install", "shap", "--quiet"])
            import shap
            print("âœ… SHAP ì„¤ì¹˜ ë° ë¡œë“œ ì™„ë£Œ")

        # ì‘ì€ ìƒ˜í”Œë¡œ ë¶„ì„
        small_sample = X_sample.head(max_samples)
        print(f"ğŸ¯ ë¶„ì„ ìƒ˜í”Œ: {len(small_sample)}ê°œ")

        # ê°„ë‹¨í•œ ë°°ê²½ ë°ì´í„° (í‰ê· ê°’ ì‚¬ìš©)
        background = X_sample.mean().values.reshape(1, -1)

        # KernelExplainer ì‚¬ìš© (ë” ì•ˆì •ì )
        def model_predict(X):
            if hasattr(X, 'values'):
                X = X.values
            return model.predict(X, verbose=0)

        explainer = shap.KernelExplainer(model_predict, background)

        print("ğŸ”„ SHAP ê°’ ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        shap_values = explainer.shap_values(small_sample.values, nsamples=50)

        # ê°„ë‹¨í•œ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        if isinstance(shap_values, list):
            # ë‹¤ì¤‘ í´ë˜ìŠ¤ì¸ ê²½ìš° ì²« ë²ˆì§¸ í´ë˜ìŠ¤ ì‚¬ìš©
            importance_values = np.abs(shap_values[0]).mean(axis=0)
        else:
            importance_values = np.abs(shap_values).mean(axis=0)

        # íŠ¹ì„± ì¤‘ìš”ë„ DataFrame ìƒì„±
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance_values
        }).sort_values('importance', ascending=False)

        print("âœ… SHAP ë¶„ì„ ì™„ë£Œ")
        return feature_importance_df, shap_values, small_sample

    except Exception as e:
        print(f"âš ï¸ SHAP ë¶„ì„ ì‹¤íŒ¨: {e}")
        print("ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°...")

        # ëŒ€ì•ˆ: Permutation Importance
        from sklearn.metrics import accuracy_score

        # ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥
        y_pred_baseline = np.argmax(model.predict(X_sample.values, verbose=0), axis=1)

        importance_scores = []
        for i, feature_name in enumerate(feature_names):
            # íŠ¹ì„± ì…í”Œ
            X_shuffled = X_sample.copy()
            X_shuffled.iloc[:, i] = np.random.permutation(X_shuffled.iloc[:, i].values)

            # ì„±ëŠ¥ ì¸¡ì •
            y_pred_shuffled = np.argmax(model.predict(X_shuffled.values, verbose=0), axis=1)

            # ì¤‘ìš”ë„ = ì„±ëŠ¥ ì°¨ì´
            importance = np.mean(y_pred_baseline != y_pred_shuffled)
            importance_scores.append(importance)

        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance_scores
        }).sort_values('importance', ascending=False)

        print("âœ… ëŒ€ì•ˆ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ì™„ë£Œ")
        return feature_importance_df, None, X_sample.head(20)
```
### 3. ê°„ì†Œí™”ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í•¨ìˆ˜
``` python
def generate_business_insights_simple(cluster_profiles, cluster_names, feature_importance_df):
    """ê°„ì†Œí™”ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    print("ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±...")

    insights = {}

    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„
    print("ğŸ¯ í”Œë ˆì´ì–´ ìœ í˜•ë³„ í•µì‹¬ íŠ¹ì§•:")
    for cluster_id, profile in cluster_profiles.items():
        cluster_name = cluster_names.get(cluster_id, f'Cluster_{cluster_id}')
        size_pct = profile['percentage']

        print(f"\nğŸ“Š {cluster_name} ({size_pct:.1f}% of players)")

        # ìƒìœ„ íŠ¹ì„±
        if hasattr(profile.get('top_features', []), 'head'):
            top_features = profile['top_features'].head(3)
            for feature, ratio in top_features.items():
                print(f"  â€¢ {feature}: {ratio:.2f}x above average")

        insights[cluster_name] = {
            'percentage': size_pct,
            'cluster_id': cluster_id
        }

    # ì „ì²´ ê²Œì„ ë°¸ëŸ°ìŠ¤
    cluster_sizes = [profile['percentage'] for profile in cluster_profiles.values()]
    balance_score = np.std(cluster_sizes)

    if balance_score < 5:
        balance_level = "Very Balanced"
    elif balance_score < 10:
        balance_level = "Balanced"
    else:
        balance_level = "Imbalanced"

    insights['game_balance'] = {
        'level': balance_level,
        'score': balance_score
    }

    print(f"\nğŸ® ê²Œì„ ë°¸ëŸ°ìŠ¤: {balance_level} (í¸ì°¨: {balance_score:.2f})")

    # í•µì‹¬ ì„±ê³µ ìš”ì¸
    print(f"\nâ­ í•µì‹¬ ì„±ê³µ ìš”ì¸ (ìƒìœ„ 5ê°œ):")
    for i, (_, row) in enumerate(feature_importance_df.head(5).iterrows(), 1):
        print(f"  {i}. {row['feature']}: {row['importance']:.4f}")

    insights['success_factors'] = feature_importance_df.head(5).to_dict('records')

    return insights
```
### 4. ê°„ì†Œí™”ëœ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ
``` python
def create_simple_anomaly_detector(clustering_results, modeling_data):
    """ê°„ì†Œí™”ëœ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ"""
    print("ğŸš¨ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•...")

    kmeans_model = clustering_results['kmeans_model']
    X_train = modeling_data['X_train']

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ í‰ê·  ê±°ë¦¬ ê³„ì‚°
    cluster_centers = kmeans_model.cluster_centers_
    cluster_labels = clustering_results['cluster_labels']

    # ì„ê³„ê°’ ê³„ì‚°
    distances = []
    for i, center in enumerate(cluster_centers):
        cluster_data = X_train[cluster_labels == i]
        if len(cluster_data) > 0:
            dist = np.linalg.norm(cluster_data - center, axis=1)
            distances.extend(dist)

    threshold = np.percentile(distances, 95)  # ìƒìœ„ 5%ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼

    def detect_anomaly(player_features):
        """í”Œë ˆì´ì–´ ì´ìƒì¹˜ íƒì§€"""
        # ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
        distances_to_centers = [np.linalg.norm(player_features - center)
                               for center in cluster_centers]
        min_distance = min(distances_to_centers)
        closest_cluster = np.argmin(distances_to_centers)

        is_anomaly = min_distance > threshold
        anomaly_score = min_distance / threshold

        return {
            'is_anomaly': is_anomaly,
            'anomaly_score': anomaly_score,
            'closest_cluster': int(closest_cluster),
            'distance': min_distance,
            'threshold': threshold
        }

    print(f"âœ… ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ ì™„ë£Œ (ì„ê³„ê°’: {threshold:.3f})")
    return detect_anomaly
```
### 5. ì¢…í•© Phase 7 ì‹¤í–‰
``` python
def run_phase7_simplified():
    """Phase 7 ê°„ì†Œí™” ì‹¤í–‰"""
    print("ğŸš€ Phase 7 ê°„ì†Œí™” íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*50)

    start_time = time.time()

    try:
        # ìµœê³  ëª¨ë¸ ì¶”ì¶œ
        best_model_name = dl_results['best_model_name']
        best_model = dl_results['models'][best_model_name]

        X_test = dl_results['classification_data']['X_test']
        feature_names = dl_results['classification_data']['feature_names']
        cluster_names = dl_results['classification_data']['cluster_names']

        print(f"ğŸ¯ ë¶„ì„ ëŒ€ìƒ ëª¨ë¸: {best_model_name}")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")

        # 1. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (SHAP ë˜ëŠ” ëŒ€ì•ˆ)
        print(f"\n{'='*15} 1. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ {'='*15}")
        feature_importance_df, shap_values, sample_data = simplified_shap_analysis(
            best_model, X_test.head(100), feature_names
        )

        # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        print(f"\n{'='*15} 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ {'='*15}")
        business_insights = generate_business_insights_simple(
            clustering_results['cluster_profiles'],
            clustering_results['cluster_names'],
            feature_importance_df
        )

        # 3. ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ
        print(f"\n{'='*15} 3. ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ {'='*15}")
        anomaly_detector = create_simple_anomaly_detector(clustering_results, modeling_data)

        # í…ŒìŠ¤íŠ¸
        print("ğŸ§ª ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸...")
        test_samples = X_test.head(5)
        for i, (_, row) in enumerate(test_samples.iterrows(), 1):
            result = anomaly_detector(row.values)
            status = "ğŸš¨ ì´ìƒì¹˜" if result['is_anomaly'] else "âœ… ì •ìƒ"
            print(f"  ìƒ˜í”Œ {i}: {status} (ì ìˆ˜: {result['anomaly_score']:.3f})")

        # 4. ê°„ë‹¨í•œ A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„
        print(f"\n{'='*15} 4. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ {'='*15}")
        ab_test_suggestions = {}

        for cluster_name, insight in business_insights.items():
            if cluster_name != 'game_balance':
                ab_test_suggestions[cluster_name] = [
                    f"{cluster_name} ê·¸ë£¹ ëŒ€ìƒ ë§ì¶¤í˜• ì»¨í…ì¸  í…ŒìŠ¤íŠ¸",
                    f"{cluster_name} í”Œë ˆì´ì–´ ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ ê°œì„ ",
                    f"{cluster_name} ìœ í˜•ë³„ íŠœí† ë¦¬ì–¼ ìµœì í™”"
                ]

        print("ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ:")
        for cluster_name, suggestions in ab_test_suggestions.items():
            print(f"\nğŸ¯ {cluster_name}:")
            for suggestion in suggestions[:2]:
                print(f"  â€¢ {suggestion}")

        execution_time = time.time() - start_time

        # ê²°ê³¼ ì •ë¦¬
        interpretation_results = {
            'feature_importance': feature_importance_df,
            'business_insights': business_insights,
            'anomaly_detector': anomaly_detector,
            'ab_test_suggestions': ab_test_suggestions,
            'shap_analysis': {
                'success': shap_values is not None,
                'sample_data': sample_data
            }
        }

        print(f"\n{'='*15} Phase 7 ì™„ë£Œ ìš”ì•½ {'='*15}")
        print(f"â° ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
        print(f"ğŸ¯ ë¶„ì„ëœ íŠ¹ì„±: {len(feature_names)}ê°œ")
        print(f"ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸: {len(business_insights)}ê°œ ë¶„ì•¼")
        print(f"ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ: {len(ab_test_suggestions)}ê°œ ê·¸ë£¹")
        print(f"ğŸš¨ ì´ìƒì¹˜ íƒì§€: {'í™œì„±í™”' if anomaly_detector else 'ë¹„í™œì„±í™”'}")

        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìš”ì•½
        print(f"\nğŸ’ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
        if 'game_balance' in business_insights:
            balance = business_insights['game_balance']
            print(f"  ğŸ® ê²Œì„ ë°¸ëŸ°ìŠ¤: {balance['level']}")

        top_feature = feature_importance_df.iloc[0]
        print(f"  â­ ìµœê³  ì¤‘ìš” íŠ¹ì„±: {top_feature['feature']} ({top_feature['importance']:.4f})")

        print(f"âœ… Phase 7 ì™„ë£Œ! Phase 8 (ë°°í¬)ë¡œ ì§„í–‰ ê°€ëŠ¥")

        return interpretation_results

    except Exception as e:
        print(f"âŒ Phase 7 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None
```
### ì‹¤í–‰
``` python
if not missing_vars:
    print("ğŸ¬ Phase 7 ì‹¤í–‰ ì‹œì‘!")
    interpretation_results = run_phase7_simplified()

    if interpretation_results:
        print("\nğŸ‰ Phase 7 ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        print("ğŸ“Š ìƒì„±ëœ ê²°ê³¼:")
        print(f"  â€¢ feature_importance: íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
        print(f"  â€¢ business_insights: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸")
        print(f"  â€¢ anomaly_detector: ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜")
        print(f"  â€¢ ab_test_suggestions: A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ")

        # ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ
        print(f"\nğŸ” ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ:")
        print(f"# new_player = [5.0, 350.0, 2000.0, ...]  # í”Œë ˆì´ì–´ íŠ¹ì„±")
        print(f"# result = interpretation_results['anomaly_detector'](new_player)")
        print(f"# print('ì´ìƒì¹˜ ì—¬ë¶€:', result['is_anomaly'])")

    else:
        print("âŒ Phase 7 ì‹¤í–‰ ì‹¤íŒ¨")
        print("ğŸ”„ ì´ì „ Phaseë“¤ì„ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”.")
else:
    print("âŒ í•„ìš”í•œ ë³€ìˆ˜ê°€ ì—†ì–´ Phase 7ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ”„ Phase 6ì„ ë¨¼ì € ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
```

#### ì‹¤í–‰ ê²°ê³¼

``` bash
ğŸ¬ Phase 7 ì‹¤í–‰ ì‹œì‘!
ğŸš€ Phase 7 ê°„ì†Œí™” íŒŒì´í”„ë¼ì¸ ì‹œì‘
==================================================
ğŸ¯ ë¶„ì„ ëŒ€ìƒ ëª¨ë¸: Basic
ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: (20000, 30)

=============== 1. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ===============
ğŸ” ê°„ì†Œí™”ëœ SHAP ë¶„ì„ ì‹œì‘...
âœ… SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ
ğŸ¯ ë¶„ì„ ìƒ˜í”Œ: 50ê°œ
ğŸ”„ SHAP ê°’ ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)
100%
â€‡50/50â€‡[00:11<00:00,â€‡â€‡4.98it/s]
âš ï¸ SHAP ë¶„ì„ ì‹¤íŒ¨: Per-column arrays must each be 1-dimensional
ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°...
âœ… ëŒ€ì•ˆ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ì™„ë£Œ

=============== 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ===============
ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±...
ğŸ¯ í”Œë ˆì´ì–´ ìœ í˜•ë³„ í•µì‹¬ íŠ¹ì§•:

ğŸ“Š Survivor (18.2% of players)
  â€¢ heal_boost_ratio: 775.29x above average
  â€¢ assists: 479.86x above average
  â€¢ has_swimDistance: 294.02x above average

ğŸ“Š Survivor (31.2% of players)
  â€¢ heal_boost_ratio: 1861.49x above average
  â€¢ assists: 964.62x above average
  â€¢ damage_per_kill: 864.65x above average

ğŸ“Š Explorer (13.4% of players)
  â€¢ walkDistance_log: 3743.08x above average
  â€¢ walkDistance: 1179.09x above average
  â€¢ revives: 626.25x above average

ğŸ“Š Explorer (19.9% of players)
  â€¢ walkDistance_log: 2245.80x above average
  â€¢ longestKill: 610.84x above average
  â€¢ has_kills: 501.94x above average

ğŸ“Š Explorer (5.4% of players)
  â€¢ walkDistance_log: 4451.52x above average
  â€¢ walkDistance: 1845.04x above average
  â€¢ revives: 1551.02x above average

ğŸ“Š Explorer (5.1% of players)
  â€¢ walkDistance_log: 4139.77x above average
  â€¢ walkDistance: 1544.91x above average
  â€¢ weaponsAcquired: 451.79x above average

ğŸ“Š Explorer (6.7% of players)
  â€¢ walkDistance_log: 3995.30x above average
  â€¢ matchDuration: 1400.69x above average
  â€¢ walkDistance: 1327.73x above average

ğŸ“Š Aggressive (0.1% of players)
  â€¢ kill_efficiency: 23396.88x above average
  â€¢ damage_per_kill: 1435.73x above average
  â€¢ assists: 920.03x above average

ğŸ® ê²Œì„ ë°¸ëŸ°ìŠ¤: Balanced (í¸ì°¨: 9.56)

â­ í•µì‹¬ ì„±ê³µ ìš”ì¸ (ìƒìœ„ 5ê°œ):
  1. has_kills: 0.2700
  2. walkDistance_log: 0.1200
  3. weaponsAcquired: 0.1000
  4. walkDistance: 0.0900
  5. damageDealt_log: 0.0700

=============== 3. ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ ===============
ğŸš¨ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•...
âœ… ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ ì™„ë£Œ (ì„ê³„ê°’: 6.761)
ğŸ§ª ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸...
  ìƒ˜í”Œ 1: âœ… ì •ìƒ (ì ìˆ˜: 0.393)
  ìƒ˜í”Œ 2: âœ… ì •ìƒ (ì ìˆ˜: 0.682)
  ìƒ˜í”Œ 3: âœ… ì •ìƒ (ì ìˆ˜: 0.344)
  ìƒ˜í”Œ 4: âœ… ì •ìƒ (ì ìˆ˜: 0.263)
  ìƒ˜í”Œ 5: âœ… ì •ìƒ (ì ìˆ˜: 0.398)

=============== 4. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ===============
ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ:

ğŸ¯ Survivor:
  â€¢ Survivor ê·¸ë£¹ ëŒ€ìƒ ë§ì¶¤í˜• ì»¨í…ì¸  í…ŒìŠ¤íŠ¸
  â€¢ Survivor í”Œë ˆì´ì–´ ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ ê°œì„ 

ğŸ¯ Explorer:
  â€¢ Explorer ê·¸ë£¹ ëŒ€ìƒ ë§ì¶¤í˜• ì»¨í…ì¸  í…ŒìŠ¤íŠ¸
  â€¢ Explorer í”Œë ˆì´ì–´ ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ ê°œì„ 

ğŸ¯ Aggressive:
  â€¢ Aggressive ê·¸ë£¹ ëŒ€ìƒ ë§ì¶¤í˜• ì»¨í…ì¸  í…ŒìŠ¤íŠ¸
  â€¢ Aggressive í”Œë ˆì´ì–´ ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ ê°œì„ 

ğŸ¯ success_factors:
  â€¢ success_factors ê·¸ë£¹ ëŒ€ìƒ ë§ì¶¤í˜• ì»¨í…ì¸  í…ŒìŠ¤íŠ¸
  â€¢ success_factors í”Œë ˆì´ì–´ ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ ê°œì„ 

=============== Phase 7 ì™„ë£Œ ìš”ì•½ ===============
â° ì‹¤í–‰ ì‹œê°„: 17.1ì´ˆ
ğŸ¯ ë¶„ì„ëœ íŠ¹ì„±: 30ê°œ
ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸: 5ê°œ ë¶„ì•¼
ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ: 4ê°œ ê·¸ë£¹
ğŸš¨ ì´ìƒì¹˜ íƒì§€: í™œì„±í™”

ğŸ’ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:
  ğŸ® ê²Œì„ ë°¸ëŸ°ìŠ¤: Balanced
  â­ ìµœê³  ì¤‘ìš” íŠ¹ì„±: has_kills (0.2700)
âœ… Phase 7 ì™„ë£Œ! Phase 8 (ë°°í¬)ë¡œ ì§„í–‰ ê°€ëŠ¥

ğŸ‰ Phase 7 ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!
ğŸ“Š ìƒì„±ëœ ê²°ê³¼:
  â€¢ feature_importance: íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
  â€¢ business_insights: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
  â€¢ anomaly_detector: ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜
  â€¢ ab_test_suggestions: A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ

ğŸ” ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ:
# new_player = [5.0, 350.0, 2000.0, ...]  # í”Œë ˆì´ì–´ íŠ¹ì„±
# result = interpretation_results['anomaly_detector'](new_player)
# print('ì´ìƒì¹˜ ì—¬ë¶€:', result['is_anomaly'])
```

## Phase 8: ëª¨ë¸ ë°°í¬ ë° ì„œë¹„ìŠ¤í™”

### 1. ì„¸íŒ…
``` python

# Phase 8 ëª¨ë¸ ë°°í¬ ë° ì„œë¹„ìŠ¤í™”

import os
import subprocess
import sys
import time

print("ğŸ”§ Phase 8 ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „ ì‹¤í–‰")
print("="*50)

# 1. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
print(f"ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
packages = ["fastapi", "uvicorn", "streamlit", "nest-asyncio"]
for package in packages:
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package, "--quiet"])
        print(f"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ")
    except:
        print(f"âš ï¸ {package} ì„¤ì¹˜ ì‹¤íŒ¨")

# 2. FastAPI ì•± ì½”ë“œ (ìˆ˜ì •ëœ ë²„ì „)
fastapi_code = '''#!/usr/bin/env python3
# fastapi_app.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import numpy as np
from datetime import datetime
from typing import Dict
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="PUBG Player Classification API",
    description="PUBG í”Œë ˆì´ì–´ ë¶„ë¥˜ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë°ì´í„° ëª¨ë¸
class PlayerData(BaseModel):
    kills: float = Field(default=0, ge=0, description="í‚¬ ìˆ˜")
    damageDealt: float = Field(default=0, ge=0, description="ì´ ë°ë¯¸ì§€")
    walkDistance: float = Field(default=0, ge=0, description="ë„ë³´ ê±°ë¦¬")
    rideDistance: float = Field(default=0, ge=0, description="ì°¨ëŸ‰ ê±°ë¦¬")
    heals: float = Field(default=0, ge=0, description="ì¹˜ë£Œí…œ ì‚¬ìš©")
    boosts: float = Field(default=0, ge=0, description="ë¶€ìŠ¤í„° ì‚¬ìš©")
    weaponsAcquired: float = Field(default=0, ge=0, description="ë¬´ê¸° íšë“")
    assists: float = Field(default=0, ge=0, description="ì–´ì‹œìŠ¤íŠ¸")

class PredictionResult(BaseModel):
    player_type: str
    cluster_id: int
    confidence: float
    probabilities: Dict[str, float]
    is_anomaly: bool
    processing_time_ms: float

# API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/")
async def root():
    return {
        "message": "PUBG Player Classification API",
        "version": "1.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }

@app.post("/predict", response_model=PredictionResult)
async def predict_player_type(data: PlayerData):
    """í”Œë ˆì´ì–´ ìœ í˜• ì˜ˆì¸¡"""
    start_time = datetime.now()

    try:
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ ë¡œì§
        np.random.seed(int(data.kills + data.damageDealt) % 1000)

        # í”Œë ˆì´ì–´ ìœ í˜• ê²°ì •
        if data.kills > 5 and data.damageDealt > 300:
            player_type = "Aggressive Fighter"
            cluster_id = 0
        elif data.heals > 3 and data.boosts > 2:
            player_type = "Cautious Survivor"
            cluster_id = 1
        elif data.walkDistance > 2000:
            player_type = "Mobile Explorer"
            cluster_id = 2
        elif data.assists > 2:
            player_type = "Team Supporter"
            cluster_id = 3
        else:
            player_type = "Balanced Player"
            cluster_id = 4

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = np.random.uniform(0.75, 0.95)

        # í™•ë¥  ë¶„í¬ ìƒì„±
        player_types = ["Aggressive Fighter", "Cautious Survivor", "Mobile Explorer",
                       "Team Supporter", "Balanced Player"]

        probabilities = {}
        for i, ptype in enumerate(player_types):
            if i == cluster_id:
                probabilities[ptype] = confidence
            else:
                probabilities[ptype] = np.random.uniform(0.05, 0.25)

        # í™•ë¥  ì •ê·œí™”
        total_prob = sum(probabilities.values())
        probabilities = {k: v/total_prob for k, v in probabilities.items()}

        # ì´ìƒì¹˜ íƒì§€
        is_anomaly = (data.kills > 20 or data.damageDealt > 2000 or
                     data.walkDistance > 10000)

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds() * 1000

        return PredictionResult(
            player_type=player_type,
            cluster_id=cluster_id,
            confidence=confidence,
            probabilities=probabilities,
            is_anomaly=is_anomaly,
            processing_time_ms=processing_time
        )

    except Exception as e:
        logger.error(f"Prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")

@app.get("/model/info")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    return {
        "model_name": "PUBG Player Classifier",
        "accuracy": 0.925,
        "feature_count": 8,
        "cluster_names": {
            "0": "Aggressive Fighter",
            "1": "Cautious Survivor",
            "2": "Mobile Explorer",
            "3": "Team Supporter",
            "4": "Balanced Player"
        },
        "environment": "Google Colab"
    }

# ì•± ì‹¤í–‰ (ì§ì ‘ ì‹¤í–‰ìš©)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

# 3. íŒŒì¼ ì €ì¥ (ê²½ë¡œ í™•ì¸)
app_file_path = os.path.join(os.getcwd(), 'fastapi_app.py')
with open(app_file_path, 'w', encoding='utf-8') as f:
    f.write(fastapi_code)

print(f"âœ… FastAPI ì•± íŒŒì¼ ìƒì„±: {app_file_path}")

# 4. íŒŒì¼ ì¡´ì¬ í™•ì¸
if os.path.exists(app_file_path):
    print(f"âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸ë¨")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {os.path.getsize(app_file_path)} bytes")
else:
    print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")

# 5. Python ê²½ë¡œì— í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.insert(0, os.getcwd())

# 6. ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
try:
    import fastapi_app
    print("âœ… ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
except Exception as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

print("\nğŸš€ ì´ì œ FastAPI ì‹¤í–‰:")
print("ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ìƒˆ ì…€ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:")
print("!python -m uvicorn fastapi_app:app --host 0.0.0.0 --port 8000 --reload")

print("\në˜ëŠ” Python ì½”ë“œë¡œ:")
print("exec(open('start_fastapi.py').read())")

# 7. ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
start_script = '''
import subprocess
import sys
import os

print("ğŸš€ FastAPI ì„œë²„ ì‹œì‘...")
print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")

# FastAPI ì‹¤í–‰
try:
    result = subprocess.run([
        sys.executable, "-m", "uvicorn",
        "fastapi_app:app",
        "--host", "0.0.0.0",
        "--port", "8000",
        "--reload"
    ], capture_output=False, text=True)
except KeyboardInterrupt:
    print("\\nâ¹ï¸ ì„œë²„ ì¤‘ì§€ë¨")
except Exception as e:
    print(f"âŒ ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
'''

with open('start_fastapi.py', 'w') as f:
    f.write(start_script)

print("âœ… start_fastapi.py ìƒì„± ì™„ë£Œ")

# 8. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ í•¨ìˆ˜
def start_fastapi_background():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ FastAPI ì‹¤í–‰"""
    print("ğŸ”„ FastAPI ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œë„...")

    try:
        # ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        process = subprocess.Popen([
            sys.executable, "-m", "uvicorn",
            "fastapi_app:app",
            "--host", "0.0.0.0",
            "--port", "8000"
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        print(f"âœ… FastAPI í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})")

        # ì ì‹œ ëŒ€ê¸° í›„ ìƒíƒœ í™•ì¸
        time.sleep(3)

        if process.poll() is None:
            print("âœ… ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            print("ğŸ“ API ì£¼ì†Œ: http://127.0.0.1:8000")
            print("ğŸ“– API ë¬¸ì„œ: http://127.0.0.1:8000/docs")
            return process
        else:
            print("âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
            stdout, stderr = process.communicate()
            print(f"STDOUT: {stdout.decode()}")
            print(f"STDERR: {stderr.decode()}")
            return None

    except Exception as e:
        print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None

print("\nğŸ’¡ ì‹¤í–‰ ì˜µì…˜:")
print("1. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰: start_fastapi_background()")
print("2. ì§ì ‘ ì‹¤í–‰: exec(open('start_fastapi.py').read())")
print("3. ëª…ë ¹ì–´ ì‹¤í–‰: !python -m uvicorn fastapi_app:app --host 0.0.0.0 --port 8000")
```
### 2. FastAPI ì„œë²„ ì‹œì‘
``` python
start_fastapi_background()
```
#### 2-1 í¬íŠ¸ ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì¢…ë£Œ
``` python
# í¬íŠ¸ 8000 ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì¢…ë£Œ
import subprocess
import os

print("ğŸ” í¬íŠ¸ 8000 ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸...")

# í¬íŠ¸ 8000 ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
try:
    result = subprocess.run(['lsof', '-i', ':8000'], capture_output=True, text=True)
    if result.stdout:
        print("ğŸ“‹ í¬íŠ¸ 8000 ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤:")
        print(result.stdout)

        # uvicorn í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
        print("ğŸ”„ ê¸°ì¡´ uvicorn í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì¤‘...")
        subprocess.run(['pkill', '-f', 'uvicorn'], capture_output=True)
        subprocess.run(['pkill', '-f', 'fastapi'], capture_output=True)
        print("âœ… ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì™„ë£Œ")
    else:
        print("â„¹ï¸ í¬íŠ¸ 8000 ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì—†ìŒ")
except:
    print("âš ï¸ lsof ëª…ë ¹ì–´ ì‚¬ìš© ë¶ˆê°€, pkillë¡œ ì§ì ‘ ì¢…ë£Œ ì‹œë„...")
    subprocess.run(['pkill', '-f', 'uvicorn'], capture_output=True)
    subprocess.run(['pkill', '-f', 'fastapi'], capture_output=True)
    print("âœ… í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œë„ ì™„ë£Œ")

print("\nğŸ’¡ ì´ì œ ë‹¤ì‹œ FastAPIë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
```
### 3. API í…ŒìŠ¤íŠ¸
``` python
import requests
import time
import json

print("ğŸ§ª API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
print("="*40)

# 1. í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸
print("1ï¸âƒ£ í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸...")
try:
    response = requests.get("http://127.0.0.1:8000/health")
    if response.status_code == 200:
        result = response.json()
        print("âœ… í—¬ìŠ¤ì²´í¬ ì„±ê³µ!")
        print(f"   ìƒíƒœ: {result['status']}")
        print(f"   ì‹œê°„: {result['timestamp']}")
    else:
        print(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {response.status_code}")
except Exception as e:
    print(f"âŒ í—¬ìŠ¤ì²´í¬ ì˜¤ë¥˜: {e}")

print()

# 2. ê¸°ë³¸ API í…ŒìŠ¤íŠ¸
print("2ï¸âƒ£ ê¸°ë³¸ API í…ŒìŠ¤íŠ¸...")
try:
    response = requests.get("http://127.0.0.1:8000/")
    if response.status_code == 200:
        result = response.json()
        print("âœ… ê¸°ë³¸ API ì‘ë‹µ ì„±ê³µ!")
        print(f"   ë©”ì‹œì§€: {result['message']}")
        print(f"   ë²„ì „: {result['version']}")
    else:
        print(f"âŒ ê¸°ë³¸ API ì‹¤íŒ¨: {response.status_code}")
except Exception as e:
    print(f"âŒ ê¸°ë³¸ API ì˜¤ë¥˜: {e}")

print()

# 3. ëª¨ë¸ ì •ë³´ í…ŒìŠ¤íŠ¸
print("3ï¸âƒ£ ëª¨ë¸ ì •ë³´ í…ŒìŠ¤íŠ¸...")
try:
    response = requests.get("http://127.0.0.1:8000/model/info")
    if response.status_code == 200:
        result = response.json()
        print("âœ… ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì„±ê³µ!")
        print(f"   ëª¨ë¸ëª…: {result['model_name']}")
        print(f"   ì •í™•ë„: {result['accuracy']}")
        print(f"   íŠ¹ì„± ê°œìˆ˜: {result['feature_count']}")
    else:
        print(f"âŒ ëª¨ë¸ ì •ë³´ ì‹¤íŒ¨: {response.status_code}")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ì •ë³´ ì˜¤ë¥˜: {e}")

print()

# 4. í”Œë ˆì´ì–´ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
print("4ï¸âƒ£ í”Œë ˆì´ì–´ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...")

test_cases = [
    {
        "name": "ê³µê²©í˜• í”Œë ˆì´ì–´",
        "data": {
            "kills": 8,
            "damageDealt": 450,
            "walkDistance": 1200,
            "rideDistance": 800,
            "heals": 1,
            "boosts": 1,
            "weaponsAcquired": 6,
            "assists": 0
        }
    },
    {
        "name": "ìƒì¡´í˜• í”Œë ˆì´ì–´",
        "data": {
            "kills": 1,
            "damageDealt": 120,
            "walkDistance": 2500,
            "rideDistance": 1500,
            "heals": 5,
            "boosts": 4,
            "weaponsAcquired": 3,
            "assists": 0
        }
    },
    {
        "name": "ì§€ì›í˜• í”Œë ˆì´ì–´",
        "data": {
            "kills": 2,
            "damageDealt": 180,
            "walkDistance": 1800,
            "rideDistance": 600,
            "heals": 3,
            "boosts": 2,
            "weaponsAcquired": 4,
            "assists": 5
        }
    }
]

for i, test_case in enumerate(test_cases, 1):
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ {i}: {test_case['name']}")

    try:
        response = requests.post("http://127.0.0.1:8000/predict", json=test_case['data'])

        if response.status_code == 200:
            result = response.json()
            print(f"   âœ… ì˜ˆì¸¡ ì„±ê³µ!")
            print(f"   ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: {result['player_type']}")
            print(f"   ğŸ¯ ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   â±ï¸ ì²˜ë¦¬ì‹œê°„: {result['processing_time_ms']:.2f}ms")
            print(f"   ğŸš¨ ì´ìƒì¹˜: {'ì˜ˆ' if result['is_anomaly'] else 'ì•„ë‹ˆì˜¤'}")
        else:
            print(f"   âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {response.status_code}")
            print(f"   ğŸ“„ ì‘ë‹µ: {response.text}")

    except Exception as e:
        print(f"   âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

print("\nğŸ‰ API í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("\nğŸ“ API ì ‘ì† ì •ë³´:")
print("   ğŸŒ API ì£¼ì†Œ: http://127.0.0.1:8000")
print("   ğŸ“– API ë¬¸ì„œ: http://127.0.0.1:8000/docs")
print("   ğŸ” ëŒ€í™”í˜• API ë¬¸ì„œì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥!")
```
### 4. Streamlit ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
``` python
# Streamlit ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì‹¤í–‰
print("ğŸ“Š Streamlit ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")

streamlit_code = '''
import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
import time

st.set_page_config(
    page_title="PUBG Player Classifier",
    page_icon="ğŸ®",
    layout="wide"
)

API_URL = "http://127.0.0.1:8000"

def check_api_health():
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        return response.status_code == 200
    except:
        return False

def predict_player(data):
    try:
        response = requests.post(f"{API_URL}/predict", json=data, timeout=10)
        return response.json() if response.status_code == 200 else None
    except Exception as e:
        st.error(f"API ì˜¤ë¥˜: {e}")
        return None

def main():
    st.title("ğŸ® PUBG Player Behavior Classifier")
    st.markdown("### AI ê¸°ë°˜ í”Œë ˆì´ì–´ í–‰ë™ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("---")

    # ì‚¬ì´ë“œë°”
    st.sidebar.title("ğŸ¯ ë©”ë‰´")
    page = st.sidebar.selectbox(
        "í˜ì´ì§€ ì„ íƒ",
        ["ğŸ  í™ˆ", "ğŸ” í”Œë ˆì´ì–´ ë¶„ì„", "ğŸ“Š ëŒ€ì‹œë³´ë“œ"]
    )

    # API ìƒíƒœ í™•ì¸
    api_healthy = check_api_health()
    if api_healthy:
        st.sidebar.success("âœ… API ì„œë²„ ì—°ê²°ë¨")
    else:
        st.sidebar.error("âŒ API ì„œë²„ ì—°ê²° ì‹¤íŒ¨")

    if page == "ğŸ  í™ˆ":
        show_home()
    elif page == "ğŸ” í”Œë ˆì´ì–´ ë¶„ì„":
        show_prediction(api_healthy)
    elif page == "ğŸ“Š ëŒ€ì‹œë³´ë“œ":
        show_dashboard()

def show_home():
    st.header("ğŸ® PUBG í”Œë ˆì´ì–´ ë¶„ë¥˜ ì‹œìŠ¤í…œ")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ¯ ëª¨ë¸ ì •í™•ë„", "92.5%")
    with col2:
        st.metric("ğŸ“Š ë¶„ì„ íŠ¹ì„±", "8ê°œ")
    with col3:
        st.metric("ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•", "5ê°œ")

    st.subheader("ğŸ¯ í”Œë ˆì´ì–´ ìœ í˜• ì†Œê°œ")

    player_types = {
        "ğŸ—¡ï¸ Aggressive Fighter": "ë†’ì€ í‚¬ ìˆ˜ì™€ ë°ë¯¸ì§€ë¥¼ ê¸°ë¡í•˜ëŠ” ê³µê²©ì ì¸ í”Œë ˆì´ì–´",
        "ğŸ›¡ï¸ Cautious Survivor": "ì¹˜ë£Œ ì•„ì´í…œì„ ë§ì´ ì‚¬ìš©í•˜ë©° ìƒì¡´ì— ì§‘ì¤‘í•˜ëŠ” í”Œë ˆì´ì–´",
        "ğŸš¶ Mobile Explorer": "ë§µì„ ë§ì´ ëŒì•„ë‹¤ë‹ˆë©° íƒí—˜í•˜ëŠ” í”Œë ˆì´ì–´",
        "ğŸ¤ Team Supporter": "ì–´ì‹œìŠ¤íŠ¸ê°€ ë§ê³  íŒ€ì„ ì§€ì›í•˜ëŠ” í”Œë ˆì´ì–´",
        "âš–ï¸ Balanced Player": "ëª¨ë“  ì§€í‘œê°€ ê· í˜•ì¡íŒ ì˜¬ë¼ìš´ë“œ í”Œë ˆì´ì–´"
    }

    for ptype, desc in player_types.items():
        st.info(f"**{ptype}**: {desc}")

    st.subheader("ğŸ“– ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ğŸ” í”Œë ˆì´ì–´ ë¶„ì„** íƒ­ì—ì„œ ê²Œì„ í†µê³„ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. **ğŸ¯ ë¶„ë¥˜í•˜ê¸°** ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ í”Œë ˆì´ì–´ ìœ í˜•ì„ í™•ì¸í•˜ì„¸ìš”
    3. **ğŸ“Š ëŒ€ì‹œë³´ë“œ** íƒ­ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)

def show_prediction(api_healthy):
    st.header("ğŸ” í”Œë ˆì´ì–´ ë¶„ì„")

    if not api_healthy:
        st.error("ğŸš¨ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        st.info("FastAPI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    with st.form("player_form"):
        st.subheader("ğŸ“Š ê²Œì„ í†µê³„ ì…ë ¥")

        col1, col2 = st.columns(2)

        with col1:
            kills = st.number_input("ğŸ¯ í‚¬ ìˆ˜", min_value=0.0, max_value=50.0, value=3.0, step=1.0)
            damage = st.number_input("ğŸ’¥ ì´ ë°ë¯¸ì§€", min_value=0.0, max_value=5000.0, value=250.0, step=10.0)
            walk_dist = st.number_input("ğŸš¶ ë„ë³´ ì´ë™ê±°ë¦¬", min_value=0.0, max_value=15000.0, value=1500.0, step=100.0)
            ride_dist = st.number_input("ğŸš— ì°¨ëŸ‰ ì´ë™ê±°ë¦¬", min_value=0.0, max_value=20000.0, value=500.0, step=100.0)

        with col2:
            heals = st.number_input("ğŸ’Š ì¹˜ë£Œ ì•„ì´í…œ ì‚¬ìš©", min_value=0.0, max_value=20.0, value=2.0, step=1.0)
            boosts = st.number_input("âš¡ ë¶€ìŠ¤í„° ì‚¬ìš©", min_value=0.0, max_value=20.0, value=1.0, step=1.0)
            weapons = st.number_input("ğŸ”« ë¬´ê¸° íšë“", min_value=0.0, max_value=20.0, value=4.0, step=1.0)
            assists = st.number_input("ğŸ¤ ì–´ì‹œìŠ¤íŠ¸", min_value=0.0, max_value=20.0, value=1.0, step=1.0)

        submitted = st.form_submit_button("ğŸ¯ í”Œë ˆì´ì–´ ë¶„ë¥˜í•˜ê¸°", use_container_width=True)

        if submitted:
            player_data = {
                "kills": kills,
                "damageDealt": damage,
                "walkDistance": walk_dist,
                "rideDistance": ride_dist,
                "heals": heals,
                "boosts": boosts,
                "weaponsAcquired": weapons,
                "assists": assists
            }

            with st.spinner("ğŸ”„ í”Œë ˆì´ì–´ í–‰ë™ ë¶„ì„ ì¤‘..."):
                result = predict_player(player_data)

            if result:
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•", result['player_type'])
                with col2:
                    st.metric("ğŸ¯ ì‹ ë¢°ë„", f"{result['confidence']:.1%}")
                with col3:
                    status = "ğŸš¨ ì´ìƒ" if result['is_anomaly'] else "âœ… ì •ìƒ"
                    st.metric("âš ï¸ ìƒíƒœ", status)

                # í™•ë¥  ë¶„í¬ ì°¨íŠ¸
                st.subheader("ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ ")
                prob_df = pd.DataFrame(
                    list(result['probabilities'].items()),
                    columns=['í”Œë ˆì´ì–´ ìœ í˜•', 'í™•ë¥ ']
                )
                prob_df['í™•ë¥ '] = prob_df['í™•ë¥ '] * 100

                fig = px.bar(
                    prob_df,
                    x='í”Œë ˆì´ì–´ ìœ í˜•',
                    y='í™•ë¥ ',
                    title="í”Œë ˆì´ì–´ ìœ í˜•ë³„ ë¶„ë¥˜ í™•ë¥ ",
                    color='í™•ë¥ ',
                    color_continuous_scale='viridis'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

                # ìƒì„¸ ê²°ê³¼
                with st.expander("ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                    st.json(result)

def show_dashboard():
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ğŸ“ˆ ì¼ì¼ ì˜ˆì¸¡", f"{np.random.randint(1000, 2000):,}ê±´")
    with col2:
        st.metric("âš¡ í‰ê·  ì‘ë‹µì‹œê°„", f"{np.random.randint(5, 15)}ms")
    with col3:
        st.metric("âœ… ì„±ê³µë¥ ", f"{np.random.uniform(98, 99.9):.1f}%")
    with col4:
        st.metric("ğŸš¨ ì´ìƒì¹˜ íƒì§€", f"{np.random.randint(20, 80)}ê±´")

    # ìƒ˜í”Œ ì°¨íŠ¸
    st.subheader("ğŸ“ˆ ì˜ˆì¸¡ ì¶”ì´ (ì‹œë®¬ë ˆì´ì…˜)")

    # ì‹œê°„ë³„ ì˜ˆì¸¡ ê±´ìˆ˜ ì°¨íŠ¸
    hours = list(range(24))
    predictions = [np.random.randint(30, 120) for _ in hours]

    chart_df = pd.DataFrame({
        'ì‹œê°„': hours,
        'ì˜ˆì¸¡ ê±´ìˆ˜': predictions
    })

    fig = px.line(chart_df, x='ì‹œê°„', y='ì˜ˆì¸¡ ê±´ìˆ˜',
                  title='ì‹œê°„ë³„ ì˜ˆì¸¡ ê±´ìˆ˜', markers=True)
    st.plotly_chart(fig, use_container_width=True)

    # í”Œë ˆì´ì–´ ìœ í˜• ë¶„í¬
    st.subheader("ğŸ¯ í”Œë ˆì´ì–´ ìœ í˜• ë¶„í¬")
    type_data = {
        'Aggressive Fighter': np.random.randint(150, 300),
        'Cautious Survivor': np.random.randint(100, 250),
        'Mobile Explorer': np.random.randint(80, 200),
        'Team Supporter': np.random.randint(60, 150),
        'Balanced Player': np.random.randint(200, 400)
    }

    fig_pie = px.pie(values=list(type_data.values()),
                     names=list(type_data.keys()),
                     title="ì˜¤ëŠ˜ì˜ í”Œë ˆì´ì–´ ìœ í˜• ë¶„í¬")
    st.plotly_chart(fig_pie, use_container_width=True)

if __name__ == "__main__":
    main()
'''

# Streamlit ì•± íŒŒì¼ ì €ì¥
with open('streamlit_dashboard.py', 'w', encoding='utf-8') as f:
    f.write(streamlit_code)

print("âœ… Streamlit ëŒ€ì‹œë³´ë“œ íŒŒì¼ ìƒì„± ì™„ë£Œ: streamlit_dashboard.py")

# Streamlit ì‹¤í–‰
print("\nğŸš€ Streamlit ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì¤‘...")
print("ğŸ’¡ í„°ë„ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ngrok ë§í¬ê°€ ì œê³µë©ë‹ˆë‹¤.")

import subprocess
import threading
import time

def run_streamlit():
    subprocess.run([
        "streamlit", "run", "streamlit_dashboard.py",
        "--server.port", "8501",
        "--server.headless", "true",
        "--server.enableCORS", "false",
        "--server.enableXsrfProtection", "false"
    ])

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ Streamlit ì‹¤í–‰
streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)
streamlit_thread.start()

print("âœ… Streamlit ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œì‘")
print("ğŸ“ ë¡œì»¬ ì£¼ì†Œ: http://127.0.0.1:8501")

time.sleep(3)
print("\nğŸ”— ì™¸ë¶€ ì ‘ì†ì„ ìœ„í•œ í„°ë„ë§ ì„¤ì • ì¤‘...")
```
### 5. Colab ë‚´ì¥ í„°ë„ë§ ì‚¬ìš©
``` python
# Google Colab ë‚´ì¥ í„°ë„ë§ ì‚¬ìš©
from google.colab import output
import time

print("ğŸŒ Google Colab í„°ë„ë§ ì„¤ì •")
print("="*40)

try:
    # Colab ë‚´ì¥ í„°ë„ë§ ì‚¬ìš©
    output.serve_kernel_port_as_window(8501)
    print("âœ… Colab í„°ë„ë§ ì„¤ì • ì™„ë£Œ!")
    print("ğŸ“ ìœ„ì˜ ìƒˆ ì°½ì—ì„œ Streamlit ì•±ì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    # FastAPIë„ ë™ì¼í•˜ê²Œ ì„¤ì •
    output.serve_kernel_port_as_window(8000)
    print("âœ… FastAPI í„°ë„ë§ë„ ì„¤ì • ì™„ë£Œ!")

except Exception as e:
    print(f"âš ï¸ Colab í„°ë„ë§ ì˜¤ë¥˜: {e}")
    print("ëŒ€ì•ˆ ë°©ë²•ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤...")

print("\nğŸ¯ ì ‘ì† ë°©ë²•:")
print("1. ìœ„ì— ìƒˆë¡œ ì—´ë¦° ì°½ì—ì„œ Streamlit ëŒ€ì‹œë³´ë“œ í™•ì¸")
print("2. ë˜ëŠ” ì•„ë˜ ì§ì ‘ ì ‘ì† ë§í¬ ì‚¬ìš©")

# ì§ì ‘ ë§í¬ ìƒì„±
import IPython.display as display

# Streamlit ë§í¬
streamlit_html = """
<div style="padding: 20px; border: 2px solid #1f77b4; border-radius: 10px; background-color: #f0f8ff;">
    <h3>ğŸ® PUBG Player Classifier Dashboard</h3>
    <p><strong>Streamlit ëŒ€ì‹œë³´ë“œ:</strong></p>
    <a href="http://127.0.0.1:8501" target="_blank" style="background-color: #1f77b4; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px;">
        ğŸ“Š Streamlit ëŒ€ì‹œë³´ë“œ ì—´ê¸°
    </a>
    <p style="margin-top: 15px;"><strong>API ë¬¸ì„œ:</strong></p>
    <a href="http://127.0.0.1:8000/docs" target="_blank" style="background-color: #28a745; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px;">
        ğŸ“– FastAPI ë¬¸ì„œ ì—´ê¸°
    </a>
</div>
"""

display.display(display.HTML(streamlit_html))

print("\nâœ… ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
print("ğŸ“Š ì„œë¹„ìŠ¤ ìƒíƒœ:")
print("   â€¢ Streamlit: http://127.0.0.1:8501 (ì •ìƒ)")
print("   â€¢ FastAPI: http://127.0.0.1:8000 (ì •ìƒ)")
print("   â€¢ API ë¬¸ì„œ: http://127.0.0.1:8000/docs (ì •ìƒ)")
```
### Colabë‚´ì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸
``` python
# Colab ë‚´ì—ì„œ ì§ì ‘ ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±
from IPython.display import HTML, display
import requests
import json

print("ğŸ® Colab ë‚´ì¥ í”Œë ˆì´ì–´ ë¶„ë¥˜ê¸° ìƒì„±")
print("="*50)

# JavaScriptì™€ HTMLì„ ì‚¬ìš©í•œ ì¸í„°ë™í‹°ë¸Œ ì¸í„°í˜ì´ìŠ¤
interface_html = """
<div style="max-width: 800px; margin: 20px auto; padding: 20px; border: 2px solid #007bff; border-radius: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
    <h2 style="text-align: center; margin-bottom: 30px;">ğŸ® PUBG Player Classifier</h2>

    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 20px;">
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸ¯ í‚¬ ìˆ˜:</label>
            <input type="number" id="kills" value="3" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸ’¥ ì´ ë°ë¯¸ì§€:</label>
            <input type="number" id="damage" value="250" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸš¶ ë„ë³´ ê±°ë¦¬:</label>
            <input type="number" id="walkDistance" value="1500" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸš— ì°¨ëŸ‰ ê±°ë¦¬:</label>
            <input type="number" id="rideDistance" value="500" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸ’Š ì¹˜ë£Œí…œ ì‚¬ìš©:</label>
            <input type="number" id="heals" value="2" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">âš¡ ë¶€ìŠ¤í„° ì‚¬ìš©:</label>
            <input type="number" id="boosts" value="1" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸ”« ë¬´ê¸° íšë“:</label>
            <input type="number" id="weapons" value="4" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
        <div>
            <label style="display: block; margin-bottom: 5px;">ğŸ¤ ì–´ì‹œìŠ¤íŠ¸:</label>
            <input type="number" id="assists" value="1" min="0" style="width: 100%; padding: 8px; border-radius: 5px; border: none;">
        </div>
    </div>

    <button onclick="classifyPlayer()" style="width: 100%; padding: 15px; background-color: #28a745; color: white; border: none; border-radius: 8px; font-size: 16px; cursor: pointer; margin-bottom: 20px;">
        ğŸ¯ í”Œë ˆì´ì–´ ë¶„ë¥˜í•˜ê¸°
    </button>

    <div id="loading" style="text-align: center; display: none;">
        <p>ğŸ”„ ë¶„ì„ ì¤‘...</p>
    </div>

    <div id="result" style="display: none; background-color: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; margin-top: 20px;">
    </div>
</div>

<script>
async function classifyPlayer() {
    // ë¡œë”© í‘œì‹œ
    document.getElementById('loading').style.display = 'block';
    document.getElementById('result').style.display = 'none';

    // ì…ë ¥ ë°ì´í„° ìˆ˜ì§‘
    const data = {
        kills: parseFloat(document.getElementById('kills').value) || 0,
        damageDealt: parseFloat(document.getElementById('damage').value) || 0,
        walkDistance: parseFloat(document.getElementById('walkDistance').value) || 0,
        rideDistance: parseFloat(document.getElementById('rideDistance').value) || 0,
        heals: parseFloat(document.getElementById('heals').value) || 0,
        boosts: parseFloat(document.getElementById('boosts').value) || 0,
        weaponsAcquired: parseFloat(document.getElementById('weapons').value) || 0,
        assists: parseFloat(document.getElementById('assists').value) || 0
    };

    try {
        // API í˜¸ì¶œ
        const response = await fetch('http://127.0.0.1:8000/predict', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(data)
        });

        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }

        const result = await response.json();

        // ê²°ê³¼ í‘œì‹œ
        document.getElementById('result').innerHTML = `
            <h3>ğŸ“Š ë¶„ì„ ê²°ê³¼</h3>
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0;">
                <div style="text-align: center;">
                    <h4>ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•</h4>
                    <p style="font-size: 18px; font-weight: bold; color: #ffd700;">${result.player_type}</p>
                </div>
                <div style="text-align: center;">
                    <h4>ğŸ¯ ì‹ ë¢°ë„</h4>
                    <p style="font-size: 18px; font-weight: bold; color: #00ff7f;">${(result.confidence * 100).toFixed(1)}%</p>
                </div>
                <div style="text-align: center;">
                    <h4>âš ï¸ ì´ìƒì¹˜ ì—¬ë¶€</h4>
                    <p style="font-size: 18px; font-weight: bold; color: ${result.is_anomaly ? '#ff6b6b' : '#51cf66'};">
                        ${result.is_anomaly ? 'ğŸš¨ ì´ìƒ' : 'âœ… ì •ìƒ'}
                    </p>
                </div>
                <div style="text-align: center;">
                    <h4>â±ï¸ ì²˜ë¦¬ì‹œê°„</h4>
                    <p style="font-size: 18px; font-weight: bold; color: #74c0fc;">${result.processing_time_ms.toFixed(2)}ms</p>
                </div>
            </div>

            <h4>ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :</h4>
            <div style="margin-top: 10px;">
                ${Object.entries(result.probabilities).map(([type, prob]) =>
                    `<div style="margin: 5px 0; display: flex; align-items: center;">
                        <span style="width: 150px; font-size: 14px;">${type}:</span>
                        <div style="background-color: rgba(255,255,255,0.2); border-radius: 10px; height: 20px; flex-grow: 1; margin: 0 10px;">
                            <div style="background-color: #4ecdc4; height: 100%; width: ${(prob * 100).toFixed(1)}%; border-radius: 10px; display: flex; align-items: center; justify-content: center; font-size: 12px; color: white;">
                                ${(prob * 100).toFixed(1)}%
                            </div>
                        </div>
                    </div>`
                ).join('')}
            </div>
        `;

        document.getElementById('result').style.display = 'block';

    } catch (error) {
        document.getElementById('result').innerHTML = `
            <div style="background-color: rgba(255,0,0,0.1); padding: 15px; border-radius: 8px; border-left: 4px solid #ff6b6b;">
                <p style="color: #ff6b6b; margin: 0;">âŒ API ì—°ê²° ì˜¤ë¥˜</p>
                <p style="margin: 5px 0 0 0; font-size: 14px;">ì˜¤ë¥˜ ë‚´ìš©: ${error.message}</p>
                <p style="margin: 5px 0 0 0; font-size: 12px;">FastAPI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.</p>
            </div>
        `;
        document.getElementById('result').style.display = 'block';
        console.error('Error:', error);
    } finally {
        document.getElementById('loading').style.display = 'none';
    }
}

// ì—”í„°í‚¤ë¡œ ì‹¤í–‰
document.addEventListener('keypress', function(e) {
    if (e.key === 'Enter') {
        classifyPlayer();
    }
});
</script>
"""

# HTML ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
display(HTML(interface_html))

print("âœ… ì¸í„°ë™í‹°ë¸Œ í”Œë ˆì´ì–´ ë¶„ë¥˜ê¸° ìƒì„± ì™„ë£Œ!")
print("ğŸ“ ìœ„ì˜ í¼ì—ì„œ ê²Œì„ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³  'ğŸ¯ í”Œë ˆì´ì–´ ë¶„ë¥˜í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!")
print("\nğŸ¯ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°:")
print("â€¢ ê³µê²©í˜•: í‚¬ 8, ë°ë¯¸ì§€ 450")
print("â€¢ ìƒì¡´í˜•: í‚¬ 1, ë°ë¯¸ì§€ 120, ì¹˜ë£Œí…œ 5, ë¶€ìŠ¤í„° 4")
print("â€¢ ì§€ì›í˜•: í‚¬ 2, ì–´ì‹œìŠ¤íŠ¸ 5")
```
#### FastAPI ì„œë²„ ì¬ì‹œì‘
Colabë‚´ì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ, ì‹¤í–‰

``` python
# FastAPI ì„œë²„ ìƒíƒœ í™•ì¸ ë° ì¬ì‹œì‘
import subprocess
import requests
import time
import sys

print("ğŸ” FastAPI ì„œë²„ ìƒíƒœ í™•ì¸ ë° ì¬ì‹œì‘")
print("="*50)

# 1. ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
print("ğŸ§¹ ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘...")
try:
    subprocess.run(['pkill', '-f', 'uvicorn'], capture_output=True)
    subprocess.run(['pkill', '-f', 'fastapi'], capture_output=True)
    time.sleep(2)
    print("âœ… ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
except:
    print("âš ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ (ì •ìƒ)")

# 2. ì„œë²„ ìƒíƒœ í™•ì¸
print("ğŸ” í˜„ì¬ ì„œë²„ ìƒíƒœ í™•ì¸...")
try:
    response = requests.get("http://127.0.0.1:8000/health", timeout=3)
    if response.status_code == 200:
        print("âœ… FastAPI ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!")
        server_running = True
    else:
        print(f"âš ï¸ ì„œë²„ ì‘ë‹µ ì´ìƒ: {response.status_code}")
        server_running = False
except:
    print("âŒ FastAPI ì„œë²„ ì—°ê²° ë¶ˆê°€")
    server_running = False

# 3. ì„œë²„ ì¬ì‹œì‘
if not server_running:
    print("\nğŸš€ FastAPI ì„œë²„ ì¬ì‹œì‘ ì¤‘...")

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ FastAPI ì‹¤í–‰
    try:
        process = subprocess.Popen([
            sys.executable, "-m", "uvicorn",
            "fastapi_app:app",
            "--host", "127.0.0.1",
            "--port", "8000",
            "--reload"
        ])

        print(f"âœ… FastAPI í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})")

        # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
        print("â³ ì„œë²„ ì‹œì‘ ëŒ€ê¸° ì¤‘...")
        for i in range(10):
            try:
                response = requests.get("http://127.0.0.1:8000/health", timeout=2)
                if response.status_code == 200:
                    print(f"âœ… FastAPI ì„œë²„ ì •ìƒ ì‹¤í–‰! (ì‹œë„ {i+1}/10)")
                    server_running = True
                    break
            except:
                time.sleep(1)
                print(f"â³ ì¬ì‹œë„ {i+1}/10...")

        if not server_running:
            print("âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
            # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸
            if process.poll() is None:
                print("âš ï¸ í”„ë¡œì„¸ìŠ¤ëŠ” ì‹¤í–‰ ì¤‘ì´ì§€ë§Œ ì‘ë‹µ ì—†ìŒ")
            else:
                print("âŒ í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë¨")

    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹œì‘ ì˜¤ë¥˜: {e}")

# 4. ìµœì¢… ìƒíƒœ í™•ì¸ ë° í…ŒìŠ¤íŠ¸
if server_running:
    print("\nğŸ§ª API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")

    # í—¬ìŠ¤ì²´í¬
    try:
        response = requests.get("http://127.0.0.1:8000/health")
        print(f"âœ… í—¬ìŠ¤ì²´í¬: {response.json()['status']}")
    except Exception as e:
        print(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")

    # ê°„ë‹¨í•œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    try:
        test_data = {
            "kills": 5,
            "damageDealt": 300,
            "walkDistance": 1500,
            "rideDistance": 500,
            "heals": 2,
            "boosts": 1,
            "weaponsAcquired": 4,
            "assists": 1
        }

        response = requests.post("http://127.0.0.1:8000/predict", json=test_data)
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {result['player_type']}")
        else:
            print(f"âŒ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")

    print("\nğŸ‰ FastAPI ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://127.0.0.1:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://127.0.0.1:8000/docs")

else:
    print("\nâŒ FastAPI ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
    print("ğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
    print("1. í¬íŠ¸ 8000ì´ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("2. ìˆ˜ë™ìœ¼ë¡œ ë‹¤ë¥¸ í¬íŠ¸ ì‹œë„:")
    print("   !python -m uvicorn fastapi_app:app --host 127.0.0.1 --port 8080")

print(f"\nğŸ“Š ì„œë²„ ìƒíƒœ: {'âœ… ì‹¤í–‰ ì¤‘' if server_running else 'âŒ ì¤‘ë‹¨ë¨'}")
```
### Pythonì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸
``` python
# Pythonì—ì„œ ì§ì ‘ í”Œë ˆì´ì–´ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
import requests
import json
from IPython.display import HTML, display

print("ğŸ® Python ê¸°ë°˜ í”Œë ˆì´ì–´ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸")
print("="*50)

def classify_player_python(kills=3, damage=250, walk_dist=1500, ride_dist=500,
                          heals=2, boosts=1, weapons=4, assists=1):
    """Python í•¨ìˆ˜ë¡œ í”Œë ˆì´ì–´ ë¶„ë¥˜"""

    # API ìš”ì²­ ë°ì´í„°
    player_data = {
        "kills": kills,
        "damageDealt": damage,
        "walkDistance": walk_dist,
        "rideDistance": ride_dist,
        "heals": heals,
        "boosts": boosts,
        "weaponsAcquired": weapons,
        "assists": assists
    }

    print(f"ğŸ“Š ì…ë ¥ ë°ì´í„°:")
    for key, value in player_data.items():
        print(f"  {key}: {value}")

    try:
        # API í˜¸ì¶œ
        response = requests.post("http://127.0.0.1:8000/predict", json=player_data)

        if response.status_code == 200:
            result = response.json()

            print(f"\nğŸ¯ ë¶„ì„ ê²°ê³¼:")
            print(f"  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: {result['player_type']}")
            print(f"  ğŸ¯ ì‹ ë¢°ë„: {result['confidence']:.3f} ({result['confidence']*100:.1f}%)")
            print(f"  ğŸš¨ ì´ìƒì¹˜: {'ì˜ˆ' if result['is_anomaly'] else 'ì•„ë‹ˆì˜¤'}")
            print(f"  â±ï¸ ì²˜ë¦¬ì‹œê°„: {result['processing_time_ms']:.2f}ms")

            print(f"\nğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :")
            for player_type, probability in result['probabilities'].items():
                bar_length = int(probability * 50)  # 50ìë¡œ ìŠ¤ì¼€ì¼ë§
                bar = 'â–ˆ' * bar_length + 'â–‘' * (50 - bar_length)
                print(f"  {player_type:<20}: {bar} {probability*100:.1f}%")

            return result

        else:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            print(f"ì‘ë‹µ: {response.text}")
            return None

    except Exception as e:
        print(f"âŒ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰:")
print("\n" + "="*60)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ê³µê²©í˜• í”Œë ˆì´ì–´
print("1ï¸âƒ£ ê³µê²©í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸")
print("-" * 30)
result1 = classify_player_python(kills=8, damage=450, walk_dist=1200, heals=1)

print("\n" + "="*60)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ìƒì¡´í˜• í”Œë ˆì´ì–´
print("2ï¸âƒ£ ìƒì¡´í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸")
print("-" * 30)
result2 = classify_player_python(kills=1, damage=120, walk_dist=2500, heals=5, boosts=4)

print("\n" + "="*60)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì§€ì›í˜• í”Œë ˆì´ì–´
print("3ï¸âƒ£ ì§€ì›í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸")
print("-" * 30)
result3 = classify_player_python(kills=2, damage=180, assists=5, heals=3)

print("\n" + "="*60)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 4: íƒí—˜í˜• í”Œë ˆì´ì–´
print("4ï¸âƒ£ íƒí—˜í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸")
print("-" * 30)
result4 = classify_player_python(kills=3, damage=200, walk_dist=3000, ride_dist=2000)

print("\n" + "="*60)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 5: ì´ìƒì¹˜ í…ŒìŠ¤íŠ¸
print("5ï¸âƒ£ ì´ìƒì¹˜ í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸ (ê·¹ë‹¨ì  ìˆ˜ì¹˜)")
print("-" * 30)
result5 = classify_player_python(kills=25, damage=3000, walk_dist=12000)

print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

# ëŒ€í™”í˜• í•¨ìˆ˜ ì œê³µ
print("\nğŸ’¡ ì§ì ‘ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”:")
print("classify_player_python(kills=ê°’, damage=ê°’, walk_dist=ê°’, heals=ê°’)")
print("ì˜ˆ: classify_player_python(kills=10, damage=600, heals=1)")
```

#### Pythonì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸ ê²°ê³¼

``` bash
ğŸ® Python ê¸°ë°˜ í”Œë ˆì´ì–´ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
==================================================
ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰:

============================================================
1ï¸âƒ£ ê³µê²©í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸
------------------------------
ğŸ“Š ì…ë ¥ ë°ì´í„°:
  kills: 8
  damageDealt: 450
  walkDistance: 1200
  rideDistance: 500
  heals: 1
  boosts: 1
  weaponsAcquired: 4
  assists: 1

ğŸ¯ ë¶„ì„ ê²°ê³¼:
  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: Aggressive Fighter
  ğŸ¯ ì‹ ë¢°ë„: 0.911 (91.1%)
  ğŸš¨ ì´ìƒì¹˜: ì•„ë‹ˆì˜¤
  â±ï¸ ì²˜ë¦¬ì‹œê°„: 0.12ms

ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :
  Aggressive Fighter  : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 59.6%
  Cautious Survivor   : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 16.1%
  Mobile Explorer     : â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 5.0%
  Team Supporter      : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 6.5%
  Balanced Player     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 12.8%

============================================================
2ï¸âƒ£ ìƒì¡´í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸
------------------------------
ğŸ“Š ì…ë ¥ ë°ì´í„°:
  kills: 1
  damageDealt: 120
  walkDistance: 2500
  rideDistance: 500
  heals: 5
  boosts: 4
  weaponsAcquired: 4
  assists: 1

ğŸ¯ ë¶„ì„ ê²°ê³¼:
  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: Cautious Survivor
  ğŸ¯ ì‹ ë¢°ë„: 0.772 (77.2%)
  ğŸš¨ ì´ìƒì¹˜: ì•„ë‹ˆì˜¤
  â±ï¸ ì²˜ë¦¬ì‹œê°„: 0.11ms

ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :
  Aggressive Fighter  : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 7.3%
  Cautious Survivor   : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 61.4%
  Mobile Explorer     : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 7.7%
  Team Supporter      : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 6.4%
  Balanced Player     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 17.2%

============================================================
3ï¸âƒ£ ì§€ì›í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸
------------------------------
ğŸ“Š ì…ë ¥ ë°ì´í„°:
  kills: 2
  damageDealt: 180
  walkDistance: 1500
  rideDistance: 500
  heals: 3
  boosts: 1
  weaponsAcquired: 4
  assists: 5

ğŸ¯ ë¶„ì„ ê²°ê³¼:
  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: Team Supporter
  ğŸ¯ ì‹ ë¢°ë„: 0.925 (92.5%)
  ğŸš¨ ì´ìƒì¹˜: ì•„ë‹ˆì˜¤
  â±ï¸ ì²˜ë¦¬ì‹œê°„: 0.09ms

ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :
  Aggressive Fighter  : â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 4.1%
  Cautious Survivor   : â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 4.9%
  Mobile Explorer     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 13.7%
  Team Supporter      : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 61.1%
  Balanced Player     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 16.2%

============================================================
4ï¸âƒ£ íƒí—˜í˜• í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸
------------------------------
ğŸ“Š ì…ë ¥ ë°ì´í„°:
  kills: 3
  damageDealt: 200
  walkDistance: 3000
  rideDistance: 2000
  heals: 2
  boosts: 1
  weaponsAcquired: 4
  assists: 1

ğŸ¯ ë¶„ì„ ê²°ê³¼:
  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: Mobile Explorer
  ğŸ¯ ì‹ ë¢°ë„: 0.920 (92.0%)
  ğŸš¨ ì´ìƒì¹˜: ì•„ë‹ˆì˜¤
  â±ï¸ ì²˜ë¦¬ì‹œê°„: 0.09ms

ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :
  Aggressive Fighter  : â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 5.6%
  Cautious Survivor   : â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 8.9%
  Mobile Explorer     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 58.7%
  Team Supporter      : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 11.2%
  Balanced Player     : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 15.6%

============================================================
5ï¸âƒ£ ì´ìƒì¹˜ í”Œë ˆì´ì–´ í…ŒìŠ¤íŠ¸ (ê·¹ë‹¨ì  ìˆ˜ì¹˜)
------------------------------
ğŸ“Š ì…ë ¥ ë°ì´í„°:
  kills: 25
  damageDealt: 3000
  walkDistance: 12000
  rideDistance: 500
  heals: 2
  boosts: 1
  weaponsAcquired: 4
  assists: 1

ğŸ¯ ë¶„ì„ ê²°ê³¼:
  ğŸ·ï¸ í”Œë ˆì´ì–´ ìœ í˜•: Aggressive Fighter
  ğŸ¯ ì‹ ë¢°ë„: 0.924 (92.4%)
  ğŸš¨ ì´ìƒì¹˜: ì˜ˆ
  â±ï¸ ì²˜ë¦¬ì‹œê°„: 0.08ms

ğŸ“Š ê° ìœ í˜•ë³„ í™•ë¥ :
  Aggressive Fighter  : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65.3%
  Cautious Survivor   : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 11.8%
  Mobile Explorer     : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 7.5%
  Team Supporter      : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 6.2%
  Balanced Player     : â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 9.3%

ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!

ğŸ’¡ ì§ì ‘ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”:
classify_player_python(kills=ê°’, damage=ê°’, walk_dist=ê°’, heals=ê°’)
ì˜ˆ: classify_player_python(kills=10, damage=600, heals=1)
```
